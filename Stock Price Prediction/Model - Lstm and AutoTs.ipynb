{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import datetime\n",
        "from datetime import date, timedelta\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "\n",
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "\n",
        "!pip install AutoTS\n",
        "from autots import AutoTS"
      ],
      "metadata": {
        "id": "V_NqQyfrs-Cn",
        "outputId": "6d396f6f-88fd-4b1f-a38f-3a2403765521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.9/dist-packages (0.2.12)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2.3.5)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2.28.2)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.9/dist-packages (from yfinance) (39.0.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/dist-packages (from html5lib>=1.1->yfinance) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (1.26.15)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: AutoTS in /usr/local/lib/python3.9/dist-packages (0.5.4)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.9/dist-packages (from AutoTS) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from AutoTS) (1.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from AutoTS) (0.13.5)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.9/dist-packages (from AutoTS) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25.0->AutoTS) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25.0->AutoTS) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->AutoTS) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->AutoTS) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->AutoTS) (1.1.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.10.0->AutoTS) (23.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.10.0->AutoTS) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.2->statsmodels>=0.10.0->AutoTS) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stockPrice(val ,title) :\n",
        "\n",
        "    today = date.today()\n",
        "\n",
        "    d1       = today.strftime(\"%Y-%m-%d\")\n",
        "    end_date = d1\n",
        "\n",
        "    d2         = date.today() - timedelta(days=5000) \n",
        "    d2         = d2.strftime(\"%Y-%m-%d\")\n",
        "    start_date = d2\n",
        "\n",
        "\n",
        "    data = yf.download(\n",
        "                          val                   , \n",
        "                          start    = start_date , \n",
        "                          end      = end_date   , \n",
        "                          progress = False\n",
        "                      )\n",
        "\n",
        "    data = data[[\"Close\"]]\n",
        "  \n",
        "    close_data = data['Close'].values\n",
        "    close_data = close_data.reshape((-1,1))\n",
        "\n",
        "    split_percent = 0.80\n",
        "    split = int(split_percent*len(close_data))\n",
        "\n",
        "    close_train = close_data[:split]\n",
        "    close_test = close_data[split:]\n",
        "\n",
        "    date_train = data['Close'][:split]\n",
        "    date_test  = data['Close'][split:]\n",
        "  \n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.plot(date_train, color = \"black\" , label = 'Train')\n",
        "    plt.plot(date_test, color = \"red\"  , label = 'Test')\n",
        "    plt.ylabel('Stock Price')\n",
        "    plt.xlabel('Date')\n",
        "    plt.title(\"Stock Price Data\")\n",
        "    plt.show()\n",
        "\n",
        "    ## Model 1\n",
        "    look_back = 15\n",
        "\n",
        "    train_generator = TimeseriesGenerator(close_train, close_train, length=look_back, batch_size=20)     \n",
        "    test_generator = TimeseriesGenerator(close_test, close_test, length=look_back, batch_size=1)\n",
        "\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(LSTM(10,activation='relu',input_shape=(look_back,1)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    num_epochs = 25\n",
        "    model.fit_generator(train_generator, epochs=num_epochs, verbose=1)\n",
        "   \n",
        "    prediction = model.predict_generator(test_generator)\n",
        "\n",
        "    close_train = close_train.reshape((-1))\n",
        "    close_test = close_test.reshape((-1))\n",
        "    prediction = prediction.reshape((-1))\n",
        "\n",
        "    trace1 = go.Scatter(x = date_train ,y = close_train ,mode = 'lines' ,name = 'Data')\n",
        "    trace2 = go.Scatter(x = date_test  ,y = prediction  ,mode = 'lines' ,name = 'Prediction')\n",
        "    trace3 = go.Scatter(x = date_test  ,y = close_test  , mode='lines'  ,name = 'Ground Truth')\n",
        "    layout = go.Layout(title = \"Stock\" ,xaxis = {'title' : \"Date\"} ,yaxis = {'title' : \"Close\"})\n",
        "\n",
        "    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n",
        "    fig.show()\n",
        "        \n",
        "\n",
        "\n",
        "    ## Model 2\n",
        "    model = AutoTS(forecast_length=30, frequency='infer', ensemble='simple',max_generations=2,transformer_max_depth=2 ,verbose=2)\n",
        "    model = model.fit(date_train)\n",
        "\n",
        "    prediction = model.predict()\n",
        "\n",
        "    y_pred = model.predict()\n",
        "    forecast = y_pred.forecast\n",
        "\n",
        "    print(forecast)"
      ],
      "metadata": {
        "id": "VOAgnDWzt_pu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Main\n",
        "if __name__==\"__main__\":\n",
        "    \n",
        "    print(\"Available Stocks : \\n\")\n",
        "    print(\"1. Apple \\n\")\n",
        "    print(\"2. Bitcoin \\n\")\n",
        "    print(\"3. Netflix \\n\")\n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        val = input('Enter name of stock or -1 to exit: ')\n",
        "        \n",
        "        if(val=='-1'):\n",
        "            print(\"Thank you\")\n",
        "            break\n",
        "        \n",
        "        \n",
        "        elif(val==\"Apple\" or val=='1'):\n",
        "            stockPrice('AAPL','Apple Stock Price Analysis')\n",
        "            \n",
        "        elif(val==\"Bitcoin\" or val=='2'):\n",
        "            stockPrice('BTC-USD','Bitcoin Price Analysis')\n",
        "        \n",
        "        elif(val==\"Netflix\" or val=='3'):\n",
        "            stockPrice('NFLX','Netflix Stock Price Analysis')\n"
      ],
      "metadata": {
        "id": "pOv8axkct_sG",
        "outputId": "03a07365-5785-4b6e-a75c-db79a4e31f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available Stocks : \n",
            "\n",
            "1. Apple \n",
            "\n",
            "2. Bitcoin \n",
            "\n",
            "3. Netflix \n",
            "\n",
            "Enter name of stock or -1 to exit: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ea0185fccf84>:55: UserWarning:\n",
            "\n",
            "`Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138/138 [==============================] - 6s 17ms/step - loss: 1516.0902\n",
            "Epoch 2/25\n",
            "138/138 [==============================] - 2s 15ms/step - loss: 35.4341\n",
            "Epoch 3/25\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 4.9541\n",
            "Epoch 4/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 4.5726\n",
            "Epoch 5/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 4.1577\n",
            "Epoch 6/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 3.8520\n",
            "Epoch 7/25\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 4.0130\n",
            "Epoch 8/25\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 4.2435\n",
            "Epoch 9/25\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 3.3147\n",
            "Epoch 10/25\n",
            "138/138 [==============================] - 2s 11ms/step - loss: 3.0754\n",
            "Epoch 11/25\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 3.7789\n",
            "Epoch 12/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 2.2160\n",
            "Epoch 13/25\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 2.1384\n",
            "Epoch 14/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 1.6890\n",
            "Epoch 15/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 1.5221\n",
            "Epoch 16/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 1.4938\n",
            "Epoch 17/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 1.2654\n",
            "Epoch 18/25\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 1.3156\n",
            "Epoch 19/25\n",
            "138/138 [==============================] - 1s 10ms/step - loss: 2.8361\n",
            "Epoch 20/25\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 2.3642\n",
            "Epoch 21/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 2.7164\n",
            "Epoch 22/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 1.4335\n",
            "Epoch 23/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 1.2076\n",
            "Epoch 24/25\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 1.2327\n",
            "Epoch 25/25\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 1.2209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ea0185fccf84>:57: UserWarning:\n",
            "\n",
            "`Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9d805f06-573d-4274-8b5c-95b16ea5d7cb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9d805f06-573d-4274-8b5c-95b16ea5d7cb\")) {                    Plotly.newPlot(                        \"9d805f06-573d-4274-8b5c-95b16ea5d7cb\",                        [{\"mode\":\"lines\",\"name\":\"Data\",\"x\":[4.900713920593262,4.869999885559082,4.947143077850342,5.083570957183838,5.081070899963379,5.24571418762207,5.268570899963379,5.419642925262451,5.461071014404297,5.411070823669434,5.5978569984436035,5.6364288330078125,5.713929176330566,5.7178568840026855,5.714285850524902,5.715356826782227,5.813929080963135,5.835357189178467,5.943929195404053,5.912499904632568,5.896786212921143,5.853929042816162,5.911070823669434,5.882856845855713,5.815357208251953,5.903929233551025,6.014999866485596,5.9564290046691895,5.699643135070801,5.857142925262451,5.878571033477783,5.940357208251953,6.0435709953308105,6.0378570556640625,6.050000190734863,5.978929042816162,6.051785945892334,6.073214054107666,6.007500171661377,5.903571128845215,5.899285793304443,5.948214054107666,6.082499980926514,6.1760711669921875,6.112143039703369,6.1628570556640625,6.148571014404297,6.204286098480225,6.255713939666748,6.495357036590576,6.591071128845215,6.6078572273254395,6.572143077850342,6.588571071624756,6.625,6.565000057220459,6.513214111328125,6.648213863372803,6.62071418762207,6.619643211364746,6.459286212921143,6.603570938110352,6.643570899963379,6.786070823669434,6.794642925262451,6.759643077850342,6.802499771118164,6.814642906188965,6.786428928375244,6.831786155700684,6.805714130401611,6.716071128845215,6.78071403503418,7.098570823669434,7.318571090698242,7.32857084274292,7.283570766448975,7.231429100036621,7.048929214477539,6.871428966522217,7.012499809265137,6.732142925262451,6.76107120513916,6.7410712242126465,6.814642906188965,6.929643154144287,6.940713882446289,7.195000171661377,7.24928617477417,7.2589287757873535,7.213929176330566,7.301785945892334,7.379642963409424,7.392857074737549,7.355713844299316,7.161070823669434,7.139999866485596,7.3528571128845215,7.30142879486084,7.292500019073486,7.163928985595703,7.13964319229126,7.034643173217773,7.008213996887207,7.0171427726745605,6.904285907745361,6.748213768005371,6.781071186065674,7.064286231994629,7.01535701751709,6.952499866485596,7.034999847412109,6.934642791748047,6.965356826782227,6.852142810821533,6.979642868041992,7.0796427726745605,7.15571403503418,7.2178568840026855,7.465713977813721,7.557499885559082,7.4678568840026855,7.558570861816406,7.526071071624756,7.643214225769043,7.656428813934326,7.534643173217773,7.520713806152344,7.570713996887207,7.503929138183594,7.4185709953308105,7.523213863372803,7.479642868041992,7.354642868041992,7.679999828338623,7.56178617477417,7.431070804595947,7.0625,7.252500057220459,7.355000019073486,7.424285888671875,7.117499828338623,6.859285831451416,6.9546427726745605,6.994999885559082,7.115356922149658,6.85892915725708,6.980713844299316,6.932857036590576,7.006785869598389,6.968571186065674,7.0953569412231445,7.156428813934326,7.264286041259766,7.23392915725708,7.247499942779541,7.202499866485596,7.1578569412231445,7.0378570556640625,7.166429042816162,7.214285850524902,7.307857036590576,7.463929176330566,7.458929061889648,7.476070880889893,7.525356769561768,7.819643020629883,7.824285984039307,7.965000152587891,8.029999732971191,8.053570747375488,8.092857360839844,7.994286060333252,8.016071319580078,8.00428581237793,8.023214340209961,7.9375,8.026785850524902,8.15571403503418,8.19178581237793,8.094642639160156,8.246429443359375,8.299642562866211,8.423213958740234,8.39285659790039,8.427499771118164,8.517499923706055,8.555000305175781,8.592857360839844,8.569643020629883,8.635356903076172,8.653214454650879,8.65821361541748,8.774642944335938,8.890000343322754,8.835714340209961,8.823928833007812,8.735357284545898,9.257857322692871,9.516785621643066,9.672499656677246,9.625,9.35857105255127,9.342857360839844,9.59428596496582,9.3246431350708,9.512499809265137,9.238571166992188,9.142499923706055,8.79464340209961,8.42357063293457,9.071070671081543,9.161429405212402,9.360357284545898,9.227143287658691,9.0649995803833,9.079285621643066,9.012857437133789,8.869285583496094,8.491429328918457,8.65428638458252,8.812856674194336,8.757857322692871,8.71821403503418,9.048213958740234,9.174285888671875,9.315357208251953,9.426786422729492,9.397143363952637,9.14142894744873,8.962142944335938,8.904643058776855,8.685713768005371,8.946785926818848,9.053929328918457,9.081428527832031,9.274642944335938,9.54464340209961,9.709643363952637,9.788213729858398,9.64892864227295,9.780357360839844,9.677499771118164,9.60714340209961,9.524999618530273,9.58214282989502,9.14892864227295,8.983214378356934,8.874285697937012,8.819286346435547,8.879643440246582,9.238213539123535,9.217499732971191,9.272143363952637,9.188928604125977,8.992856979370117,9.026070594787598,8.98035717010498,8.925000190734863,8.770713806152344,8.996070861816406,9.079999923706055,9.250714302062988,9.283571243286133,9.260000228881836,9.431428909301758,9.319999694824219,9.21821403503418,9.1875,9.351785659790039,9.354642868041992,9.392143249511719,9.346428871154785,9.288928985595703,9.348214149475098,9.264642715454102,8.935357093811035,8.992500305175781,8.896429061889648,8.84428596496582,8.998929023742676,9.038213729858398,8.924285888671875,8.915714263916016,8.778571128845215,8.568928718566895,8.674642562866211,8.581428527832031,8.62928581237793,8.660714149475098,8.682143211364746,8.940357208251953,9.006071090698242,9.241786003112793,9.207500457763672,9.390000343322754,9.395357131958008,9.407500267028809,9.537142753601074,9.57357120513916,9.650713920593262,9.8774995803833,9.834643363952637,10.115357398986816,10.134642601013184,10.276785850524902,10.318571090698242,10.4399995803833,10.398571014404297,10.244999885559082,10.263214111328125,10.133929252624512,10.09000015258789,9.95142936706543,10.319286346435547,10.328213691711426,10.329285621643066,10.5024995803833,10.54857063293457,10.662142753601074,10.71928596496582,10.796786308288574,11.240714073181152,11.35714340209961,11.053214073181152,11.090356826782227,11.054286003112793,10.981071472167969,11.029999732971191,11.001786231994629,10.993928909301758,10.901429176330566,10.749285697937012,10.863571166992188,11.04857063293457,11.171428680419922,11.366786003112793,11.326070785522461,11.37928581237793,11.28857135772705,11.358214378356934,11.308929443359375,11.001070976257324,10.965714454650879,10.771071434020996,10.73214340209961,11.01535701751709,10.954643249511719,11.191429138183594,11.026070594787598,11.242856979370117,11.25,11.31678581237793,11.112500190734863,11.300000190734863,11.362500190734863,11.337142944335938,11.433929443359375,11.364643096923828,11.464642524719238,11.420000076293945,11.44857120513916,11.488213539123535,11.438928604125977,11.441429138183594,11.473214149475098,11.450357437133789,11.507499694824219,11.578571319580078,11.6128568649292,11.557143211364746,11.59571361541748,11.623929023742676,11.617500305175781,11.559286117553711,11.520000457763672,11.770357131958008,11.831786155700684,11.928570747375488,11.918929100036621,12.00428581237793,12.23035717010498,12.20142936706543,12.300713539123535,12.34571361541748,12.445713996887207,12.166070938110352,12.101428985595703,11.881428718566895,11.668571472167969,12.051786422729492,12.192856788635254,12.280357360839844,12.257499694824219,12.003570556640625,12.118571281433105,12.322500228881836,12.29714298248291,12.265713691711426,12.375,12.567143440246582,12.685713768005371,12.791428565979004,12.662142753601074,12.744643211364746,12.82785701751709,12.853570938110352,12.968929290771484,12.796428680419922,12.520000457763672,12.09321403503418,12.236429214477539,12.24571418762207,12.434286117553711,12.614643096923828,12.475357055664062,12.575714111328125,12.841428756713867,12.85714340209961,12.691429138183594,12.705714225769043,12.588213920593262,12.381071090698242,12.571070671081543,12.627142906188965,12.336786270141602,11.786070823669434,11.95142936706543,11.809642791748047,12.117856979370117,12.185713768005371,12.11392879486084,12.320357322692871,12.555000305175781,12.515713691711426,12.534285545349121,12.451070785522461,12.446785926818848,12.305713653564453,12.185357093811035,12.103214263916016,12.072856903076172,12.074286460876465,11.966428756713867,11.814286231994629,11.871429443359375,12.004643440246582,11.872142791748047,11.694999694824219,11.851785659790039,12.066429138183594,12.228928565979004,12.524999618530273,12.607500076293945,12.515000343322754,12.505356788635254,12.383929252624512,12.504643440246582,12.367142677307129,12.435713768005371,12.48464298248291,12.383929252624512,12.380714416503906,12.414285659790039,12.48035717010498,12.401070594787598,12.3774995803833,12.160714149475098,11.903571128845215,12.005000114440918,12.138214111328125,12.161786079406738,11.972143173217773,11.942856788635254,11.86392879486084,12.027856826782227,11.964285850524902,12.0503568649292,12.422499656677246,12.339642524719238,12.360713958740234,12.265713691711426,12.072856903076172,11.85857105255127,11.865714073181152,11.838929176330566,11.639286041259766,11.664285659790039,11.872857093811035,11.66964340209961,11.6128568649292,11.437856674194336,11.261428833007812,11.617856979370117,11.521785736083984,11.829643249511719,11.655357360839844,11.85857105255127,11.973570823669434,11.930000305175781,11.988213539123535,12.259285926818848,12.479642868041992,12.562856674194336,12.757143020629883,12.846785545349121,12.64285659790039,12.633929252624512,12.786429405212402,12.77750015258789,13.032856941223145,13.350000381469727,13.458929061889648,13.817856788635254,13.831786155700684,14.046428680419922,14.23214340209961,14.407500267028809,14.021071434020996,13.993571281433105,13.945713996887207,14.16964340209961,13.889642715454102,14.020357131958008,13.477499961853027,13.343570709228516,12.614643096923828,13.357500076293945,12.98892879486084,13.346428871154785,13.463929176330566,13.693214416503906,13.588570594787598,13.587142944335938,13.073213577270508,12.715356826782227,12.729999542236328,13.342857360839844,13.4350004196167,13.347143173217773,13.699286460876465,13.927499771118164,13.928214073181152,13.743928909301758,13.608214378356934,13.358928680419922,13.562143325805664,13.711786270141602,13.71928596496582,13.481429100036621,13.569286346435547,13.736429214477539,13.903571128845215,14.034285545349121,14.303570747375488,14.701070785522461,14.766071319580078,14.71928596496582,14.350713729858398,14.439286231994629,14.39892864227295,14.259285926818848,14.178929328918457,13.948928833007812,13.618571281433105,13.378570556640625,13.303570747375488,13.508929252624512,13.477499961853027,13.20714282989502,13.88607120513916,14.29607105255127,14.36392879486084,14.586786270141602,15.071429252624512,14.999643325805664,15.079999923706055,14.236429214477539,14.118213653564453,14.031070709228516,14.491786003112793,14.206070899963379,14.307143211364746,14.453213691711426,14.462499618530273,14.456428527832031,14.161070823669434,14.193214416503906,14.395357131958008,14.294285774230957,14.276070594787598,14.508213996887207,14.117142677307129,13.757857322692871,13.736429214477539,13.545000076293945,13.886786460876465,13.741786003112793,13.478928565979004,13.390713691711426,13.178929328918457,13.446785926818848,13.106785774230957,12.98464298248291,13.432856559753418,13.328571319580078,13.649999618530273,13.854642868041992,13.91785717010498,14.036070823669434,13.962499618530273,13.896071434020996,13.952142715454102,14.057856559753418,13.994285583496094,13.88607120513916,13.578213691711426,13.533571243286133,13.607856750488281,13.650357246398926,14.141071319580078,14.158928871154785,14.233928680419922,14.404643058776855,14.518928527832031,14.380000114440918,14.468570709228516,14.464285850524902,14.686785697937012,14.765713691711426,14.929642677307129,15.085714340209961,15.061785697937012,15.115714073181152,15.091071128845215,15.049642562866211,14.993213653564453,15.16785717010498,15.325357437133789,15.276785850524902,15.010713577270508,15.264642715454102,15.014642715454102,15.952142715454102,15.879643440246582,15.974286079406738,16.17892837524414,16.3028564453125,16.292499542236328,16.25428581237793,16.417142868041992,16.570356369018555,16.743928909301758,17.0242862701416,17.61321449279785,17.622142791748047,17.950000762939453,18.19499969482422,17.773929595947266,17.936071395874023,17.932857513427734,18.387500762939453,18.322856903076172,18.4424991607666,18.657499313354492,18.777143478393555,19.12178611755371,19.37285614013672,19.445356369018555,19.470714569091797,19.04142951965332,18.937856674194336,18.953214645385742,19.356786727905273,19.47035789489746,19.71428680419922,20.28928565979004,21.056428909301758,20.912857055664062,20.9132137298584,21.467857360839844,21.641429901123047,21.51785659790039,21.405000686645508,21.287500381469727,21.6778564453125,21.945714950561523,22.057857513427734,21.78071403503418,21.412500381469727,22.093929290771484,22.4757137298584,22.296785354614258,22.63142967224121,22.72249984741211,22.444286346435547,22.364286422729492,22.241785049438477,21.6153564453125,20.718929290771484,21.774999618530273,21.726428985595703,20.979999542236328,20.463571548461914,20.417856216430664,20.010000228881836,21.78571319580078,21.703571319580078,21.53571319580078,20.856428146362305,20.79035758972168,20.9278564453125,20.779285430908203,20.1875,20.338571548461914,20.292142868041992,20.327856063842773,20.375713348388672,20.239643096923828,19.93642807006836,19.756071090698242,19.502857208251953,18.932857513427734,18.942142486572266,20.045713424682617,19.891786575317383,20.37714385986328,20.190000534057617,20.081785202026367,20.438213348388672,20.684642791748047,20.633214950561523,20.035356521606445,20.153213500976562,20.101070404052734,20.409286499023438,20.41857147216797,20.7257137298584,20.398929595947266,20.5771427154541,20.43428611755371,20.411785125732422,20.504642486572266,20.920713424682617,20.97892951965332,20.919286727905273,20.631071090698242,20.78928565979004,20.3846435546875,20.429643630981445,20.51785659790039,20.323213577270508,20.85714340209961,21.161428451538086,21.407499313354492,21.783571243286133,21.63857078552246,21.92464256286621,21.721786499023438,21.5867862701416,21.389286041259766,21.60607147216797,21.675357818603516,21.676429748535156,21.652143478393555,21.940000534057617,21.582143783569336,21.565357208251953,21.461429595947266,20.534643173217773,20.531429290771484,20.898571014404297,21.25107192993164,21.812856674194336,21.671785354614258,21.706785202026367,21.989286422729492,22.233928680419922,22.175357818603516,22.13785743713379,22.168928146362305,22.203571319580078,22.5,22.56035614013672,22.52964210510254,22.726428985595703,23.146785736083984,23.75535774230957,23.430713653564453,23.888214111328125,23.66535758972168,23.68642807006836,24.13142967224121,24.100000381469727,24.052499771118164,23.70964241027832,23.75857162475586,24.10607147216797,23.936786651611328,24.15250015258789,24.301429748535156,23.669286727905273,23.592500686645508,23.921070098876953,24.39214324951172,24.68857192993164,24.992143630981445,25.068214416503906,25.075000762939453,24.953571319580078,25.00321388244629,24.671070098876953,24.05500030517578,23.75642967224121,24.332857131958008,23.825000762939453,23.54964256286621,23.618213653564453,23.980356216430664,23.814285278320312,23.306785583496094,22.791786193847656,22.70892906188965,22.8896427154541,22.43214225769043,22.489643096923828,22.670000076293945,23.206785202026367,23.021785736083984,22.59428596496582,21.780000686645508,22.64392852783203,21.90571403503418,22.02964210510254,21.769285202026367,21.571428298950195,21.261428833007812,21.30500030517578,20.600000381469727,20.87928581237793,20.816070556640625,19.928571701049805,19.20535659790039,19.537857055664062,19.38678550720215,19.389286041259766,19.174285888671875,18.77214241027832,18.845714569091797,20.20464324951172,20.032499313354492,20.060714721679688,20.41071319580078,21.054643630981445,20.885000228881836,20.819286346435547,21.04857063293457,20.902856826782227,20.93535614013672,20.566070556640625,19.24250030517578,19.544286727905273,19.04464340209961,18.922143936157227,19.335357666015625,19.25,18.917499542236328,18.206785202026367,18.52964210510254,19.06785774230957,18.796785354614258,18.633214950561523,18.547500610351562,18.577499389648438,18.321428298950195,18.395000457763672,18.199642181396484,19.006071090698242,19.608213424682617,19.360713958740234,18.821428298950195,18.71071434020996,18.761070251464844,18.467857360839844,18.696786880493164,18.582143783569336,17.91964340209961,17.354286193847656,18.074642181396484,17.952856063842773,17.85714340209961,18.02750015258789,18.357500076293945,16.08928680419922,15.710000038146973,16.065357208251953,16.366785049438477,16.315357208251953,16.267499923706055,16.200714111328125,15.79714298248291,16.351428985595703,16.33392906188965,16.722143173217773,16.963571548461914,17.140356063842773,16.71071434020996,16.67892837524414,16.663928985595703,16.43428611755371,16.428213119506836,16.030357360839844,15.930713653564453,16.100357055664062,15.814286231994629,16.034643173217773,15.8774995803833,15.764286041259766,15.373929023742676,15.001786231994629,15.397856712341309,15.202142715454102,15.377857208251953,15.418571472167969,15.638214111328125,15.301071166992188,15.298213958740234,15.446429252624512,15.845000267028809,16.275714874267578,16.231786727905273,16.145713806152344,16.168928146362305,16.49678611755371,16.556428909301758,16.46928596496582,16.145713806152344,15.809286117553711,15.318214416503906,15.349642753601074,15.428214073181152,15.275713920593262,15.114286422729492,15.221785545349121,15.249285697937012,15.560357093811035,15.511786460876465,15.350000381469727,14.994643211364746,15.222857475280762,14.385713577270508,14.001786231994629,13.947500228881836,14.238213539123535,14.504643440246582,14.480713844299316,14.585000038146973,14.899999618530273,15.361429214477539,15.813570976257324,15.688928604125977,15.911429405212402,16.070714950561523,16.453929901123047,16.380714416503906,16.56571388244629,16.313213348388672,16.177499771118164,16.240713119506836,15.852143287658691,15.316070556640625,15.520713806152344,15.473570823669434,15.818928718566895,15.702142715454102,15.762499809265137,15.790714263916016,15.898214340209961,15.765713691711426,15.891071319580078,16.127857208251953,16.061786651611328,16.097143173217773,16.046785354614258,15.896785736083984,15.659285545349121,15.778928756713867,15.674642562866211,15.628570556640625,15.435357093811035,15.569999694824219,15.358928680419922,15.428570747375488,15.420356750488281,15.10714340209961,14.8871431350708,14.76785659790039,14.376428604125977,14.379643440246582,14.21678638458252,14.063570976257324,14.161786079406738,14.614999771118164,14.946070671081543,15.028571128845215,14.907856941223145,14.823213577270508,15.083929061889648,15.026070594787598,15.260356903076172,15.232500076293945,15.265713691711426,15.364286422729492,15.368213653564453,15.420000076293945,15.176786422729492,15.225357055664062,14.963929176330566,15.732500076293945,15.660714149475098,15.749643325805664,15.992500305175781,16.190000534057617,16.161785125732422,16.309999465942383,16.519285202026367,16.766071319580078,16.616071701049805,16.606428146362305,16.464643478393555,16.230356216430664,16.691429138183594,17.484643936157227,17.803571701049805,17.782499313354492,17.940357208251953,18.13357162475586,17.895357131958008,17.941429138183594,17.96285629272461,17.893571853637695,17.963214874267578,17.449642181396484,17.532142639160156,17.560714721679688,17.400714874267578,17.44928550720215,17.81035614013672,17.688213348388672,17.79357147216797,18.077499389648438,17.665714263916016,16.703929901123047,16.881786346435547,16.60357093811035,16.075714111328125,16.261428833007812,16.595714569091797,16.867856979370117,16.693214416503906,17.522857666015625,17.467857360839844,17.197500228881836,17.364999771118164,17.241071701049805,17.02678680419922,17.427143096923828,17.484285354614258,17.2646427154541,17.25107192993164,17.41964340209961,17.176429748535156,17.37821388244629,17.48714256286621,17.600357055664062,17.715713500976562,17.809999465942383,17.896785736083984,18.01785659790039,18.17464256286621,18.6200008392334,18.56678581237793,18.748571395874023,18.99678611755371,18.784286499023438,18.924285888671875,18.452856063842773,18.746429443359375,18.667856216430664,18.572500228881836,18.8125,18.766071319580078,18.604286193847656,18.303213119506836,18.591428756713867,18.537500381469727,18.571786880493164,18.593929290771484,18.862857818603516,18.749643325805664,18.522499084472656,18.555356979370117,18.39285659790039,18.61214256286621,18.564285278320312,18.704999923706055,19.049999237060547,19.498571395874023,19.859643936157227,19.686786651611328,20.2257137298584,20.178571701049805,20.282142639160156,20.000713348388672,20.229642868041992,20.198213577270508,20.04857063293457,20.019285202026367,19.801071166992188,19.91071319580078,19.82107162475586,19.67035675048828,19.44499969482422,19.60785675048828,20.3603572845459,20.273929595947266,20.139286041259766,20.00321388244629,19.804285049438477,20.036428451538086,19.754642486572266,19.320714950561523,19.426071166992188,19.28714370727539,19.409286499023438,19.161428451538086,19.033571243286133,19.133214950561523,19.51392936706543,19.90571403503418,19.79464340209961,19.309642791748047,19.609643936157227,19.696786880493164,19.863571166992188,19.502500534057617,19.66071319580078,18.08928680419922,17.883928298950195,17.849285125732422,17.878570556640625,17.911785125732422,18.171070098876953,18.306785583496094,18.30392837524414,18.559999465942383,18.892499923706055,19.141429901123047,19.139999389648438,19.44392967224121,19.428213119506836,19.499643325805664,19.19178581237793,18.969642639160156,18.758928298950195,18.8410701751709,18.645000457763672,18.47678565979004,18.84535789489746,18.794286727905273,18.84857177734375,18.972856521606445,19.01285743713379,18.95535659790039,18.944286346435547,18.961429595947266,19.14607048034668,19.164642333984375,18.951786041259766,18.738929748535156,18.812143325805664,18.97857093811035,18.97357177734375,18.882143020629883,19.031070709228516,19.256786346435547,19.46392822265625,19.277856826782227,19.19499969482422,19.17357063293457,19.169286727905273,19.344642639160156,19.376785278320312,19.24250030517578,18.99357032775879,18.695356369018555,18.694286346435547,18.940000534057617,18.695714950561523,18.5575008392334,18.63142967224121,18.498571395874023,18.53607177734375,18.74785614013672,18.97035789489746,18.989286422729492,18.741071701049805,20.27750015258789,20.426429748535156,21.217500686645508,21.15464210510254,21.074642181396484,21.124286651611328,21.163570404052734,21.46285629272461,21.22892951965332,21.15464210510254,20.999643325805664,20.91214370727539,21.172500610351562,21.205713272094727,21.20964241027832,21.029285430908203,21.339643478393555,21.592500686645508,21.596786499023438,21.653928756713867,21.688213348388672,21.93321418762207,22.343929290771484,22.28607177734375,22.692142486572266,22.60714340209961,22.451786041259766,22.769285202026367,23.029285430908203,23.11964225769043,23.05607032775879,23.424999237060547,23.5625,23.46500015258789,23.072500228881836,22.81999969482422,23.049999237060547,23.020000457763672,23.045000076293945,22.96500015258789,22.727500915527344,22.707500457763672,22.56999969482422,22.59000015258789,22.725000381469727,22.9950008392334,23.232500076293945,23.3799991607666,23.3700008392334,23.50749969482422,23.99250030517578,23.837499618530273,23.84749984741211,23.760000228881836,23.80500030517578,24.112499237060547,23.829999923706055,23.69499969482422,23.272499084472656,23.607500076293945,23.485000610351562,23.68000030517578,24.297500610351562,24.25749969482422,24.417499542236328,24.7549991607666,24.594999313354492,24.537500381469727,23.899999618530273,24.032499313354492,23.897499084472656,23.780000686645508,23.739999771118164,23.6200008392334,23.684999465942383,23.997499465942383,23.99250030517578,24.309999465942383,24.375,24.4950008392334,24.790000915527344,25.13249969482422,25.142499923706055,25.145000457763672,25.329999923706055,25.385000228881836,25.22249984741211,25.532499313354492,25.5625,25.625,25.825000762939453,24.735000610351562,24.530000686645508,24.74250030517578,24.59000015258789,24.497499465942383,25.25,25.357500076293945,25.415000915527344,25.407499313354492,25.21500015258789,25.395000457763672,25.447500228881836,25.239999771118164,25.264999389648438,25.65999984741211,25.4375,24.467500686645508,25.1875,25.02750015258789,25.1875,24.795000076293945,24.975000381469727,24.905000686645508,24.905000686645508,24.6875,25.200000762939453,25.2549991607666,25.1825008392334,24.952499389648438,24.6875,24.385000228881836,24.065000534057617,24.417499542236328,24.940000534057617,25.61750030517578,25.747499465942383,26.207500457763672,26.30500030517578,26.27750015258789,26.684999465942383,26.834999084472656,26.7450008392334,27.0,27.350000381469727,27.149999618530273,27.21500015258789,27.174999237060547,27.252500534057617,27.207500457763672,27.424999237060547,27.8125,28.204999923706055,28.545000076293945,28.497499465942383,28.86750030517578,28.667499542236328,29.077499389648438,29.11750030517578,29.657499313354492,29.399999618530273,29.75,29.732500076293945,28.767499923706055,28.657499313354492,28.982500076293945,28.872499465942383,28.75,28.100000381469727,28.530000686645508,27.987499237060547,27.905000686645508,27.4325008392334,27.0575008392334,26.6875,27.352500915527344,28.162500381469727,27.94499969482422,28.235000610351562,28.135000228881836,28.002500534057617,28.497499465942383,28.477500915527344,28.1299991607666,27.594999313354492,27.332500457763672,26.5625,26.565000534057617,26.9375,27.97249984741211,28.002500534057617,27.3125,27.55500030517578,27.450000762939453,26.704999923706055,26.497499465942383,27.18000030517578,27.387500762939453,28.100000381469727,28.2450008392334,28.274999618530273,27.28499984741211,28.827499389648438,29.725000381469727,29.290000915527344,29.657499313354492,29.662500381469727,29.889999389648438,29.985000610351562,29.732500076293945,29.93000030517578,30.5049991607666,31.219999313354492,31.614999771118164,31.770000457763672,31.957500457763672,32.18000030517578,32.11249923706055,32.375,33.25,33.04249954223633,32.1974983215332,32.60499954223633,32.1150016784668,32.272499084472656,32.34000015258789,32.1349983215332,31.602500915527344,31.649999618530273,31.78499984741211,31.127500534057617,30.559999465942383,31.112499237060547,30.897499084472656,31.237499237060547,31.760000228881836,32.11750030517578,31.875,31.475000381469727,31.802499771118164,31.672500610351562,30.844999313354492,31.059999465942383,30.8125,31.592500686645508,31.107500076293945,31.0625,31.329999923706055,31.837499618530273,31.502500534057617,31.399999618530273,31.639999389648438,31.774999618530273,31.712499618530273,31.575000762939453,31.69499969482422,31.542499542236328,31.1875,31.899999618530273,31.727500915527344,32.154998779296875,32.41749954223633,32.56999969482422,33.162498474121094,32.63999938964844,32.15999984741211,31.287500381469727,32.23749923706055,32.17499923706055,31.450000762939453,31.252500534057617,31.315000534057617,31.905000686645508,31.579999923706055,31.467500686645508,31.502500534057617,32.23749923706055,32.192501068115234,32.54750061035156,32.51750183105469,32.51499938964844,32.84749984741211,33.1349983215332,32.404998779296875,33.0099983215332,32.94499969482422,32.56999969482422,32.6349983215332,32.4900016784668,32.529998779296875,32.34000015258789,32.162498474121094,31.950000762939453,31.854999542236328,32.220001220703125,32.147499084472656,31.792499542236328,31.729999542236328,31.899999618530273,31.825000762939453,31.969999313354492,31.649999618530273,31.90250015258789,31.75749969482422,32.02750015258789,31.875,31.6875,31.13249969482422,31.357500076293945,31.649999618530273,31.610000610351562,31.5,31.422500610351562,30.642499923706055,30.017499923706055,30.81999969482422,31.415000915527344,31.40250015258789,31.704999923706055,32.127498626708984,32.404998779296875,33.01750183105469,32.6875,31.30500030517578,31.290000915527344,31.125,30.6924991607666,30.844999313354492,30.747499465942383,30.592500686645508,30.325000762939453,29.610000610351562,28.65999984741211,28.850000381469727,28.782499313354492,28.8799991607666,29.93000030517578,28.372499465942383,28.809999465942383,28.787500381469727,28.989999771118164,29.290000915527344,29.125,28.752500534057617,28.162500381469727,26.440000534057617,25.780000686645508,25.934999465942383,27.422500610351562,28.229999542236328,28.322500228881836,28.190000534057617,26.93000030517578,28.084999084472656,27.592500686645508,27.3174991607666,28.077499389648438,27.537500381469727,28.142499923706055,28.552499771118164,28.827499389648438,29.06999969482422,29.102500915527344,28.479999542236328,28.362499237060547,28.802499771118164,28.350000381469727,28.579999923706055,28.75,28.677499771118164,28.110000610351562,27.264999389648438,27.575000762939453,27.395000457763672,27.594999313354492,27.69499969482422,27.827499389648438,27.69499969482422,27.375,28.030000686645508,27.899999618530273,27.947500228881836,27.552499771118164,27.96500015258789,27.760000228881836,27.9325008392334,28.4424991607666,28.440000534057617,28.875,29.770000457763672,28.81999969482422,28.637500762939453,29.8174991607666,30.13249969482422,29.875,30.295000076293945,30.642499923706055,30.5,30.229999542236328,30.264999389648438,30.142499923706055,29.1924991607666,29.02750015258789,28.93000030517578,28.084999084472656,28.545000076293945,28.422500610351562,29.322500228881836,29.69499969482422,29.825000762939453,29.4375,29.719999313354492,29.50749969482422,29.452499389648438,29.575000762939453,29.334999084472656,29.06999969482422,28.799999237060547,29.75749969482422,29.56999969482422,29.5575008392334,28.905000686645508,29.042499542236328,28.295000076293945,28.1200008392334,27.622499465942383,27.834999084472656,27.2450008392334,26.50749969482422,26.832500457763672,26.8075008392334,27.15250015258789,27.00749969482422,26.704999923706055,27.184999465942383,26.829999923706055,26.315000534057617,26.337499618530273,25.677499771118164,25.174999237060547,24.112499237060547,24.239999771118164,24.63249969482422,24.989999771118164,24.34749984741211,24.8799991607666,24.282499313354492,24.165000915527344,24.197500228881836,24.075000762939453,25.354999542236328,24.860000610351562,24.997499465942383,23.354999542236328,23.522499084472656,24.334999084472656,24.107500076293945,23.6200008392334,24.087499618530273,24.149999618530273,23.5049991607666,23.752500534057617,23.747499465942383,23.5674991607666,23.424999237060547,23.497499465942383,24.15999984741211,24.530000686645508,24.065000534057617,24.010000228881836,24.219999313354492,23.672500610351562,24.024999618530273,24.190000534057617,24.227500915527344,24.172500610351562,25.13249969482422,25.1875,25.375,25.752500534057617,25.467500686645508,25.25749969482422,25.280000686645508,25.292499542236328,25.565000534057617,25.6299991607666,26.145000457763672,26.49250030517578,26.450000762939453,26.479999542236328,26.477500915527344,26.68000030517578,26.532499313354492,26.417499542236328,26.297500610351562,26.920000076293945,27.389999389648438,27.247499465942383,27.497499465942383,27.780000686645508,27.452499389648438,27.739999771118164,27.135000228881836,27.165000915527344,27.2549991607666,27.610000610351562,28.010000228881836,28.024999618530273,27.462499618530273,26.8700008392334,26.727500915527344,26.782499313354492,26.49250030517578,26.420000076293945,26.270000457763672,26.087499618530273,24.454999923706055,23.707500457763672,23.434999465942383,23.40999984741211,23.795000076293945,23.547500610351562,23.309999465942383,23.18000030517578,23.197500228881836,23.354999542236328,23.127500534057617,22.584999084472656,22.6299991607666,23.469999313354492,23.372499465942383,23.639999389648438,23.549999237060547,23.80500030517578,24.107500076293945,24.475000381469727,24.905000686645508,25.102500915527344,25.087499618530273,24.96500015258789,24.614999771118164,24.43000030517578,24.479999542236328,24.657499313354492,24.75749969482422,24.735000610351562,24.912500381469727,24.707500457763672,24.334999084472656,24.364999771118164,24.28499984741211,24.387500762939453,23.832500457763672,23.774999618530273,23.977500915527344,23.887500762939453,24.024999618530273,23.350000381469727,23.010000228881836,23.397499084472656,23.600000381469727,23.899999618530273,23.97249984741211,23.747499465942383,23.88249969482422,23.985000610351562,24.170000076293945,24.2450008392334,24.354999542236328,24.217500686645508,24.697500228881836,24.69499969482422,24.957500457763672,24.967500686645508,24.989999771118164,24.857500076293945,24.665000915527344,24.334999084472656,24.167499542236328,25.737499237060547,26.084999084472656,26.052499771118164,26.512500762939453,26.1200008392334,26.447500228881836,26.467500686645508,26.8700008392334,27.092500686645508,27.202499389648438,27.0,26.982500076293945,27.045000076293945,27.3700008392334,27.344999313354492,27.30500030517578,27.270000457763672,27.34000015258789,27.127500534057617,27.212499618530273,27.00749969482422,26.892499923706055,26.735000610351562,26.704999923706055,26.5,26.524999618530273,26.6825008392334,26.9325008392334,26.924999237060547,27.09000015258789,26.3799991607666,25.782499313354492,26.360000610351562,26.987499237060547,27.9424991607666,28.892499923706055,28.729999542236328,28.395000457763672,28.392499923706055,28.387500762939453,28.655000686645508,28.177499771118164,28.219999313354492,28.272499084472656,28.487499237060547,28.045000076293945,28.262500762939453,28.1299991607666,28.25,28.262500762939453,28.47249984741211,28.514999389648438,29.012500762939453,29.075000762939453,29.334999084472656,29.2450008392334,29.407499313354492,29.387500762939453,29.36750030517578,29.280000686645508,29.264999389648438,29.149999618530273,29.412500381469727,29.5625,28.897499084472656,28.6200008392334,28.43000030517578,28.385000228881836,27.872499465942383,27.897499084472656,27.457500457763672,27.209999084472656,27.602500915527344,27.764999389648438,27.719999313354492,26.947500228881836,27.107500076293945,26.427499771118164,26.77750015258789,27.497499465942383,27.487499237060547,27.514999389648438,27.9325008392334,27.950000762939453,27.8075008392334,27.947500228881836,27.892499923706055,27.864999771118164,27.6299991607666,27.372499465942383,27.475000381469727,27.27750015258789,27.487499237060547,27.75749969482422,28.030000686645508,28.487499237060547,28.325000762939453,28.797500610351562,28.797500610351562,28.954999923706055,28.99250030517578,29.15999984741211,29.237499237060547,29.264999389648438,29.072500228881836,29.1299991607666,29.315000534057617,29.190000534057617,29.1825008392334,28.954999923706055,29.037500381469727,29.0049991607666,29.15250015258789,29.477500915527344,29.747499465942383,29.77750015258789,29.9375,29.8125,29.760000228881836,30.0,29.997499465942383,29.94499969482422,30.0,30.020000457763672,29.99250030517578,30.469999313354492,30.485000610351562,30.487499237060547,30.407499313354492,30.337499618530273,32.1875,32.13249969482422,32.27000045776367,32.5724983215332,32.88249969482422,33.0099983215332,33.10499954223633,33.029998779296875,33.3224983215332,33.755001068115234,33.877498626708984,33.837501525878906,33.93000030517578,34.17499923706055,34.27750015258789,34.13249969482422,34.165000915527344,34.23249816894531,34.247501373291016,34.9474983215332,34.7400016784668,34.94499969482422,34.834999084472656,34.880001068115234,34.75,34.66999816894531,34.78499984741211,34.79999923706055,34.747501373291016,35.1150016784668,35.17250061035156,34.997501373291016,35.3650016784668,34.959999084472656,35.35499954223633,35.22999954223633,35.15999984741211,35.220001220703125,35.95000076293945,36.029998779296875,35.98249816894531,35.915000915527344,35.92499923706055,36.192501068115234,36.005001068115234,35.915000915527344,35.834999084472656,35.79249954223633,35.407501220703125,35.45000076293945,35.26250076293945,35.45750045776367,35.29999923706055,35.16999816894531,35.61000061035156,35.567501068115234,35.90999984741211,36.13249969482422,35.91999816894531,35.9474983215332,35.912498474121094,36.64500045776367,36.877498626708984,36.76499938964844,36.63249969482422,37.2400016784668,38.252498626708984,38.497501373291016,38.314998626708984,38.48749923706055,39.025001525878906,38.92499923706055,38.86750030517578,37.5625,38.1349983215332,38.26499938964844,38.497501373291016,38.45000076293945,38.334999084472656,38.467498779296875,38.40250015258789,38.41749954223633,38.189998626708984,38.29499816894531,38.86249923706055,38.48249816894531,38.61249923706055,38.842498779296875,38.747501373291016,37.244998931884766,36.35499954223633,36.647499084472656,36.290000915527344,36.0724983215332,35.567501068115234,36.584999084472656,36.252498626708984,36.467498779296875,36.407501220703125,36.56999969482422,36.45500183105469,35.932498931884766,36.45750045776367,35.91999816894531,36.005001068115234,35.875,36.022499084472656,35.682498931884766,36.04499816894531,36.26499938964844,36.38249969482422,36.435001373291016,36.942501068115234,37.2599983215332,37.38999938964844,37.52000045776367,37.755001068115234,37.584999084472656,37.567501068115234,38.022499084472656,38.185001373291016,38.3650016784668,37.63999938964844,37.375,37.182498931884766,37.51250076293945,39.28499984741211,38.89250183105469,39.09749984741211,39.70249938964844,40.02000045776367,40.26499938964844,38.83000183105469,39.369998931884766,39.962501525878906,40.400001525878906,40.23749923706055,39.46500015258789,39.375,39.3025016784668,39.94499969482422,39.994998931884766,39.817501068115234,39.96500015258789,40.36750030517578,40.727500915527344,40.837501525878906,41.0,41.01250076293945,40.52000045776367,40.477500915527344,40.314998626708984,39.657501220703125,40.375,40.21500015258789,39.912498474121094,39.56999969482422,39.970001220703125,39.66749954223633,39.682498931884766,39.01750183105469,38.34749984741211,37.97249984741211,37.63750076293945,38.28499984741211,38.557498931884766,38.31999969482422,38.529998779296875,38.45249938964844,38.619998931884766,38.369998931884766,38.84749984741211,38.82500076293945,38.959999084472656,38.974998474121094,39.13750076293945,39.0,39.247501373291016,39.970001220703125,40.11750030517578,39.939998626708984,38.994998931884766,39.0625,39.04249954223633,39.275001525878906,39.102500915527344,39.352500915527344,40.76250076293945,41.68000030517578,42.2599983215332,41.72249984741211,42.02750015258789,43.125,43.5625,43.70249938964844,44.060001373291016,43.970001220703125,43.66749954223633,43.49250030517578,42.834999084472656,42.27000045776367,42.775001525878906,42.537498474121094,42.494998931884766,43.28499984741211,43.7400016784668,43.74250030517578,43.522499084472656,43.26750183105469,42.369998931884766,42.962501525878906,42.76250076293945,42.45000076293945,42.40999984741211,42.252498626708984,42.33000183105469,42.342498779296875,43.16749954223633,42.92499923706055,43.067501068115234,43.05500030517578,43.49250030517578,44.10499954223633,43.6349983215332,43.587501525878906,43.752498626708984,43.752498626708984,42.64250183105469,42.650001525878906,42.77000045776367,42.307498931884766,43.064998626708984,43.057498931884766,43.25749969482422,43.75,43.587501525878906,43.58250045776367,43.5724983215332,43.81999969482422,44.272499084472656,44.04750061035156,44.775001525878906,44.814998626708984,44.6150016784668,44.25,44.2599983215332,43.55500030517578,42.77750015258789,42.877498626708984,41.9900016784668,41.74250030517578,41.85749816894531,41.94499969482422,40.125,39.122501373291016,40.75749969482422,39.8849983215332,38.787498474121094,39.102500915527344,40.6775016784668,41.084999084472656,41.842498779296875,43.247501373291016,43.10749816894531,42.962501525878906,42.76750183105469,43.125,43.875,44.74250030517578,44.59749984741211,44.529998779296875,43.75,44.0525016784668,44.20500183105469,44.16749954223633,43.75749969482422,44.23500061035156,44.994998931884766,45.43000030517578,44.99250030517578,44.61000061035156,44.662498474121094,44.505001068115234,43.82500076293945,43.810001373291016,42.817501068115234,42.212501525878906,41.23500061035156,43.192501068115234,42.084999084472656,41.619998931884766,41.94499969482422,41.66999816894531,42.09749984741211,42.90250015258789,43.20000076293945,42.095001220703125,42.51250076293945,43.3125,43.11000061035156,43.53499984741211,43.682498931884766,43.95500183105469,44.560001373291016,44.459999084472656,43.20000076293945,41.43000030517578,41.310001373291016,40.73500061035156,40.912498474121094,41.05500030517578,40.58000183105469,41.314998626708984,42.275001525878906,44.14250183105469,44.22249984741211,45.95750045776367,46.290000915527344,46.51250076293945,46.84000015258789,47.5099983215332,47.147499084472656,47.037498474121094,46.61000061035156,47.04499816894531,46.747501373291016,46.57749938964844,46.907501220703125,46.790000915527344,47.09000015258789,47.037498474121094,47.14500045776367,46.974998474121094,46.875,46.717498779296875,47.560001373291016,47.95750045776367,48.32749938964844,48.494998931884766,48.3650016784668,47.92499923706055,47.807498931884766,48.06999969482422,47.67499923706055,47.70000076293945,47.209999084472656,47.185001373291016,46.42250061035156,46.625,46.3650016784668,46.22999954223633,45.54249954223633,46.10749816894531,46.040000915527344,46.375,46.27750015258789,46.79499816894531,45.97999954223633,46.349998474121094,46.99250030517578,47.64500045776367,47.587501525878906,46.970001220703125,47.75749969482422,47.83250045776367,47.727500915527344,47.86249923706055,47.599998474121094,47.970001220703125,47.86000061035156,47.90250015258789,48.25,48.70500183105469,48.5525016784668,47.744998931884766,47.477500915527344,47.5724983215332,50.375,51.84749984741211,51.997501373291016,52.26750183105469,51.77750015258789,51.8125,52.220001220703125,51.88249969482422,52.217498779296875,52.4375,52.560001373291016,53.33000183105469,54.39500045776367,53.8650016784668,53.7599983215332,53.76250076293945,53.872501373291016,54.040000915527344,54.48500061035156,54.92499923706055,55.744998931884766,56.25749969482422,56.907501220703125,57.09000015258789,56.717498779296875,55.775001525878906,55.32500076293945,54.58250045776367,55.962501525878906,55.26750183105469,56.602500915527344,55.959999084472656,54.470001220703125,54.560001373291016,54.592498779296875,55.00749969482422,54.415000915527344,55.1974983215332,55.54750061035156,55.10499954223633,56.23749923706055,56.435001373291016,56.814998626708984,57.31999969482422,58.01750183105469,56.997501373291016,56.0724983215332,55.942501068115234,56.717498779296875,54.09000015258789,53.61249923706055,55.52750015258789,54.34000015258789,55.537498474121094,55.29750061035156,54.005001068115234,54.82749938964844,55.162498474121094,55.682498931884766,53.772499084472656,54.95000076293945,54.07500076293945,53.060001373291016,53.32500076293945,54.71500015258789,55.55500030517578,51.869998931884766,50.397499084472656,50.942501068115234,52.48749923706055,52.122501373291016,51.11750030517578,48.54249954223633,48.057498931884766,46.70000076293945,47.852500915527344,48.38249969482422,46.46500015258789,44.244998931884766,44.19499969482422,43.0724983215332,43.654998779296875,43.560001373291016,45.23500061035156,44.88750076293945,44.64500045776367,46.20500183105469,44.17250061035156,43.68000030517578,42.122501373291016,42.400001525878906,42.157501220703125,42.275001525878906,42.73749923706055,41.369998931884766,40.98500061035156,41.51750183105469,40.22249984741211,39.20750045776367,37.682498931884766,36.70750045776367,39.29249954223633,39.037498474121094,39.057498931884766,39.435001373291016,39.47999954223633,35.54750061035156,37.064998626708984,36.98249816894531,37.6875,38.32749938964844,38.45000076293945,38.0724983215332,37.5,38.26750183105469,38.73500061035156,38.96500015258789,39.20500183105469,38.32500076293945,38.47999954223633,38.17499923706055,39.439998626708984,39.07500076293945,38.66999816894531,41.3125,41.61000061035156,41.630001068115234,42.8125,43.54499816894531,43.560001373291016,42.73500061035156,42.602500915527344,42.35749816894531,42.72249984741211,42.54499816894531,42.70000076293945,42.60499954223633,42.73249816894531,43.00749969482422,42.76499938964844,43.24250030517578,43.557498931884766,43.58250045776367,43.717498779296875,43.287498474121094,43.74250030517578,43.962501525878906,43.88249969482422,43.630001068115234,43.125,43.227500915527344,44.724998474121094,45.227500915527344,45.4275016784668,45.932498931884766,46.529998779296875,47.005001068115234,46.63249969482422,47.040000915527344,48.772499084472656,47.76250076293945,47.185001373291016,46.6974983215332,47.11750030517578,47.18000030517578,47.48749923706055,47.810001373291016,48.505001068115234,48.837501525878906,48.92250061035156,49.25,50.025001525878906,49.875,50.154998779296875,49.73749923706055,49.717498779296875,49.807498931884766,49.8125,50.782501220703125,50.96500015258789,51.13249969482422,51.869998931884766,51.790000915527344,51.31999969482422,51.07500076293945,51.15250015258789,50.16749954223633,52.630001068115234,52.287498474121094,52.9375,52.119998931884766,50.71500015258789,50.724998474121094,50.18000030517578,49.29499816894531,46.43000030517578,47.165000915527344,47.72999954223633,47.52000045776367,47.25,45.772499084472656,46.650001525878906,45.69499969482422,44.915000915527344,44.74250030517578,44.557498931884766,44.345001220703125,44.57500076293945,43.76750183105469,43.32500076293945,44.90999984741211,45.6349983215332,46.30500030517578,47.537498474121094,48.14500045776367,48.70249938964844,48.54750061035156,48.537498474121094,48.185001373291016,48.47249984741211,49.61249923706055,49.467498779296875,49.8650016784668,49.69499969482422,49.64500045776367,48.89250183105469,49.95000076293945,49.935001373291016,49.47999954223633,50.38750076293945,50.682498931884766,51.102500915527344,51.057498931884766,50.005001068115234,50.310001373291016,50.807498931884766,50.4375,50.82500076293945,51.3025016784668,51.125,50.837501525878906,51.415000915527344,50.647499084472656,51.80500030517578,52.209999084472656,52.16749954223633,51.755001068115234,51.935001373291016,52.41999816894531,52.19499969482422,53.2599983215332,52.10749816894531,51.005001068115234,48.334999084472656,49.25,49.7599983215332,50.85749816894531,50.247501373291016,50.119998931884766,52.24250030517578,50.6875,50.435001373291016,51.625,52.587501525878906,52.59000015258789,53.15999984741211,53.1150016784668,50.65999984741211,51.622501373291016,51.040000915527344,51.38249969482422,52.252498626708984,52.185001373291016,51.42499923706055,52.29750061035156,53.31999969482422,53.314998626708984,53.54249954223633,54.17499923706055,55.897499084472656,55.772499084472656,54.6875,54.974998474121094,55.17499923706055,55.692501068115234,55.2400016784668,54.432498931884766,54.68000030517578,54.41999816894531,55.25749969482422,54.97249984741211,54.70500183105469,55.99250030517578,56.147499084472656,54.7400016784668,55.20500183105469,56.752498626708984,56.76499938964844,56.099998474121094,56.75749969482422,57.522499084472656,59.0525016784668,58.967498779296875,58.83000183105469,58.592498779296875,58.81999969482422,59.102500915527344,60.127498626708984,59.9900016784668,60.79499816894531,60.89500045776367,61.64500045776367,62.26250076293945,60.8224983215332,60.814998626708984,62.189998626708984,63.95500183105469,64.375,64.28250122070312,64.30999755859375,64.85749816894531,65.03500366210938,65.55000305175781,65.48999786376953,66.11750030517578,65.66000366210938,66.44000244140625,66.7750015258789,66.57250213623047,65.79750061035156,65.50250244140625,65.44499969482422,66.59249877929688,66.07250213623047,66.95999908447266,66.8125,66.04000091552734,64.86250305175781,65.43499755859375,66.3949966430664,67.67749786376953,66.7300033569336,67.12000274658203,67.69249725341797,67.86499786376953,68.7874984741211,69.96499633789062,70.10250091552734,69.93499755859375,70.00499725341797,69.86000061035156,71.0,71.06749725341797,72.47750091552734,72.44999694824219,72.87999725341797,73.4124984741211,75.0875015258789,74.35749816894531,74.94999694824219,74.59750366210938,75.79750061035156,77.40750122070312,77.5824966430664,79.23999786376953,78.16999816894531,77.83499908447266,78.80999755859375,79.68250274658203,79.14250183105469,79.42500305175781,79.80750274658203,79.57749938964844,77.23750305175781,79.42250061035156,81.08499908447266,80.96749877929688,77.37750244140625,77.16500091552734,79.7125015258789,80.36250305175781,81.30249786376953,80.00749969482422,80.38749694824219,79.90249633789062,81.80000305175781,81.21749877929688,81.23750305175781,79.75,80.90499877929688,80.07499694824219,78.26249694824219,74.54499816894531,72.0199966430664,73.1624984741211,68.37999725341797,68.33999633789062,74.70249938964844,72.33000183105469,75.68499755859375,73.2300033569336,72.25749969482422,66.5425033569336,71.33499908447266,68.85749816894531,62.057498931884766,69.49250030517578,60.5525016784668,63.21500015258789,61.66749954223633,61.19499969482422,57.310001373291016,56.092498779296875,61.720001220703125,61.380001068115234,64.61000061035156,61.935001373291016,63.70249938964844,63.5724983215332,60.227500915527344,61.23249816894531,60.352500915527344,65.61750030517578,64.85749816894531,66.51750183105469,66.99749755859375,68.3125,71.76249694824219,71.10749816894531,71.67250061035156,70.69999694824219,69.23249816894531,67.09249877929688,69.0250015258789,68.75749969482422,70.74250030517578,70.7925033569336,69.6449966430664,71.93250274658203,73.44999694824219,72.26750183105469,73.29000091552734,74.38999938964844,75.15750122070312,75.93499755859375,77.53250122070312,78.75250244140625,77.85250091552734,76.9124984741211,77.38500213623047,76.92749786376953,78.73999786376953,78.28500366210938,79.80750274658203,79.2125015258789,79.72250366210938,79.18250274658203,79.52749633789062,79.5625,79.48500061035156,80.4625015258789,80.83499908447266,81.27999877929688,80.58000183105469,82.875,83.36499786376953,85.99749755859375,88.20999908447266,83.9749984741211,84.69999694824219,85.74749755859375,88.0199966430664,87.89749908447266,87.93250274658203],\"y\":[4.900713920593262,4.869999885559082,4.947143077850342,5.083570957183838,5.081070899963379,5.24571418762207,5.268570899963379,5.419642925262451,5.461071014404297,5.411070823669434,5.5978569984436035,5.6364288330078125,5.713929176330566,5.7178568840026855,5.714285850524902,5.715356826782227,5.813929080963135,5.835357189178467,5.943929195404053,5.912499904632568,5.896786212921143,5.853929042816162,5.911070823669434,5.882856845855713,5.815357208251953,5.903929233551025,6.014999866485596,5.9564290046691895,5.699643135070801,5.857142925262451,5.878571033477783,5.940357208251953,6.0435709953308105,6.0378570556640625,6.050000190734863,5.978929042816162,6.051785945892334,6.073214054107666,6.007500171661377,5.903571128845215,5.899285793304443,5.948214054107666,6.082499980926514,6.1760711669921875,6.112143039703369,6.1628570556640625,6.148571014404297,6.204286098480225,6.255713939666748,6.495357036590576,6.591071128845215,6.6078572273254395,6.572143077850342,6.588571071624756,6.625,6.565000057220459,6.513214111328125,6.648213863372803,6.62071418762207,6.619643211364746,6.459286212921143,6.603570938110352,6.643570899963379,6.786070823669434,6.794642925262451,6.759643077850342,6.802499771118164,6.814642906188965,6.786428928375244,6.831786155700684,6.805714130401611,6.716071128845215,6.78071403503418,7.098570823669434,7.318571090698242,7.32857084274292,7.283570766448975,7.231429100036621,7.048929214477539,6.871428966522217,7.012499809265137,6.732142925262451,6.76107120513916,6.7410712242126465,6.814642906188965,6.929643154144287,6.940713882446289,7.195000171661377,7.24928617477417,7.2589287757873535,7.213929176330566,7.301785945892334,7.379642963409424,7.392857074737549,7.355713844299316,7.161070823669434,7.139999866485596,7.3528571128845215,7.30142879486084,7.292500019073486,7.163928985595703,7.13964319229126,7.034643173217773,7.008213996887207,7.0171427726745605,6.904285907745361,6.748213768005371,6.781071186065674,7.064286231994629,7.01535701751709,6.952499866485596,7.034999847412109,6.934642791748047,6.965356826782227,6.852142810821533,6.979642868041992,7.0796427726745605,7.15571403503418,7.2178568840026855,7.465713977813721,7.557499885559082,7.4678568840026855,7.558570861816406,7.526071071624756,7.643214225769043,7.656428813934326,7.534643173217773,7.520713806152344,7.570713996887207,7.503929138183594,7.4185709953308105,7.523213863372803,7.479642868041992,7.354642868041992,7.679999828338623,7.56178617477417,7.431070804595947,7.0625,7.252500057220459,7.355000019073486,7.424285888671875,7.117499828338623,6.859285831451416,6.9546427726745605,6.994999885559082,7.115356922149658,6.85892915725708,6.980713844299316,6.932857036590576,7.006785869598389,6.968571186065674,7.0953569412231445,7.156428813934326,7.264286041259766,7.23392915725708,7.247499942779541,7.202499866485596,7.1578569412231445,7.0378570556640625,7.166429042816162,7.214285850524902,7.307857036590576,7.463929176330566,7.458929061889648,7.476070880889893,7.525356769561768,7.819643020629883,7.824285984039307,7.965000152587891,8.029999732971191,8.053570747375488,8.092857360839844,7.994286060333252,8.016071319580078,8.00428581237793,8.023214340209961,7.9375,8.026785850524902,8.15571403503418,8.19178581237793,8.094642639160156,8.246429443359375,8.299642562866211,8.423213958740234,8.39285659790039,8.427499771118164,8.517499923706055,8.555000305175781,8.592857360839844,8.569643020629883,8.635356903076172,8.653214454650879,8.65821361541748,8.774642944335938,8.890000343322754,8.835714340209961,8.823928833007812,8.735357284545898,9.257857322692871,9.516785621643066,9.672499656677246,9.625,9.35857105255127,9.342857360839844,9.59428596496582,9.3246431350708,9.512499809265137,9.238571166992188,9.142499923706055,8.79464340209961,8.42357063293457,9.071070671081543,9.161429405212402,9.360357284545898,9.227143287658691,9.0649995803833,9.079285621643066,9.012857437133789,8.869285583496094,8.491429328918457,8.65428638458252,8.812856674194336,8.757857322692871,8.71821403503418,9.048213958740234,9.174285888671875,9.315357208251953,9.426786422729492,9.397143363952637,9.14142894744873,8.962142944335938,8.904643058776855,8.685713768005371,8.946785926818848,9.053929328918457,9.081428527832031,9.274642944335938,9.54464340209961,9.709643363952637,9.788213729858398,9.64892864227295,9.780357360839844,9.677499771118164,9.60714340209961,9.524999618530273,9.58214282989502,9.14892864227295,8.983214378356934,8.874285697937012,8.819286346435547,8.879643440246582,9.238213539123535,9.217499732971191,9.272143363952637,9.188928604125977,8.992856979370117,9.026070594787598,8.98035717010498,8.925000190734863,8.770713806152344,8.996070861816406,9.079999923706055,9.250714302062988,9.283571243286133,9.260000228881836,9.431428909301758,9.319999694824219,9.21821403503418,9.1875,9.351785659790039,9.354642868041992,9.392143249511719,9.346428871154785,9.288928985595703,9.348214149475098,9.264642715454102,8.935357093811035,8.992500305175781,8.896429061889648,8.84428596496582,8.998929023742676,9.038213729858398,8.924285888671875,8.915714263916016,8.778571128845215,8.568928718566895,8.674642562866211,8.581428527832031,8.62928581237793,8.660714149475098,8.682143211364746,8.940357208251953,9.006071090698242,9.241786003112793,9.207500457763672,9.390000343322754,9.395357131958008,9.407500267028809,9.537142753601074,9.57357120513916,9.650713920593262,9.8774995803833,9.834643363952637,10.115357398986816,10.134642601013184,10.276785850524902,10.318571090698242,10.4399995803833,10.398571014404297,10.244999885559082,10.263214111328125,10.133929252624512,10.09000015258789,9.95142936706543,10.319286346435547,10.328213691711426,10.329285621643066,10.5024995803833,10.54857063293457,10.662142753601074,10.71928596496582,10.796786308288574,11.240714073181152,11.35714340209961,11.053214073181152,11.090356826782227,11.054286003112793,10.981071472167969,11.029999732971191,11.001786231994629,10.993928909301758,10.901429176330566,10.749285697937012,10.863571166992188,11.04857063293457,11.171428680419922,11.366786003112793,11.326070785522461,11.37928581237793,11.28857135772705,11.358214378356934,11.308929443359375,11.001070976257324,10.965714454650879,10.771071434020996,10.73214340209961,11.01535701751709,10.954643249511719,11.191429138183594,11.026070594787598,11.242856979370117,11.25,11.31678581237793,11.112500190734863,11.300000190734863,11.362500190734863,11.337142944335938,11.433929443359375,11.364643096923828,11.464642524719238,11.420000076293945,11.44857120513916,11.488213539123535,11.438928604125977,11.441429138183594,11.473214149475098,11.450357437133789,11.507499694824219,11.578571319580078,11.6128568649292,11.557143211364746,11.59571361541748,11.623929023742676,11.617500305175781,11.559286117553711,11.520000457763672,11.770357131958008,11.831786155700684,11.928570747375488,11.918929100036621,12.00428581237793,12.23035717010498,12.20142936706543,12.300713539123535,12.34571361541748,12.445713996887207,12.166070938110352,12.101428985595703,11.881428718566895,11.668571472167969,12.051786422729492,12.192856788635254,12.280357360839844,12.257499694824219,12.003570556640625,12.118571281433105,12.322500228881836,12.29714298248291,12.265713691711426,12.375,12.567143440246582,12.685713768005371,12.791428565979004,12.662142753601074,12.744643211364746,12.82785701751709,12.853570938110352,12.968929290771484,12.796428680419922,12.520000457763672,12.09321403503418,12.236429214477539,12.24571418762207,12.434286117553711,12.614643096923828,12.475357055664062,12.575714111328125,12.841428756713867,12.85714340209961,12.691429138183594,12.705714225769043,12.588213920593262,12.381071090698242,12.571070671081543,12.627142906188965,12.336786270141602,11.786070823669434,11.95142936706543,11.809642791748047,12.117856979370117,12.185713768005371,12.11392879486084,12.320357322692871,12.555000305175781,12.515713691711426,12.534285545349121,12.451070785522461,12.446785926818848,12.305713653564453,12.185357093811035,12.103214263916016,12.072856903076172,12.074286460876465,11.966428756713867,11.814286231994629,11.871429443359375,12.004643440246582,11.872142791748047,11.694999694824219,11.851785659790039,12.066429138183594,12.228928565979004,12.524999618530273,12.607500076293945,12.515000343322754,12.505356788635254,12.383929252624512,12.504643440246582,12.367142677307129,12.435713768005371,12.48464298248291,12.383929252624512,12.380714416503906,12.414285659790039,12.48035717010498,12.401070594787598,12.3774995803833,12.160714149475098,11.903571128845215,12.005000114440918,12.138214111328125,12.161786079406738,11.972143173217773,11.942856788635254,11.86392879486084,12.027856826782227,11.964285850524902,12.0503568649292,12.422499656677246,12.339642524719238,12.360713958740234,12.265713691711426,12.072856903076172,11.85857105255127,11.865714073181152,11.838929176330566,11.639286041259766,11.664285659790039,11.872857093811035,11.66964340209961,11.6128568649292,11.437856674194336,11.261428833007812,11.617856979370117,11.521785736083984,11.829643249511719,11.655357360839844,11.85857105255127,11.973570823669434,11.930000305175781,11.988213539123535,12.259285926818848,12.479642868041992,12.562856674194336,12.757143020629883,12.846785545349121,12.64285659790039,12.633929252624512,12.786429405212402,12.77750015258789,13.032856941223145,13.350000381469727,13.458929061889648,13.817856788635254,13.831786155700684,14.046428680419922,14.23214340209961,14.407500267028809,14.021071434020996,13.993571281433105,13.945713996887207,14.16964340209961,13.889642715454102,14.020357131958008,13.477499961853027,13.343570709228516,12.614643096923828,13.357500076293945,12.98892879486084,13.346428871154785,13.463929176330566,13.693214416503906,13.588570594787598,13.587142944335938,13.073213577270508,12.715356826782227,12.729999542236328,13.342857360839844,13.4350004196167,13.347143173217773,13.699286460876465,13.927499771118164,13.928214073181152,13.743928909301758,13.608214378356934,13.358928680419922,13.562143325805664,13.711786270141602,13.71928596496582,13.481429100036621,13.569286346435547,13.736429214477539,13.903571128845215,14.034285545349121,14.303570747375488,14.701070785522461,14.766071319580078,14.71928596496582,14.350713729858398,14.439286231994629,14.39892864227295,14.259285926818848,14.178929328918457,13.948928833007812,13.618571281433105,13.378570556640625,13.303570747375488,13.508929252624512,13.477499961853027,13.20714282989502,13.88607120513916,14.29607105255127,14.36392879486084,14.586786270141602,15.071429252624512,14.999643325805664,15.079999923706055,14.236429214477539,14.118213653564453,14.031070709228516,14.491786003112793,14.206070899963379,14.307143211364746,14.453213691711426,14.462499618530273,14.456428527832031,14.161070823669434,14.193214416503906,14.395357131958008,14.294285774230957,14.276070594787598,14.508213996887207,14.117142677307129,13.757857322692871,13.736429214477539,13.545000076293945,13.886786460876465,13.741786003112793,13.478928565979004,13.390713691711426,13.178929328918457,13.446785926818848,13.106785774230957,12.98464298248291,13.432856559753418,13.328571319580078,13.649999618530273,13.854642868041992,13.91785717010498,14.036070823669434,13.962499618530273,13.896071434020996,13.952142715454102,14.057856559753418,13.994285583496094,13.88607120513916,13.578213691711426,13.533571243286133,13.607856750488281,13.650357246398926,14.141071319580078,14.158928871154785,14.233928680419922,14.404643058776855,14.518928527832031,14.380000114440918,14.468570709228516,14.464285850524902,14.686785697937012,14.765713691711426,14.929642677307129,15.085714340209961,15.061785697937012,15.115714073181152,15.091071128845215,15.049642562866211,14.993213653564453,15.16785717010498,15.325357437133789,15.276785850524902,15.010713577270508,15.264642715454102,15.014642715454102,15.952142715454102,15.879643440246582,15.974286079406738,16.17892837524414,16.3028564453125,16.292499542236328,16.25428581237793,16.417142868041992,16.570356369018555,16.743928909301758,17.0242862701416,17.61321449279785,17.622142791748047,17.950000762939453,18.19499969482422,17.773929595947266,17.936071395874023,17.932857513427734,18.387500762939453,18.322856903076172,18.4424991607666,18.657499313354492,18.777143478393555,19.12178611755371,19.37285614013672,19.445356369018555,19.470714569091797,19.04142951965332,18.937856674194336,18.953214645385742,19.356786727905273,19.47035789489746,19.71428680419922,20.28928565979004,21.056428909301758,20.912857055664062,20.9132137298584,21.467857360839844,21.641429901123047,21.51785659790039,21.405000686645508,21.287500381469727,21.6778564453125,21.945714950561523,22.057857513427734,21.78071403503418,21.412500381469727,22.093929290771484,22.4757137298584,22.296785354614258,22.63142967224121,22.72249984741211,22.444286346435547,22.364286422729492,22.241785049438477,21.6153564453125,20.718929290771484,21.774999618530273,21.726428985595703,20.979999542236328,20.463571548461914,20.417856216430664,20.010000228881836,21.78571319580078,21.703571319580078,21.53571319580078,20.856428146362305,20.79035758972168,20.9278564453125,20.779285430908203,20.1875,20.338571548461914,20.292142868041992,20.327856063842773,20.375713348388672,20.239643096923828,19.93642807006836,19.756071090698242,19.502857208251953,18.932857513427734,18.942142486572266,20.045713424682617,19.891786575317383,20.37714385986328,20.190000534057617,20.081785202026367,20.438213348388672,20.684642791748047,20.633214950561523,20.035356521606445,20.153213500976562,20.101070404052734,20.409286499023438,20.41857147216797,20.7257137298584,20.398929595947266,20.5771427154541,20.43428611755371,20.411785125732422,20.504642486572266,20.920713424682617,20.97892951965332,20.919286727905273,20.631071090698242,20.78928565979004,20.3846435546875,20.429643630981445,20.51785659790039,20.323213577270508,20.85714340209961,21.161428451538086,21.407499313354492,21.783571243286133,21.63857078552246,21.92464256286621,21.721786499023438,21.5867862701416,21.389286041259766,21.60607147216797,21.675357818603516,21.676429748535156,21.652143478393555,21.940000534057617,21.582143783569336,21.565357208251953,21.461429595947266,20.534643173217773,20.531429290771484,20.898571014404297,21.25107192993164,21.812856674194336,21.671785354614258,21.706785202026367,21.989286422729492,22.233928680419922,22.175357818603516,22.13785743713379,22.168928146362305,22.203571319580078,22.5,22.56035614013672,22.52964210510254,22.726428985595703,23.146785736083984,23.75535774230957,23.430713653564453,23.888214111328125,23.66535758972168,23.68642807006836,24.13142967224121,24.100000381469727,24.052499771118164,23.70964241027832,23.75857162475586,24.10607147216797,23.936786651611328,24.15250015258789,24.301429748535156,23.669286727905273,23.592500686645508,23.921070098876953,24.39214324951172,24.68857192993164,24.992143630981445,25.068214416503906,25.075000762939453,24.953571319580078,25.00321388244629,24.671070098876953,24.05500030517578,23.75642967224121,24.332857131958008,23.825000762939453,23.54964256286621,23.618213653564453,23.980356216430664,23.814285278320312,23.306785583496094,22.791786193847656,22.70892906188965,22.8896427154541,22.43214225769043,22.489643096923828,22.670000076293945,23.206785202026367,23.021785736083984,22.59428596496582,21.780000686645508,22.64392852783203,21.90571403503418,22.02964210510254,21.769285202026367,21.571428298950195,21.261428833007812,21.30500030517578,20.600000381469727,20.87928581237793,20.816070556640625,19.928571701049805,19.20535659790039,19.537857055664062,19.38678550720215,19.389286041259766,19.174285888671875,18.77214241027832,18.845714569091797,20.20464324951172,20.032499313354492,20.060714721679688,20.41071319580078,21.054643630981445,20.885000228881836,20.819286346435547,21.04857063293457,20.902856826782227,20.93535614013672,20.566070556640625,19.24250030517578,19.544286727905273,19.04464340209961,18.922143936157227,19.335357666015625,19.25,18.917499542236328,18.206785202026367,18.52964210510254,19.06785774230957,18.796785354614258,18.633214950561523,18.547500610351562,18.577499389648438,18.321428298950195,18.395000457763672,18.199642181396484,19.006071090698242,19.608213424682617,19.360713958740234,18.821428298950195,18.71071434020996,18.761070251464844,18.467857360839844,18.696786880493164,18.582143783569336,17.91964340209961,17.354286193847656,18.074642181396484,17.952856063842773,17.85714340209961,18.02750015258789,18.357500076293945,16.08928680419922,15.710000038146973,16.065357208251953,16.366785049438477,16.315357208251953,16.267499923706055,16.200714111328125,15.79714298248291,16.351428985595703,16.33392906188965,16.722143173217773,16.963571548461914,17.140356063842773,16.71071434020996,16.67892837524414,16.663928985595703,16.43428611755371,16.428213119506836,16.030357360839844,15.930713653564453,16.100357055664062,15.814286231994629,16.034643173217773,15.8774995803833,15.764286041259766,15.373929023742676,15.001786231994629,15.397856712341309,15.202142715454102,15.377857208251953,15.418571472167969,15.638214111328125,15.301071166992188,15.298213958740234,15.446429252624512,15.845000267028809,16.275714874267578,16.231786727905273,16.145713806152344,16.168928146362305,16.49678611755371,16.556428909301758,16.46928596496582,16.145713806152344,15.809286117553711,15.318214416503906,15.349642753601074,15.428214073181152,15.275713920593262,15.114286422729492,15.221785545349121,15.249285697937012,15.560357093811035,15.511786460876465,15.350000381469727,14.994643211364746,15.222857475280762,14.385713577270508,14.001786231994629,13.947500228881836,14.238213539123535,14.504643440246582,14.480713844299316,14.585000038146973,14.899999618530273,15.361429214477539,15.813570976257324,15.688928604125977,15.911429405212402,16.070714950561523,16.453929901123047,16.380714416503906,16.56571388244629,16.313213348388672,16.177499771118164,16.240713119506836,15.852143287658691,15.316070556640625,15.520713806152344,15.473570823669434,15.818928718566895,15.702142715454102,15.762499809265137,15.790714263916016,15.898214340209961,15.765713691711426,15.891071319580078,16.127857208251953,16.061786651611328,16.097143173217773,16.046785354614258,15.896785736083984,15.659285545349121,15.778928756713867,15.674642562866211,15.628570556640625,15.435357093811035,15.569999694824219,15.358928680419922,15.428570747375488,15.420356750488281,15.10714340209961,14.8871431350708,14.76785659790039,14.376428604125977,14.379643440246582,14.21678638458252,14.063570976257324,14.161786079406738,14.614999771118164,14.946070671081543,15.028571128845215,14.907856941223145,14.823213577270508,15.083929061889648,15.026070594787598,15.260356903076172,15.232500076293945,15.265713691711426,15.364286422729492,15.368213653564453,15.420000076293945,15.176786422729492,15.225357055664062,14.963929176330566,15.732500076293945,15.660714149475098,15.749643325805664,15.992500305175781,16.190000534057617,16.161785125732422,16.309999465942383,16.519285202026367,16.766071319580078,16.616071701049805,16.606428146362305,16.464643478393555,16.230356216430664,16.691429138183594,17.484643936157227,17.803571701049805,17.782499313354492,17.940357208251953,18.13357162475586,17.895357131958008,17.941429138183594,17.96285629272461,17.893571853637695,17.963214874267578,17.449642181396484,17.532142639160156,17.560714721679688,17.400714874267578,17.44928550720215,17.81035614013672,17.688213348388672,17.79357147216797,18.077499389648438,17.665714263916016,16.703929901123047,16.881786346435547,16.60357093811035,16.075714111328125,16.261428833007812,16.595714569091797,16.867856979370117,16.693214416503906,17.522857666015625,17.467857360839844,17.197500228881836,17.364999771118164,17.241071701049805,17.02678680419922,17.427143096923828,17.484285354614258,17.2646427154541,17.25107192993164,17.41964340209961,17.176429748535156,17.37821388244629,17.48714256286621,17.600357055664062,17.715713500976562,17.809999465942383,17.896785736083984,18.01785659790039,18.17464256286621,18.6200008392334,18.56678581237793,18.748571395874023,18.99678611755371,18.784286499023438,18.924285888671875,18.452856063842773,18.746429443359375,18.667856216430664,18.572500228881836,18.8125,18.766071319580078,18.604286193847656,18.303213119506836,18.591428756713867,18.537500381469727,18.571786880493164,18.593929290771484,18.862857818603516,18.749643325805664,18.522499084472656,18.555356979370117,18.39285659790039,18.61214256286621,18.564285278320312,18.704999923706055,19.049999237060547,19.498571395874023,19.859643936157227,19.686786651611328,20.2257137298584,20.178571701049805,20.282142639160156,20.000713348388672,20.229642868041992,20.198213577270508,20.04857063293457,20.019285202026367,19.801071166992188,19.91071319580078,19.82107162475586,19.67035675048828,19.44499969482422,19.60785675048828,20.3603572845459,20.273929595947266,20.139286041259766,20.00321388244629,19.804285049438477,20.036428451538086,19.754642486572266,19.320714950561523,19.426071166992188,19.28714370727539,19.409286499023438,19.161428451538086,19.033571243286133,19.133214950561523,19.51392936706543,19.90571403503418,19.79464340209961,19.309642791748047,19.609643936157227,19.696786880493164,19.863571166992188,19.502500534057617,19.66071319580078,18.08928680419922,17.883928298950195,17.849285125732422,17.878570556640625,17.911785125732422,18.171070098876953,18.306785583496094,18.30392837524414,18.559999465942383,18.892499923706055,19.141429901123047,19.139999389648438,19.44392967224121,19.428213119506836,19.499643325805664,19.19178581237793,18.969642639160156,18.758928298950195,18.8410701751709,18.645000457763672,18.47678565979004,18.84535789489746,18.794286727905273,18.84857177734375,18.972856521606445,19.01285743713379,18.95535659790039,18.944286346435547,18.961429595947266,19.14607048034668,19.164642333984375,18.951786041259766,18.738929748535156,18.812143325805664,18.97857093811035,18.97357177734375,18.882143020629883,19.031070709228516,19.256786346435547,19.46392822265625,19.277856826782227,19.19499969482422,19.17357063293457,19.169286727905273,19.344642639160156,19.376785278320312,19.24250030517578,18.99357032775879,18.695356369018555,18.694286346435547,18.940000534057617,18.695714950561523,18.5575008392334,18.63142967224121,18.498571395874023,18.53607177734375,18.74785614013672,18.97035789489746,18.989286422729492,18.741071701049805,20.27750015258789,20.426429748535156,21.217500686645508,21.15464210510254,21.074642181396484,21.124286651611328,21.163570404052734,21.46285629272461,21.22892951965332,21.15464210510254,20.999643325805664,20.91214370727539,21.172500610351562,21.205713272094727,21.20964241027832,21.029285430908203,21.339643478393555,21.592500686645508,21.596786499023438,21.653928756713867,21.688213348388672,21.93321418762207,22.343929290771484,22.28607177734375,22.692142486572266,22.60714340209961,22.451786041259766,22.769285202026367,23.029285430908203,23.11964225769043,23.05607032775879,23.424999237060547,23.5625,23.46500015258789,23.072500228881836,22.81999969482422,23.049999237060547,23.020000457763672,23.045000076293945,22.96500015258789,22.727500915527344,22.707500457763672,22.56999969482422,22.59000015258789,22.725000381469727,22.9950008392334,23.232500076293945,23.3799991607666,23.3700008392334,23.50749969482422,23.99250030517578,23.837499618530273,23.84749984741211,23.760000228881836,23.80500030517578,24.112499237060547,23.829999923706055,23.69499969482422,23.272499084472656,23.607500076293945,23.485000610351562,23.68000030517578,24.297500610351562,24.25749969482422,24.417499542236328,24.7549991607666,24.594999313354492,24.537500381469727,23.899999618530273,24.032499313354492,23.897499084472656,23.780000686645508,23.739999771118164,23.6200008392334,23.684999465942383,23.997499465942383,23.99250030517578,24.309999465942383,24.375,24.4950008392334,24.790000915527344,25.13249969482422,25.142499923706055,25.145000457763672,25.329999923706055,25.385000228881836,25.22249984741211,25.532499313354492,25.5625,25.625,25.825000762939453,24.735000610351562,24.530000686645508,24.74250030517578,24.59000015258789,24.497499465942383,25.25,25.357500076293945,25.415000915527344,25.407499313354492,25.21500015258789,25.395000457763672,25.447500228881836,25.239999771118164,25.264999389648438,25.65999984741211,25.4375,24.467500686645508,25.1875,25.02750015258789,25.1875,24.795000076293945,24.975000381469727,24.905000686645508,24.905000686645508,24.6875,25.200000762939453,25.2549991607666,25.1825008392334,24.952499389648438,24.6875,24.385000228881836,24.065000534057617,24.417499542236328,24.940000534057617,25.61750030517578,25.747499465942383,26.207500457763672,26.30500030517578,26.27750015258789,26.684999465942383,26.834999084472656,26.7450008392334,27.0,27.350000381469727,27.149999618530273,27.21500015258789,27.174999237060547,27.252500534057617,27.207500457763672,27.424999237060547,27.8125,28.204999923706055,28.545000076293945,28.497499465942383,28.86750030517578,28.667499542236328,29.077499389648438,29.11750030517578,29.657499313354492,29.399999618530273,29.75,29.732500076293945,28.767499923706055,28.657499313354492,28.982500076293945,28.872499465942383,28.75,28.100000381469727,28.530000686645508,27.987499237060547,27.905000686645508,27.4325008392334,27.0575008392334,26.6875,27.352500915527344,28.162500381469727,27.94499969482422,28.235000610351562,28.135000228881836,28.002500534057617,28.497499465942383,28.477500915527344,28.1299991607666,27.594999313354492,27.332500457763672,26.5625,26.565000534057617,26.9375,27.97249984741211,28.002500534057617,27.3125,27.55500030517578,27.450000762939453,26.704999923706055,26.497499465942383,27.18000030517578,27.387500762939453,28.100000381469727,28.2450008392334,28.274999618530273,27.28499984741211,28.827499389648438,29.725000381469727,29.290000915527344,29.657499313354492,29.662500381469727,29.889999389648438,29.985000610351562,29.732500076293945,29.93000030517578,30.5049991607666,31.219999313354492,31.614999771118164,31.770000457763672,31.957500457763672,32.18000030517578,32.11249923706055,32.375,33.25,33.04249954223633,32.1974983215332,32.60499954223633,32.1150016784668,32.272499084472656,32.34000015258789,32.1349983215332,31.602500915527344,31.649999618530273,31.78499984741211,31.127500534057617,30.559999465942383,31.112499237060547,30.897499084472656,31.237499237060547,31.760000228881836,32.11750030517578,31.875,31.475000381469727,31.802499771118164,31.672500610351562,30.844999313354492,31.059999465942383,30.8125,31.592500686645508,31.107500076293945,31.0625,31.329999923706055,31.837499618530273,31.502500534057617,31.399999618530273,31.639999389648438,31.774999618530273,31.712499618530273,31.575000762939453,31.69499969482422,31.542499542236328,31.1875,31.899999618530273,31.727500915527344,32.154998779296875,32.41749954223633,32.56999969482422,33.162498474121094,32.63999938964844,32.15999984741211,31.287500381469727,32.23749923706055,32.17499923706055,31.450000762939453,31.252500534057617,31.315000534057617,31.905000686645508,31.579999923706055,31.467500686645508,31.502500534057617,32.23749923706055,32.192501068115234,32.54750061035156,32.51750183105469,32.51499938964844,32.84749984741211,33.1349983215332,32.404998779296875,33.0099983215332,32.94499969482422,32.56999969482422,32.6349983215332,32.4900016784668,32.529998779296875,32.34000015258789,32.162498474121094,31.950000762939453,31.854999542236328,32.220001220703125,32.147499084472656,31.792499542236328,31.729999542236328,31.899999618530273,31.825000762939453,31.969999313354492,31.649999618530273,31.90250015258789,31.75749969482422,32.02750015258789,31.875,31.6875,31.13249969482422,31.357500076293945,31.649999618530273,31.610000610351562,31.5,31.422500610351562,30.642499923706055,30.017499923706055,30.81999969482422,31.415000915527344,31.40250015258789,31.704999923706055,32.127498626708984,32.404998779296875,33.01750183105469,32.6875,31.30500030517578,31.290000915527344,31.125,30.6924991607666,30.844999313354492,30.747499465942383,30.592500686645508,30.325000762939453,29.610000610351562,28.65999984741211,28.850000381469727,28.782499313354492,28.8799991607666,29.93000030517578,28.372499465942383,28.809999465942383,28.787500381469727,28.989999771118164,29.290000915527344,29.125,28.752500534057617,28.162500381469727,26.440000534057617,25.780000686645508,25.934999465942383,27.422500610351562,28.229999542236328,28.322500228881836,28.190000534057617,26.93000030517578,28.084999084472656,27.592500686645508,27.3174991607666,28.077499389648438,27.537500381469727,28.142499923706055,28.552499771118164,28.827499389648438,29.06999969482422,29.102500915527344,28.479999542236328,28.362499237060547,28.802499771118164,28.350000381469727,28.579999923706055,28.75,28.677499771118164,28.110000610351562,27.264999389648438,27.575000762939453,27.395000457763672,27.594999313354492,27.69499969482422,27.827499389648438,27.69499969482422,27.375,28.030000686645508,27.899999618530273,27.947500228881836,27.552499771118164,27.96500015258789,27.760000228881836,27.9325008392334,28.4424991607666,28.440000534057617,28.875,29.770000457763672,28.81999969482422,28.637500762939453,29.8174991607666,30.13249969482422,29.875,30.295000076293945,30.642499923706055,30.5,30.229999542236328,30.264999389648438,30.142499923706055,29.1924991607666,29.02750015258789,28.93000030517578,28.084999084472656,28.545000076293945,28.422500610351562,29.322500228881836,29.69499969482422,29.825000762939453,29.4375,29.719999313354492,29.50749969482422,29.452499389648438,29.575000762939453,29.334999084472656,29.06999969482422,28.799999237060547,29.75749969482422,29.56999969482422,29.5575008392334,28.905000686645508,29.042499542236328,28.295000076293945,28.1200008392334,27.622499465942383,27.834999084472656,27.2450008392334,26.50749969482422,26.832500457763672,26.8075008392334,27.15250015258789,27.00749969482422,26.704999923706055,27.184999465942383,26.829999923706055,26.315000534057617,26.337499618530273,25.677499771118164,25.174999237060547,24.112499237060547,24.239999771118164,24.63249969482422,24.989999771118164,24.34749984741211,24.8799991607666,24.282499313354492,24.165000915527344,24.197500228881836,24.075000762939453,25.354999542236328,24.860000610351562,24.997499465942383,23.354999542236328,23.522499084472656,24.334999084472656,24.107500076293945,23.6200008392334,24.087499618530273,24.149999618530273,23.5049991607666,23.752500534057617,23.747499465942383,23.5674991607666,23.424999237060547,23.497499465942383,24.15999984741211,24.530000686645508,24.065000534057617,24.010000228881836,24.219999313354492,23.672500610351562,24.024999618530273,24.190000534057617,24.227500915527344,24.172500610351562,25.13249969482422,25.1875,25.375,25.752500534057617,25.467500686645508,25.25749969482422,25.280000686645508,25.292499542236328,25.565000534057617,25.6299991607666,26.145000457763672,26.49250030517578,26.450000762939453,26.479999542236328,26.477500915527344,26.68000030517578,26.532499313354492,26.417499542236328,26.297500610351562,26.920000076293945,27.389999389648438,27.247499465942383,27.497499465942383,27.780000686645508,27.452499389648438,27.739999771118164,27.135000228881836,27.165000915527344,27.2549991607666,27.610000610351562,28.010000228881836,28.024999618530273,27.462499618530273,26.8700008392334,26.727500915527344,26.782499313354492,26.49250030517578,26.420000076293945,26.270000457763672,26.087499618530273,24.454999923706055,23.707500457763672,23.434999465942383,23.40999984741211,23.795000076293945,23.547500610351562,23.309999465942383,23.18000030517578,23.197500228881836,23.354999542236328,23.127500534057617,22.584999084472656,22.6299991607666,23.469999313354492,23.372499465942383,23.639999389648438,23.549999237060547,23.80500030517578,24.107500076293945,24.475000381469727,24.905000686645508,25.102500915527344,25.087499618530273,24.96500015258789,24.614999771118164,24.43000030517578,24.479999542236328,24.657499313354492,24.75749969482422,24.735000610351562,24.912500381469727,24.707500457763672,24.334999084472656,24.364999771118164,24.28499984741211,24.387500762939453,23.832500457763672,23.774999618530273,23.977500915527344,23.887500762939453,24.024999618530273,23.350000381469727,23.010000228881836,23.397499084472656,23.600000381469727,23.899999618530273,23.97249984741211,23.747499465942383,23.88249969482422,23.985000610351562,24.170000076293945,24.2450008392334,24.354999542236328,24.217500686645508,24.697500228881836,24.69499969482422,24.957500457763672,24.967500686645508,24.989999771118164,24.857500076293945,24.665000915527344,24.334999084472656,24.167499542236328,25.737499237060547,26.084999084472656,26.052499771118164,26.512500762939453,26.1200008392334,26.447500228881836,26.467500686645508,26.8700008392334,27.092500686645508,27.202499389648438,27.0,26.982500076293945,27.045000076293945,27.3700008392334,27.344999313354492,27.30500030517578,27.270000457763672,27.34000015258789,27.127500534057617,27.212499618530273,27.00749969482422,26.892499923706055,26.735000610351562,26.704999923706055,26.5,26.524999618530273,26.6825008392334,26.9325008392334,26.924999237060547,27.09000015258789,26.3799991607666,25.782499313354492,26.360000610351562,26.987499237060547,27.9424991607666,28.892499923706055,28.729999542236328,28.395000457763672,28.392499923706055,28.387500762939453,28.655000686645508,28.177499771118164,28.219999313354492,28.272499084472656,28.487499237060547,28.045000076293945,28.262500762939453,28.1299991607666,28.25,28.262500762939453,28.47249984741211,28.514999389648438,29.012500762939453,29.075000762939453,29.334999084472656,29.2450008392334,29.407499313354492,29.387500762939453,29.36750030517578,29.280000686645508,29.264999389648438,29.149999618530273,29.412500381469727,29.5625,28.897499084472656,28.6200008392334,28.43000030517578,28.385000228881836,27.872499465942383,27.897499084472656,27.457500457763672,27.209999084472656,27.602500915527344,27.764999389648438,27.719999313354492,26.947500228881836,27.107500076293945,26.427499771118164,26.77750015258789,27.497499465942383,27.487499237060547,27.514999389648438,27.9325008392334,27.950000762939453,27.8075008392334,27.947500228881836,27.892499923706055,27.864999771118164,27.6299991607666,27.372499465942383,27.475000381469727,27.27750015258789,27.487499237060547,27.75749969482422,28.030000686645508,28.487499237060547,28.325000762939453,28.797500610351562,28.797500610351562,28.954999923706055,28.99250030517578,29.15999984741211,29.237499237060547,29.264999389648438,29.072500228881836,29.1299991607666,29.315000534057617,29.190000534057617,29.1825008392334,28.954999923706055,29.037500381469727,29.0049991607666,29.15250015258789,29.477500915527344,29.747499465942383,29.77750015258789,29.9375,29.8125,29.760000228881836,30.0,29.997499465942383,29.94499969482422,30.0,30.020000457763672,29.99250030517578,30.469999313354492,30.485000610351562,30.487499237060547,30.407499313354492,30.337499618530273,32.1875,32.13249969482422,32.27000045776367,32.5724983215332,32.88249969482422,33.0099983215332,33.10499954223633,33.029998779296875,33.3224983215332,33.755001068115234,33.877498626708984,33.837501525878906,33.93000030517578,34.17499923706055,34.27750015258789,34.13249969482422,34.165000915527344,34.23249816894531,34.247501373291016,34.9474983215332,34.7400016784668,34.94499969482422,34.834999084472656,34.880001068115234,34.75,34.66999816894531,34.78499984741211,34.79999923706055,34.747501373291016,35.1150016784668,35.17250061035156,34.997501373291016,35.3650016784668,34.959999084472656,35.35499954223633,35.22999954223633,35.15999984741211,35.220001220703125,35.95000076293945,36.029998779296875,35.98249816894531,35.915000915527344,35.92499923706055,36.192501068115234,36.005001068115234,35.915000915527344,35.834999084472656,35.79249954223633,35.407501220703125,35.45000076293945,35.26250076293945,35.45750045776367,35.29999923706055,35.16999816894531,35.61000061035156,35.567501068115234,35.90999984741211,36.13249969482422,35.91999816894531,35.9474983215332,35.912498474121094,36.64500045776367,36.877498626708984,36.76499938964844,36.63249969482422,37.2400016784668,38.252498626708984,38.497501373291016,38.314998626708984,38.48749923706055,39.025001525878906,38.92499923706055,38.86750030517578,37.5625,38.1349983215332,38.26499938964844,38.497501373291016,38.45000076293945,38.334999084472656,38.467498779296875,38.40250015258789,38.41749954223633,38.189998626708984,38.29499816894531,38.86249923706055,38.48249816894531,38.61249923706055,38.842498779296875,38.747501373291016,37.244998931884766,36.35499954223633,36.647499084472656,36.290000915527344,36.0724983215332,35.567501068115234,36.584999084472656,36.252498626708984,36.467498779296875,36.407501220703125,36.56999969482422,36.45500183105469,35.932498931884766,36.45750045776367,35.91999816894531,36.005001068115234,35.875,36.022499084472656,35.682498931884766,36.04499816894531,36.26499938964844,36.38249969482422,36.435001373291016,36.942501068115234,37.2599983215332,37.38999938964844,37.52000045776367,37.755001068115234,37.584999084472656,37.567501068115234,38.022499084472656,38.185001373291016,38.3650016784668,37.63999938964844,37.375,37.182498931884766,37.51250076293945,39.28499984741211,38.89250183105469,39.09749984741211,39.70249938964844,40.02000045776367,40.26499938964844,38.83000183105469,39.369998931884766,39.962501525878906,40.400001525878906,40.23749923706055,39.46500015258789,39.375,39.3025016784668,39.94499969482422,39.994998931884766,39.817501068115234,39.96500015258789,40.36750030517578,40.727500915527344,40.837501525878906,41.0,41.01250076293945,40.52000045776367,40.477500915527344,40.314998626708984,39.657501220703125,40.375,40.21500015258789,39.912498474121094,39.56999969482422,39.970001220703125,39.66749954223633,39.682498931884766,39.01750183105469,38.34749984741211,37.97249984741211,37.63750076293945,38.28499984741211,38.557498931884766,38.31999969482422,38.529998779296875,38.45249938964844,38.619998931884766,38.369998931884766,38.84749984741211,38.82500076293945,38.959999084472656,38.974998474121094,39.13750076293945,39.0,39.247501373291016,39.970001220703125,40.11750030517578,39.939998626708984,38.994998931884766,39.0625,39.04249954223633,39.275001525878906,39.102500915527344,39.352500915527344,40.76250076293945,41.68000030517578,42.2599983215332,41.72249984741211,42.02750015258789,43.125,43.5625,43.70249938964844,44.060001373291016,43.970001220703125,43.66749954223633,43.49250030517578,42.834999084472656,42.27000045776367,42.775001525878906,42.537498474121094,42.494998931884766,43.28499984741211,43.7400016784668,43.74250030517578,43.522499084472656,43.26750183105469,42.369998931884766,42.962501525878906,42.76250076293945,42.45000076293945,42.40999984741211,42.252498626708984,42.33000183105469,42.342498779296875,43.16749954223633,42.92499923706055,43.067501068115234,43.05500030517578,43.49250030517578,44.10499954223633,43.6349983215332,43.587501525878906,43.752498626708984,43.752498626708984,42.64250183105469,42.650001525878906,42.77000045776367,42.307498931884766,43.064998626708984,43.057498931884766,43.25749969482422,43.75,43.587501525878906,43.58250045776367,43.5724983215332,43.81999969482422,44.272499084472656,44.04750061035156,44.775001525878906,44.814998626708984,44.6150016784668,44.25,44.2599983215332,43.55500030517578,42.77750015258789,42.877498626708984,41.9900016784668,41.74250030517578,41.85749816894531,41.94499969482422,40.125,39.122501373291016,40.75749969482422,39.8849983215332,38.787498474121094,39.102500915527344,40.6775016784668,41.084999084472656,41.842498779296875,43.247501373291016,43.10749816894531,42.962501525878906,42.76750183105469,43.125,43.875,44.74250030517578,44.59749984741211,44.529998779296875,43.75,44.0525016784668,44.20500183105469,44.16749954223633,43.75749969482422,44.23500061035156,44.994998931884766,45.43000030517578,44.99250030517578,44.61000061035156,44.662498474121094,44.505001068115234,43.82500076293945,43.810001373291016,42.817501068115234,42.212501525878906,41.23500061035156,43.192501068115234,42.084999084472656,41.619998931884766,41.94499969482422,41.66999816894531,42.09749984741211,42.90250015258789,43.20000076293945,42.095001220703125,42.51250076293945,43.3125,43.11000061035156,43.53499984741211,43.682498931884766,43.95500183105469,44.560001373291016,44.459999084472656,43.20000076293945,41.43000030517578,41.310001373291016,40.73500061035156,40.912498474121094,41.05500030517578,40.58000183105469,41.314998626708984,42.275001525878906,44.14250183105469,44.22249984741211,45.95750045776367,46.290000915527344,46.51250076293945,46.84000015258789,47.5099983215332,47.147499084472656,47.037498474121094,46.61000061035156,47.04499816894531,46.747501373291016,46.57749938964844,46.907501220703125,46.790000915527344,47.09000015258789,47.037498474121094,47.14500045776367,46.974998474121094,46.875,46.717498779296875,47.560001373291016,47.95750045776367,48.32749938964844,48.494998931884766,48.3650016784668,47.92499923706055,47.807498931884766,48.06999969482422,47.67499923706055,47.70000076293945,47.209999084472656,47.185001373291016,46.42250061035156,46.625,46.3650016784668,46.22999954223633,45.54249954223633,46.10749816894531,46.040000915527344,46.375,46.27750015258789,46.79499816894531,45.97999954223633,46.349998474121094,46.99250030517578,47.64500045776367,47.587501525878906,46.970001220703125,47.75749969482422,47.83250045776367,47.727500915527344,47.86249923706055,47.599998474121094,47.970001220703125,47.86000061035156,47.90250015258789,48.25,48.70500183105469,48.5525016784668,47.744998931884766,47.477500915527344,47.5724983215332,50.375,51.84749984741211,51.997501373291016,52.26750183105469,51.77750015258789,51.8125,52.220001220703125,51.88249969482422,52.217498779296875,52.4375,52.560001373291016,53.33000183105469,54.39500045776367,53.8650016784668,53.7599983215332,53.76250076293945,53.872501373291016,54.040000915527344,54.48500061035156,54.92499923706055,55.744998931884766,56.25749969482422,56.907501220703125,57.09000015258789,56.717498779296875,55.775001525878906,55.32500076293945,54.58250045776367,55.962501525878906,55.26750183105469,56.602500915527344,55.959999084472656,54.470001220703125,54.560001373291016,54.592498779296875,55.00749969482422,54.415000915527344,55.1974983215332,55.54750061035156,55.10499954223633,56.23749923706055,56.435001373291016,56.814998626708984,57.31999969482422,58.01750183105469,56.997501373291016,56.0724983215332,55.942501068115234,56.717498779296875,54.09000015258789,53.61249923706055,55.52750015258789,54.34000015258789,55.537498474121094,55.29750061035156,54.005001068115234,54.82749938964844,55.162498474121094,55.682498931884766,53.772499084472656,54.95000076293945,54.07500076293945,53.060001373291016,53.32500076293945,54.71500015258789,55.55500030517578,51.869998931884766,50.397499084472656,50.942501068115234,52.48749923706055,52.122501373291016,51.11750030517578,48.54249954223633,48.057498931884766,46.70000076293945,47.852500915527344,48.38249969482422,46.46500015258789,44.244998931884766,44.19499969482422,43.0724983215332,43.654998779296875,43.560001373291016,45.23500061035156,44.88750076293945,44.64500045776367,46.20500183105469,44.17250061035156,43.68000030517578,42.122501373291016,42.400001525878906,42.157501220703125,42.275001525878906,42.73749923706055,41.369998931884766,40.98500061035156,41.51750183105469,40.22249984741211,39.20750045776367,37.682498931884766,36.70750045776367,39.29249954223633,39.037498474121094,39.057498931884766,39.435001373291016,39.47999954223633,35.54750061035156,37.064998626708984,36.98249816894531,37.6875,38.32749938964844,38.45000076293945,38.0724983215332,37.5,38.26750183105469,38.73500061035156,38.96500015258789,39.20500183105469,38.32500076293945,38.47999954223633,38.17499923706055,39.439998626708984,39.07500076293945,38.66999816894531,41.3125,41.61000061035156,41.630001068115234,42.8125,43.54499816894531,43.560001373291016,42.73500061035156,42.602500915527344,42.35749816894531,42.72249984741211,42.54499816894531,42.70000076293945,42.60499954223633,42.73249816894531,43.00749969482422,42.76499938964844,43.24250030517578,43.557498931884766,43.58250045776367,43.717498779296875,43.287498474121094,43.74250030517578,43.962501525878906,43.88249969482422,43.630001068115234,43.125,43.227500915527344,44.724998474121094,45.227500915527344,45.4275016784668,45.932498931884766,46.529998779296875,47.005001068115234,46.63249969482422,47.040000915527344,48.772499084472656,47.76250076293945,47.185001373291016,46.6974983215332,47.11750030517578,47.18000030517578,47.48749923706055,47.810001373291016,48.505001068115234,48.837501525878906,48.92250061035156,49.25,50.025001525878906,49.875,50.154998779296875,49.73749923706055,49.717498779296875,49.807498931884766,49.8125,50.782501220703125,50.96500015258789,51.13249969482422,51.869998931884766,51.790000915527344,51.31999969482422,51.07500076293945,51.15250015258789,50.16749954223633,52.630001068115234,52.287498474121094,52.9375,52.119998931884766,50.71500015258789,50.724998474121094,50.18000030517578,49.29499816894531,46.43000030517578,47.165000915527344,47.72999954223633,47.52000045776367,47.25,45.772499084472656,46.650001525878906,45.69499969482422,44.915000915527344,44.74250030517578,44.557498931884766,44.345001220703125,44.57500076293945,43.76750183105469,43.32500076293945,44.90999984741211,45.6349983215332,46.30500030517578,47.537498474121094,48.14500045776367,48.70249938964844,48.54750061035156,48.537498474121094,48.185001373291016,48.47249984741211,49.61249923706055,49.467498779296875,49.8650016784668,49.69499969482422,49.64500045776367,48.89250183105469,49.95000076293945,49.935001373291016,49.47999954223633,50.38750076293945,50.682498931884766,51.102500915527344,51.057498931884766,50.005001068115234,50.310001373291016,50.807498931884766,50.4375,50.82500076293945,51.3025016784668,51.125,50.837501525878906,51.415000915527344,50.647499084472656,51.80500030517578,52.209999084472656,52.16749954223633,51.755001068115234,51.935001373291016,52.41999816894531,52.19499969482422,53.2599983215332,52.10749816894531,51.005001068115234,48.334999084472656,49.25,49.7599983215332,50.85749816894531,50.247501373291016,50.119998931884766,52.24250030517578,50.6875,50.435001373291016,51.625,52.587501525878906,52.59000015258789,53.15999984741211,53.1150016784668,50.65999984741211,51.622501373291016,51.040000915527344,51.38249969482422,52.252498626708984,52.185001373291016,51.42499923706055,52.29750061035156,53.31999969482422,53.314998626708984,53.54249954223633,54.17499923706055,55.897499084472656,55.772499084472656,54.6875,54.974998474121094,55.17499923706055,55.692501068115234,55.2400016784668,54.432498931884766,54.68000030517578,54.41999816894531,55.25749969482422,54.97249984741211,54.70500183105469,55.99250030517578,56.147499084472656,54.7400016784668,55.20500183105469,56.752498626708984,56.76499938964844,56.099998474121094,56.75749969482422,57.522499084472656,59.0525016784668,58.967498779296875,58.83000183105469,58.592498779296875,58.81999969482422,59.102500915527344,60.127498626708984,59.9900016784668,60.79499816894531,60.89500045776367,61.64500045776367,62.26250076293945,60.8224983215332,60.814998626708984,62.189998626708984,63.95500183105469,64.375,64.28250122070312,64.30999755859375,64.85749816894531,65.03500366210938,65.55000305175781,65.48999786376953,66.11750030517578,65.66000366210938,66.44000244140625,66.7750015258789,66.57250213623047,65.79750061035156,65.50250244140625,65.44499969482422,66.59249877929688,66.07250213623047,66.95999908447266,66.8125,66.04000091552734,64.86250305175781,65.43499755859375,66.3949966430664,67.67749786376953,66.7300033569336,67.12000274658203,67.69249725341797,67.86499786376953,68.7874984741211,69.96499633789062,70.10250091552734,69.93499755859375,70.00499725341797,69.86000061035156,71.0,71.06749725341797,72.47750091552734,72.44999694824219,72.87999725341797,73.4124984741211,75.0875015258789,74.35749816894531,74.94999694824219,74.59750366210938,75.79750061035156,77.40750122070312,77.5824966430664,79.23999786376953,78.16999816894531,77.83499908447266,78.80999755859375,79.68250274658203,79.14250183105469,79.42500305175781,79.80750274658203,79.57749938964844,77.23750305175781,79.42250061035156,81.08499908447266,80.96749877929688,77.37750244140625,77.16500091552734,79.7125015258789,80.36250305175781,81.30249786376953,80.00749969482422,80.38749694824219,79.90249633789062,81.80000305175781,81.21749877929688,81.23750305175781,79.75,80.90499877929688,80.07499694824219,78.26249694824219,74.54499816894531,72.0199966430664,73.1624984741211,68.37999725341797,68.33999633789062,74.70249938964844,72.33000183105469,75.68499755859375,73.2300033569336,72.25749969482422,66.5425033569336,71.33499908447266,68.85749816894531,62.057498931884766,69.49250030517578,60.5525016784668,63.21500015258789,61.66749954223633,61.19499969482422,57.310001373291016,56.092498779296875,61.720001220703125,61.380001068115234,64.61000061035156,61.935001373291016,63.70249938964844,63.5724983215332,60.227500915527344,61.23249816894531,60.352500915527344,65.61750030517578,64.85749816894531,66.51750183105469,66.99749755859375,68.3125,71.76249694824219,71.10749816894531,71.67250061035156,70.69999694824219,69.23249816894531,67.09249877929688,69.0250015258789,68.75749969482422,70.74250030517578,70.7925033569336,69.6449966430664,71.93250274658203,73.44999694824219,72.26750183105469,73.29000091552734,74.38999938964844,75.15750122070312,75.93499755859375,77.53250122070312,78.75250244140625,77.85250091552734,76.9124984741211,77.38500213623047,76.92749786376953,78.73999786376953,78.28500366210938,79.80750274658203,79.2125015258789,79.72250366210938,79.18250274658203,79.52749633789062,79.5625,79.48500061035156,80.4625015258789,80.83499908447266,81.27999877929688,80.58000183105469,82.875,83.36499786376953,85.99749755859375,88.20999908447266,83.9749984741211,84.69999694824219,85.74749755859375,88.0199966430664,87.89749908447266,87.93250274658203],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Prediction\",\"x\":[87.43000030517578,89.71749877929688,91.63249969482422,90.01499938964844,91.20999908447266,88.40750122070312,90.44499969482422,91.19999694824219,91.02749633789062,91.02749633789062,93.4625015258789,93.17250061035156,95.34249877929688,95.75250244140625,95.91999816894531,95.47750091552734,97.05750274658203,97.7249984741211,96.52249908447266,96.32749938964844,98.35749816894531,97.0,97.27249908447266,92.84500122070312,92.61499786376953,94.80999755859375,93.25250244140625,95.04000091552734,96.19000244140625,106.26000213623047,108.9375,109.66500091552734,110.0625,113.90249633789062,111.11250305175781,112.72750091552734,109.375,113.01000213623047,115.01000213623047,114.90750122070312,114.60749816894531,115.5625,115.7074966430664,118.2750015258789,124.37000274658203,125.85749816894531,124.82499694824219,126.52249908447266,125.01000213623047,124.80750274658203,129.0399932861328,134.17999267578125,131.39999389648438,120.87999725341797,120.95999908447266,112.81999969482422,117.31999969482422,113.48999786376953,112.0,115.36000061035156,115.54000091552734,112.12999725341797,110.33999633789062,106.83999633789062,110.08000183105469,111.80999755859375,107.12000274658203,108.22000122070312,112.27999877929688,114.95999908447266,114.08999633789062,115.80999755859375,116.79000091552734,113.0199966430664,116.5,113.16000366210938,115.08000183105469,114.97000122070312,116.97000122070312,124.4000015258789,121.0999984741211,121.19000244140625,120.70999908447266,119.0199966430664,115.9800033569336,117.51000213623047,116.87000274658203,115.75,115.04000091552734,115.05000305175781,116.5999984741211,111.19999694824219,115.31999969482422,108.86000061035156,108.7699966430664,110.44000244140625,114.94999694824219,119.02999877929688,118.69000244140625,116.31999969482422,115.97000122070312,119.48999786376953,119.20999908447266,119.26000213623047,120.30000305175781,119.38999938964844,118.02999877929688,118.63999938964844,117.33999633789062,113.8499984741211,115.16999816894531,116.02999877929688,116.58999633789062,119.05000305175781,122.72000122070312,123.08000183105469,122.94000244140625,122.25,123.75,124.37999725341797,121.77999877929688,123.23999786376953,122.41000366210938,121.77999877929688,127.87999725341797,127.80999755859375,128.6999969482422,126.66000366210938,128.22999572753906,131.8800048828125,130.9600067138672,131.97000122070312,136.69000244140625,134.8699951171875,133.72000122070312,132.69000244140625,129.41000366210938,131.00999450683594,126.5999984741211,130.9199981689453,132.0500030517578,128.97999572753906,128.8000030517578,130.88999938964844,128.91000366210938,127.13999938964844,127.83000183105469,132.02999877929688,136.8699951171875,139.07000732421875,142.9199981689453,143.16000366210938,142.05999755859375,137.08999633789062,131.9600067138672,134.13999938964844,134.99000549316406,133.94000244140625,137.38999938964844,136.75999450683594,136.91000366210938,136.00999450683594,135.38999938964844,135.1300048828125,135.3699951171875,133.19000244140625,130.83999633789062,129.7100067138672,129.8699951171875,126.0,125.86000061035156,125.3499984741211,120.98999786376953,121.26000213623047,127.79000091552734,125.12000274658203,122.05999755859375,120.12999725341797,121.41999816894531,116.36000061035156,121.08999633789062,119.9800033569336,121.95999908447266,121.02999877929688,123.98999786376953,125.56999969482422,124.76000213623047,120.52999877929688,119.98999786376953,123.38999938964844,122.54000091552734,120.08999633789062,120.58999633789062,121.20999908447266,121.38999938964844,119.9000015258789,122.1500015258789,123.0,125.9000015258789,126.20999908447266,127.9000015258789,130.36000061035156,133.0,131.24000549316406,134.42999267578125,132.02999877929688,134.5,134.16000366210938,134.83999633789062,133.11000061035156,133.5,131.94000244140625,134.32000732421875,134.72000122070312,134.38999938964844,133.5800018310547,133.47999572753906,131.4600067138672,132.5399932861328,127.8499984741211,128.10000610351562,129.74000549316406,130.2100067138672,126.8499984741211,125.91000366210938,122.7699966430664,124.97000122070312,127.44999694824219,126.2699966430664,124.8499984741211,124.69000244140625,127.30999755859375,125.43000030517578,127.0999984741211,126.9000015258789,126.8499984741211,125.27999877929688,124.61000061035156,124.27999877929688,125.05999755859375,123.54000091552734,125.88999938964844,125.9000015258789,126.73999786376953,127.12999725341797,126.11000061035156,127.3499984741211,130.47999572753906,129.63999938964844,130.14999389648438,131.7899932861328,130.4600067138672,132.3000030517578,133.97999572753906,133.6999969482422,133.41000366210938,133.11000061035156,134.77999877929688,136.3300018310547,136.9600067138672,137.27000427246094,139.9600067138672,142.02000427246094,144.57000732421875,143.24000549316406,145.11000061035156,144.5,145.63999938964844,149.14999389648438,148.47999572753906,146.38999938964844,142.4499969482422,146.14999389648438,145.39999389648438,146.8000030517578,148.55999755859375,148.99000549316406,146.77000427246094,144.97999572753906,145.63999938964844,145.86000061035156,145.52000427246094,147.36000061035156,146.9499969482422,147.05999755859375,146.13999938964844,146.08999633789062,145.60000610351562,145.86000061035156,148.88999938964844,149.10000610351562,151.1199951171875,150.19000244140625,146.36000061035156,146.6999969482422,148.19000244140625,149.7100067138672,149.6199951171875,148.36000061035156,147.5399932861328,148.60000610351562,153.1199951171875,151.8300018310547,152.50999450683594,153.64999389648438,154.3000030517578,156.69000244140625,155.11000061035156,154.07000732421875,148.97000122070312,149.5500030517578,148.1199951171875,149.02999877929688,148.7899932861328,146.05999755859375,142.94000244140625,143.42999267578125,145.85000610351562,146.8300018310547,146.9199981689453,145.3699951171875,141.91000366210938,142.8300018310547,141.5,142.64999389648438,139.13999938964844,141.11000061035156,142.0,143.2899932861328,142.89999389648438,142.80999755859375,141.50999450683594,140.91000366210938,143.75999450683594,144.83999633789062,146.5500030517578,148.75999450683594,149.25999450683594,149.47999572753906,148.69000244140625,148.63999938964844,149.32000732421875,148.85000610351562,152.57000732421875,149.8000030517578,148.9600067138672,150.02000427246094,151.49000549316406,150.9600067138672,151.27999877929688,150.44000244140625,150.80999755859375,147.9199981689453,147.8699951171875,149.99000549316406,150.0,151.0,153.49000549316406,157.8699951171875,160.5500030517578,161.02000427246094,161.41000366210938,161.94000244140625,156.80999755859375,160.24000549316406,165.3000030517578,164.77000427246094,163.75999450683594,161.83999633789062,165.32000732421875,171.17999267578125,175.0800018310547,174.55999755859375,179.4499969482422,175.74000549316406,174.3300018310547,179.3000030517578,172.25999450683594,171.13999938964844,169.75,172.99000549316406,175.63999938964844,176.27999877929688,180.3300018310547,179.2899932861328,179.3800048828125,178.1999969482422,177.57000732421875,182.00999450683594,179.6999969482422,174.9199981689453,172.0,172.1699981689453,172.19000244140625,175.0800018310547,175.52999877929688,172.19000244140625,173.07000732421875,169.8000030517578,166.22999572753906,164.50999450683594,162.41000366210938,161.6199951171875,159.77999877929688,159.69000244140625,159.22000122070312,170.3300018310547,174.77999877929688,174.61000061035156,175.83999633789062,172.89999389648438,172.38999938964844,171.66000366210938,174.8300018310547,176.27999877929688,172.1199951171875,168.63999938964844,168.8800048828125,172.7899932861328,172.5500030517578,168.8800048828125,167.3000030517578,164.32000732421875,160.07000732421875,162.74000549316406,164.85000610351562,165.1199951171875,163.1999969482422,166.55999755859375,166.22999572753906,163.1699981689453,159.3000030517578,157.44000244140625,162.9499969482422,158.52000427246094,154.72999572753906,150.6199951171875,155.08999633789062,159.58999633789062,160.6199951171875,163.97999572753906,165.3800048828125,168.82000732421875,170.2100067138672,174.07000732421875,174.72000122070312,175.60000610351562,178.9600067138672,177.77000427246094,174.61000061035156,174.30999755859375,178.44000244140625,175.05999755859375,171.8300018310547,172.13999938964844,170.08999633789062,165.75,167.66000366210938,170.39999389648438,165.2899932861328,165.07000732421875,167.39999389648438,167.22999572753906,166.4199981689453,161.7899932861328,162.8800048828125,156.8000030517578,156.57000732421875,163.63999938964844,157.64999389648438,157.9600067138672,159.47999572753906,166.02000427246094,156.77000427246094,157.27999877929688,152.05999755859375,154.50999450683594,146.5,142.55999755859375,147.11000061035156,145.5399932861328,149.24000549316406,140.82000732421875,137.35000610351562,137.58999633789062,143.11000061035156,140.36000061035156,140.52000427246094,143.77999877929688,149.63999938964844,148.83999633789062,148.7100067138672,151.2100067138672,145.3800048828125,146.13999938964844,148.7100067138672,147.9600067138672,142.63999938964844,137.1300048828125,131.8800048828125,132.75999450683594,135.42999267578125,130.05999755859375,131.55999755859375,135.8699951171875,135.35000610351562,138.27000427246094,141.66000366210938,141.66000366210938,137.44000244140625,139.22999572753906,136.72000122070312,138.92999267578125,141.55999755859375,142.9199981689453,146.35000610351562,147.0399932861328,144.8699951171875,145.86000061035156,145.49000549316406,148.47000122070312,150.1699981689453,147.07000732421875,151.0,153.0399932861328,155.35000610351562,154.08999633789062,152.9499969482422,151.60000610351562,156.7899932861328,157.35000610351562,162.50999450683594,161.50999450683594,160.00999450683594,166.1300048828125,165.80999755859375,165.35000610351562,164.8699951171875,164.9199981689453,169.24000549316406,168.49000549316406,172.10000610351562,173.19000244140625,173.02999877929688,174.5500030517578,174.14999389648438,171.52000427246094,167.57000732421875,167.22999572753906,167.52999877929688,170.02999877929688,163.6199951171875,161.3800048828125,158.91000366210938,157.22000122070312,157.9600067138672,155.80999755859375,154.52999877929688,155.9600067138672,154.4600067138672,157.3699951171875,163.42999267578125,153.83999633789062,155.30999755859375,152.3699951171875,150.6999969482422,154.47999572753906,156.89999389648438,153.72000122070312,152.74000549316406,150.42999267578125,150.77000427246094,151.75999450683594,149.83999633789062,142.47999572753906,138.1999969482422,142.4499969482422,146.10000610351562,146.39999389648438,145.42999267578125,140.08999633789062,140.4199981689453,138.97999572753906,138.33999633789062,142.99000549316406,138.3800048828125,142.41000366210938,143.75,143.86000061035156,143.38999938964844,147.27000427246094,149.4499969482422,152.33999633789062,149.35000610351562,144.8000030517578,155.74000549316406,153.33999633789062,150.64999389648438,145.02999877929688,138.8800048828125,138.3800048828125,138.9199981689453,139.5,134.8699951171875,146.8699951171875,149.6999969482422,148.27999877929688,150.0399932861328,148.7899932861328,150.72000122070312,151.2899932861328,148.00999450683594,150.17999267578125,151.07000732421875,148.11000061035156,144.22000122070312,141.1699981689453,148.02999877929688,148.30999755859375,147.80999755859375,146.6300048828125,142.91000366210938,140.94000244140625,142.64999389648438,142.16000366210938,144.49000549316406,145.47000122070312,143.2100067138672,136.5,134.50999450683594,132.3699951171875,132.3000030517578,135.4499969482422,132.22999572753906,131.86000061035156,130.02999877929688,126.04000091552734,129.61000061035156,129.92999267578125,125.06999969482422,126.36000061035156,125.0199966430664,129.6199951171875,130.14999389648438,130.72999572753906,133.49000549316406,133.41000366210938,134.75999450683594,135.94000244140625,135.2100067138672,135.27000427246094,137.8699951171875,141.11000061035156,142.52999877929688,141.86000061035156,143.9600067138672,145.92999267578125,143.0,144.2899932861328,145.42999267578125,150.82000732421875,154.5,151.72999572753906,154.64999389648438,151.9199981689453,150.8699951171875,151.00999450683594,153.85000610351562,153.1999969482422,155.3300018310547,153.7100067138672,152.5500030517578,148.47999572753906,148.91000366210938,149.39999389648438,146.7100067138672,147.9199981689453,147.41000366210938,145.30999755859375,145.91000366210938,151.02999877929688,153.8300018310547,151.60000610351562,152.8699951171875,150.58999633789062,148.5,150.47000122070312,152.58999633789062,152.99000549316406,155.85000610351562],\"y\":[84.77667999267578,84.76123809814453,94.3387451171875,93.5252456665039,97.32305908203125,97.8834228515625,97.99362182617188,97.68293762207031,98.80534362792969,98.623291015625,94.62934875488281,93.49797058105469,96.27460479736328,89.07721710205078,94.76567077636719,89.30140686035156,86.4681396484375,90.40660858154297,92.39169311523438,88.96742248535156,78.27848815917969,109.33499908447266,115.8403549194336,101.55731201171875,107.44022369384766,116.20614624023438,124.46829223632812,123.84490203857422,112.50985717773438,104.62648010253906,112.84945678710938,101.9644775390625,112.35489654541016,116.40620422363281,111.98822784423828,113.56175231933594,128.4213104248047,129.94198608398438,132.0157470703125,138.166015625,127.88685607910156,125.34884643554688,126.3069076538086,124.84993743896484,123.93624877929688,110.70977783203125,120.18563842773438,115.3707046508789,118.50457763671875,120.06126403808594,114.82801818847656,117.85395812988281,117.46094512939453,115.41233825683594,110.00411224365234,100.0325927734375,104.56903839111328,112.4352035522461,114.46076965332031,96.76986694335938,93.87306213378906,99.1965560913086,106.13951110839844,118.64901733398438,119.01001739501953,109.4057846069336,119.31784057617188,101.23339080810547,102.14920043945312,98.96659088134766,93.8697738647461,124.707763671875,118.82667541503906,123.7978515625,122.00215148925781,117.5754165649414,102.23665618896484,105.32038879394531,112.39750671386719,119.42848205566406,109.88006591796875,105.67294311523438,114.30624389648438,104.2630386352539,112.84394073486328,108.653076171875,113.51031494140625,95.70340728759766,103.00064849853516,100.83856201171875,117.15365600585938,119.78498840332031,119.12763214111328,122.12107849121094,117.20545196533203,107.1817626953125,116.40528106689453,108.75569915771484,103.75464630126953,107.87586212158203,111.62969207763672,110.31108093261719,106.251708984375,107.28243255615234,109.39789581298828,98.8890609741211,113.09320068359375,124.24028778076172,125.93762969970703,125.26262664794922,126.43463134765625,125.94412231445312,106.23918914794922,110.6361083984375,109.197021484375,102.2696533203125,111.20452880859375,110.13098907470703,121.5391616821289,128.57125854492188,130.08822631835938,134.6382293701172,119.77601623535156,126.67107391357422,138.0917205810547,134.1244354248047,134.20924377441406,132.01834106445312,111.93640899658203,124.50662994384766,116.20462799072266,123.93888092041016,123.5915298461914,130.42718505859375,110.6019287109375,116.8844223022461,119.73068237304688,116.48812103271484,106.44892120361328,106.67628479003906,109.38644409179688,137.38555908203125,147.70742797851562,124.37876892089844,104.23314666748047,139.5341796875,114.22657012939453,117.6733169555664,136.02426147460938,143.14813232421875,131.50811767578125,121.36723327636719,120.04620361328125,120.0553207397461,117.06415557861328,115.34367370605469,120.99864196777344,125.47489166259766,126.9222412109375,122.85160827636719,131.9425048828125,132.7629852294922,131.52479553222656,131.60340881347656,132.96017456054688,116.42516326904297,117.35218048095703,127.69407653808594,122.7982177734375,106.07239532470703,118.0782470703125,111.82195281982422,115.70515441894531,107.94670104980469,122.3062973022461,101.65654754638672,105.33812713623047,125.34658813476562,123.27484130859375,114.26590728759766,101.25631713867188,107.89965057373047,116.8795394897461,114.20682525634766,106.9098129272461,107.8626480102539,112.79350280761719,104.73838806152344,104.8721923828125,102.55858612060547,108.02404022216797,124.11412048339844,131.03713989257812,134.3980712890625,137.18362426757812,135.0159912109375,138.7393341064453,134.08021545410156,135.56707763671875,131.38723754882812,120.48706817626953,115.23182678222656,117.90445709228516,111.12919616699219,114.66712951660156,115.27613830566406,118.8949203491211,115.20758819580078,118.86747741699219,114.09656524658203,124.9673843383789,121.61112976074219,122.63945770263672,116.87928009033203,132.7936248779297,127.35238647460938,124.22266387939453,115.039306640625,116.37310791015625,116.48906707763672,125.49268341064453,115.11699676513672,105.25028991699219,112.22344970703125,107.5406723022461,109.25627899169922,110.78199005126953,112.98015594482422,111.3666763305664,110.63176727294922,109.27529907226562,115.4698715209961,110.22647094726562,111.07606506347656,108.34235382080078,109.16552734375,114.99645233154297,108.7704849243164,107.5799560546875,124.45500946044922,113.2474594116211,116.07852935791016,133.0430908203125,113.86117553710938,120.65573120117188,132.07875061035156,117.93366241455078,120.18022918701172,116.65869140625,115.87521362304688,117.52607727050781,118.52398681640625,117.76702117919922,137.4018096923828,144.2421112060547,148.05955505371094,146.60813903808594,148.32675170898438,146.01368713378906,133.79296875,150.87039184570312,136.82504272460938,134.8600616455078,117.41351318359375,123.95405578613281,123.17639923095703,129.93862915039062,122.64082336425781,128.81515502929688,128.33619689941406,122.90017700195312,123.0755615234375,127.3465576171875,127.2284164428711,126.85543060302734,126.09326934814453,127.3310317993164,124.36967468261719,125.19296264648438,124.22220611572266,120.69464111328125,123.03205871582031,121.66302490234375,127.17997741699219,141.06448364257812,124.81656646728516,121.94342041015625,122.06916809082031,130.2008056640625,132.40029907226562,129.47470092773438,124.59231567382812,118.90164184570312,129.31651306152344,125.52188873291016,124.8318099975586,143.2818145751953,128.907470703125,151.48500061035156,137.61329650878906,141.11695861816406,129.7943115234375,135.13534545898438,135.24240112304688,152.81842041015625,150.2197723388672,154.78009033203125,141.348388671875,130.047119140625,130.81472778320312,138.01327514648438,133.42945861816406,132.4802703857422,124.39630126953125,126.09300231933594,124.72662353515625,142.5426025390625,131.74281311035156,130.6844024658203,121.7157974243164,128.3902587890625,121.69453430175781,124.029541015625,122.89513397216797,116.99906158447266,118.9061279296875,119.00822448730469,118.67878723144531,139.226318359375,147.43002319335938,151.12294006347656,146.97706604003906,133.3553466796875,128.45187377929688,119.7016372680664,131.28500366210938,128.5849151611328,125.58768463134766,123.67841339111328,126.69865417480469,127.0820541381836,128.24334716796875,126.06388854980469,133.6340789794922,130.001220703125,127.0947036743164,128.18943786621094,132.96751403808594,126.6441879272461,120.98174285888672,143.67324829101562,163.95848083496094,166.1338653564453,167.10511779785156,165.51873779296875,129.0605926513672,128.4904327392578,155.9647216796875,141.15234375,139.69744873046875,130.58169555664062,129.99098205566406,165.1704559326172,175.5824737548828,177.58474731445312,188.23455810546875,178.8095245361328,175.2060089111328,181.66152954101562,147.53524780273438,157.15301513671875,140.8762969970703,154.80596923828125,154.53028869628906,145.95565795898438,147.3606719970703,151.76283264160156,169.09910583496094,158.94129943847656,136.9591522216797,153.1024932861328,157.3507537841797,164.20899963378906,151.8904571533203,154.4340057373047,161.05796813964844,166.8672637939453,166.81541442871094,157.2291259765625,149.93768310546875,153.0695037841797,161.70506286621094,161.60012817382812,171.8415069580078,182.2688446044922,179.54869079589844,175.42593383789062,142.0247802734375,136.59237670898438,142.15499877929688,167.1608123779297,195.6181182861328,177.35862731933594,174.5986328125,140.71127319335938,138.31027221679688,151.3966064453125,161.62176513671875,147.29591369628906,136.4873504638672,144.68136596679688,165.09280395507812,162.2985382080078,154.2379608154297,161.39309692382812,157.65902709960938,151.9169921875,160.3357391357422,176.5382537841797,143.0684356689453,135.5377197265625,141.78533935546875,147.18626403808594,142.3858642578125,132.08258056640625,151.5123748779297,169.1345977783203,174.18556213378906,140.98377990722656,140.73207092285156,144.37014770507812,144.87814331054688,131.9763946533203,168.33880615234375,175.62158203125,178.0829620361328,184.47300720214844,181.62841796875,180.89974975585938,184.26832580566406,179.6596221923828,148.1934356689453,135.3663330078125,151.8590545654297,158.64739990234375,156.02696228027344,150.29550170898438,169.28919982910156,168.82135009765625,151.41366577148438,169.04946899414062,179.75205993652344,150.2217559814453,138.84413146972656,153.10458374023438,158.0673828125,142.1685333251953,157.83084106445312,156.44073486328125,148.30406188964844,154.22882080078125,171.29505920410156,156.73626708984375,123.14801025390625,150.80274963378906,140.6479949951172,144.43252563476562,130.4835205078125,160.71466064453125,156.65896606445312,154.281005859375,152.6459503173828,153.4795379638672,119.20260620117188,151.72860717773438,147.27883911132812,121.04450225830078,145.54855346679688,149.14434814453125,134.81150817871094,112.68463897705078,127.69093322753906,148.3898162841797,152.48072814941406,153.4973907470703,125.6526107788086,120.62120819091797,130.27044677734375,141.93771362304688,144.76605224609375,143.93807983398438,142.53860473632812,146.00856018066406,145.08213806152344,151.85305786132812,141.7523956298828,123.81103515625,123.54044342041016,110.77242279052734,144.59608459472656,144.26416015625,137.41021728515625,142.42001342773438,115.76934814453125,116.21467590332031,116.5318832397461,116.70684814453125,128.65992736816406,149.6999053955078,147.4168243408203,148.99362182617188,133.841064453125,125.71000671386719,139.45362854003906,118.8860855102539,134.88137817382812,149.85977172851562,145.27081298828125,154.63177490234375,148.71929931640625,121.8136978149414,138.8995819091797,123.8268814086914,137.71678161621094,163.16075134277344,142.73785400390625,171.46864318847656,169.1403350830078,159.0714874267578,157.7376251220703,131.50177001953125,147.4071502685547,132.33970642089844,143.4082489013672,169.54388427734375,149.93385314941406,174.90731811523438,165.68505859375,149.42269897460938,143.97691345214844,144.21128845214844,146.74472045898438,174.26795959472656,171.56471252441406,168.45298767089844,156.82122802734375,168.9210662841797,171.10731506347656,172.6061553955078,167.17689514160156,155.06871032714844,142.20175170898438,130.2337188720703,153.78897094726562,137.57656860351562,136.82522583007812,134.34742736816406,141.57717895507812,130.66941833496094,146.3214874267578,151.29969787597656,137.9187469482422,128.1228485107422,130.88442993164062,135.8516387939453,154.81021118164062,155.83135986328125,141.92002868652344,133.22731018066406,151.77792358398438,154.19700622558594,144.03968811035156,127.09416198730469,126.28800964355469,125.42021179199219,127.8473129272461,138.56008911132812,131.09747314453125,125.019775390625,125.370849609375,121.85916137695312,120.59624481201172,148.5630645751953,150.5516357421875,154.3584747314453,150.97596740722656,110.47738647460938,154.04885864257812,142.21600341796875,141.5290985107422,140.3602294921875,141.06361389160156,144.09182739257812,154.43603515625,165.05194091796875,146.43788146972656,129.73377990722656,124.74488830566406,120.38618469238281,159.73670959472656,152.9344482421875,153.71469116210938,152.72096252441406,122.17118835449219,123.80574035644531,132.312255859375,142.0048828125,140.4215850830078,121.57250213623047,129.43002319335938,139.9847412109375,146.15806579589844,132.8095245361328,131.47499084472656,123.8181381225586,125.74268341064453,130.2098388671875,136.0780792236328,129.9942626953125,140.0966339111328,132.70628356933594,131.6199951171875,133.65660095214844,141.16212463378906,141.1776885986328,140.02554321289062,138.35861206054688,129.3011932373047,121.87507629394531,118.61111450195312,130.0723419189453,134.75123596191406,122.12411499023438,108.78502655029297,117.84586334228516,110.96710205078125,107.79305267333984,135.16769409179688,135.03013610839844,138.4945068359375,139.56488037109375,136.6730194091797,124.68415832519531,132.39053344726562,138.75025939941406,141.76820373535156,144.73077392578125,148.25064086914062,149.7326202392578,134.3656005859375,140.78408813476562,122.9952163696289,124.4360122680664,157.0330047607422,151.20553588867188,159.82760620117188,153.7724151611328,134.85369873046875,123.66305541992188,127.62297058105469,127.412109375,131.46749877929688,130.7026824951172,137.85826110839844,129.25848388671875,130.5738067626953,140.39234924316406,150.42800903320312,143.1682891845703,141.7051239013672,142.0525665283203,122.39154815673828,120.13920593261719,129.1752166748047,124.26152801513672],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Ground Truth\",\"x\":[87.43000030517578,89.71749877929688,91.63249969482422,90.01499938964844,91.20999908447266,88.40750122070312,90.44499969482422,91.19999694824219,91.02749633789062,91.02749633789062,93.4625015258789,93.17250061035156,95.34249877929688,95.75250244140625,95.91999816894531,95.47750091552734,97.05750274658203,97.7249984741211,96.52249908447266,96.32749938964844,98.35749816894531,97.0,97.27249908447266,92.84500122070312,92.61499786376953,94.80999755859375,93.25250244140625,95.04000091552734,96.19000244140625,106.26000213623047,108.9375,109.66500091552734,110.0625,113.90249633789062,111.11250305175781,112.72750091552734,109.375,113.01000213623047,115.01000213623047,114.90750122070312,114.60749816894531,115.5625,115.7074966430664,118.2750015258789,124.37000274658203,125.85749816894531,124.82499694824219,126.52249908447266,125.01000213623047,124.80750274658203,129.0399932861328,134.17999267578125,131.39999389648438,120.87999725341797,120.95999908447266,112.81999969482422,117.31999969482422,113.48999786376953,112.0,115.36000061035156,115.54000091552734,112.12999725341797,110.33999633789062,106.83999633789062,110.08000183105469,111.80999755859375,107.12000274658203,108.22000122070312,112.27999877929688,114.95999908447266,114.08999633789062,115.80999755859375,116.79000091552734,113.0199966430664,116.5,113.16000366210938,115.08000183105469,114.97000122070312,116.97000122070312,124.4000015258789,121.0999984741211,121.19000244140625,120.70999908447266,119.0199966430664,115.9800033569336,117.51000213623047,116.87000274658203,115.75,115.04000091552734,115.05000305175781,116.5999984741211,111.19999694824219,115.31999969482422,108.86000061035156,108.7699966430664,110.44000244140625,114.94999694824219,119.02999877929688,118.69000244140625,116.31999969482422,115.97000122070312,119.48999786376953,119.20999908447266,119.26000213623047,120.30000305175781,119.38999938964844,118.02999877929688,118.63999938964844,117.33999633789062,113.8499984741211,115.16999816894531,116.02999877929688,116.58999633789062,119.05000305175781,122.72000122070312,123.08000183105469,122.94000244140625,122.25,123.75,124.37999725341797,121.77999877929688,123.23999786376953,122.41000366210938,121.77999877929688,127.87999725341797,127.80999755859375,128.6999969482422,126.66000366210938,128.22999572753906,131.8800048828125,130.9600067138672,131.97000122070312,136.69000244140625,134.8699951171875,133.72000122070312,132.69000244140625,129.41000366210938,131.00999450683594,126.5999984741211,130.9199981689453,132.0500030517578,128.97999572753906,128.8000030517578,130.88999938964844,128.91000366210938,127.13999938964844,127.83000183105469,132.02999877929688,136.8699951171875,139.07000732421875,142.9199981689453,143.16000366210938,142.05999755859375,137.08999633789062,131.9600067138672,134.13999938964844,134.99000549316406,133.94000244140625,137.38999938964844,136.75999450683594,136.91000366210938,136.00999450683594,135.38999938964844,135.1300048828125,135.3699951171875,133.19000244140625,130.83999633789062,129.7100067138672,129.8699951171875,126.0,125.86000061035156,125.3499984741211,120.98999786376953,121.26000213623047,127.79000091552734,125.12000274658203,122.05999755859375,120.12999725341797,121.41999816894531,116.36000061035156,121.08999633789062,119.9800033569336,121.95999908447266,121.02999877929688,123.98999786376953,125.56999969482422,124.76000213623047,120.52999877929688,119.98999786376953,123.38999938964844,122.54000091552734,120.08999633789062,120.58999633789062,121.20999908447266,121.38999938964844,119.9000015258789,122.1500015258789,123.0,125.9000015258789,126.20999908447266,127.9000015258789,130.36000061035156,133.0,131.24000549316406,134.42999267578125,132.02999877929688,134.5,134.16000366210938,134.83999633789062,133.11000061035156,133.5,131.94000244140625,134.32000732421875,134.72000122070312,134.38999938964844,133.5800018310547,133.47999572753906,131.4600067138672,132.5399932861328,127.8499984741211,128.10000610351562,129.74000549316406,130.2100067138672,126.8499984741211,125.91000366210938,122.7699966430664,124.97000122070312,127.44999694824219,126.2699966430664,124.8499984741211,124.69000244140625,127.30999755859375,125.43000030517578,127.0999984741211,126.9000015258789,126.8499984741211,125.27999877929688,124.61000061035156,124.27999877929688,125.05999755859375,123.54000091552734,125.88999938964844,125.9000015258789,126.73999786376953,127.12999725341797,126.11000061035156,127.3499984741211,130.47999572753906,129.63999938964844,130.14999389648438,131.7899932861328,130.4600067138672,132.3000030517578,133.97999572753906,133.6999969482422,133.41000366210938,133.11000061035156,134.77999877929688,136.3300018310547,136.9600067138672,137.27000427246094,139.9600067138672,142.02000427246094,144.57000732421875,143.24000549316406,145.11000061035156,144.5,145.63999938964844,149.14999389648438,148.47999572753906,146.38999938964844,142.4499969482422,146.14999389648438,145.39999389648438,146.8000030517578,148.55999755859375,148.99000549316406,146.77000427246094,144.97999572753906,145.63999938964844,145.86000061035156,145.52000427246094,147.36000061035156,146.9499969482422,147.05999755859375,146.13999938964844,146.08999633789062,145.60000610351562,145.86000061035156,148.88999938964844,149.10000610351562,151.1199951171875,150.19000244140625,146.36000061035156,146.6999969482422,148.19000244140625,149.7100067138672,149.6199951171875,148.36000061035156,147.5399932861328,148.60000610351562,153.1199951171875,151.8300018310547,152.50999450683594,153.64999389648438,154.3000030517578,156.69000244140625,155.11000061035156,154.07000732421875,148.97000122070312,149.5500030517578,148.1199951171875,149.02999877929688,148.7899932861328,146.05999755859375,142.94000244140625,143.42999267578125,145.85000610351562,146.8300018310547,146.9199981689453,145.3699951171875,141.91000366210938,142.8300018310547,141.5,142.64999389648438,139.13999938964844,141.11000061035156,142.0,143.2899932861328,142.89999389648438,142.80999755859375,141.50999450683594,140.91000366210938,143.75999450683594,144.83999633789062,146.5500030517578,148.75999450683594,149.25999450683594,149.47999572753906,148.69000244140625,148.63999938964844,149.32000732421875,148.85000610351562,152.57000732421875,149.8000030517578,148.9600067138672,150.02000427246094,151.49000549316406,150.9600067138672,151.27999877929688,150.44000244140625,150.80999755859375,147.9199981689453,147.8699951171875,149.99000549316406,150.0,151.0,153.49000549316406,157.8699951171875,160.5500030517578,161.02000427246094,161.41000366210938,161.94000244140625,156.80999755859375,160.24000549316406,165.3000030517578,164.77000427246094,163.75999450683594,161.83999633789062,165.32000732421875,171.17999267578125,175.0800018310547,174.55999755859375,179.4499969482422,175.74000549316406,174.3300018310547,179.3000030517578,172.25999450683594,171.13999938964844,169.75,172.99000549316406,175.63999938964844,176.27999877929688,180.3300018310547,179.2899932861328,179.3800048828125,178.1999969482422,177.57000732421875,182.00999450683594,179.6999969482422,174.9199981689453,172.0,172.1699981689453,172.19000244140625,175.0800018310547,175.52999877929688,172.19000244140625,173.07000732421875,169.8000030517578,166.22999572753906,164.50999450683594,162.41000366210938,161.6199951171875,159.77999877929688,159.69000244140625,159.22000122070312,170.3300018310547,174.77999877929688,174.61000061035156,175.83999633789062,172.89999389648438,172.38999938964844,171.66000366210938,174.8300018310547,176.27999877929688,172.1199951171875,168.63999938964844,168.8800048828125,172.7899932861328,172.5500030517578,168.8800048828125,167.3000030517578,164.32000732421875,160.07000732421875,162.74000549316406,164.85000610351562,165.1199951171875,163.1999969482422,166.55999755859375,166.22999572753906,163.1699981689453,159.3000030517578,157.44000244140625,162.9499969482422,158.52000427246094,154.72999572753906,150.6199951171875,155.08999633789062,159.58999633789062,160.6199951171875,163.97999572753906,165.3800048828125,168.82000732421875,170.2100067138672,174.07000732421875,174.72000122070312,175.60000610351562,178.9600067138672,177.77000427246094,174.61000061035156,174.30999755859375,178.44000244140625,175.05999755859375,171.8300018310547,172.13999938964844,170.08999633789062,165.75,167.66000366210938,170.39999389648438,165.2899932861328,165.07000732421875,167.39999389648438,167.22999572753906,166.4199981689453,161.7899932861328,162.8800048828125,156.8000030517578,156.57000732421875,163.63999938964844,157.64999389648438,157.9600067138672,159.47999572753906,166.02000427246094,156.77000427246094,157.27999877929688,152.05999755859375,154.50999450683594,146.5,142.55999755859375,147.11000061035156,145.5399932861328,149.24000549316406,140.82000732421875,137.35000610351562,137.58999633789062,143.11000061035156,140.36000061035156,140.52000427246094,143.77999877929688,149.63999938964844,148.83999633789062,148.7100067138672,151.2100067138672,145.3800048828125,146.13999938964844,148.7100067138672,147.9600067138672,142.63999938964844,137.1300048828125,131.8800048828125,132.75999450683594,135.42999267578125,130.05999755859375,131.55999755859375,135.8699951171875,135.35000610351562,138.27000427246094,141.66000366210938,141.66000366210938,137.44000244140625,139.22999572753906,136.72000122070312,138.92999267578125,141.55999755859375,142.9199981689453,146.35000610351562,147.0399932861328,144.8699951171875,145.86000061035156,145.49000549316406,148.47000122070312,150.1699981689453,147.07000732421875,151.0,153.0399932861328,155.35000610351562,154.08999633789062,152.9499969482422,151.60000610351562,156.7899932861328,157.35000610351562,162.50999450683594,161.50999450683594,160.00999450683594,166.1300048828125,165.80999755859375,165.35000610351562,164.8699951171875,164.9199981689453,169.24000549316406,168.49000549316406,172.10000610351562,173.19000244140625,173.02999877929688,174.5500030517578,174.14999389648438,171.52000427246094,167.57000732421875,167.22999572753906,167.52999877929688,170.02999877929688,163.6199951171875,161.3800048828125,158.91000366210938,157.22000122070312,157.9600067138672,155.80999755859375,154.52999877929688,155.9600067138672,154.4600067138672,157.3699951171875,163.42999267578125,153.83999633789062,155.30999755859375,152.3699951171875,150.6999969482422,154.47999572753906,156.89999389648438,153.72000122070312,152.74000549316406,150.42999267578125,150.77000427246094,151.75999450683594,149.83999633789062,142.47999572753906,138.1999969482422,142.4499969482422,146.10000610351562,146.39999389648438,145.42999267578125,140.08999633789062,140.4199981689453,138.97999572753906,138.33999633789062,142.99000549316406,138.3800048828125,142.41000366210938,143.75,143.86000061035156,143.38999938964844,147.27000427246094,149.4499969482422,152.33999633789062,149.35000610351562,144.8000030517578,155.74000549316406,153.33999633789062,150.64999389648438,145.02999877929688,138.8800048828125,138.3800048828125,138.9199981689453,139.5,134.8699951171875,146.8699951171875,149.6999969482422,148.27999877929688,150.0399932861328,148.7899932861328,150.72000122070312,151.2899932861328,148.00999450683594,150.17999267578125,151.07000732421875,148.11000061035156,144.22000122070312,141.1699981689453,148.02999877929688,148.30999755859375,147.80999755859375,146.6300048828125,142.91000366210938,140.94000244140625,142.64999389648438,142.16000366210938,144.49000549316406,145.47000122070312,143.2100067138672,136.5,134.50999450683594,132.3699951171875,132.3000030517578,135.4499969482422,132.22999572753906,131.86000061035156,130.02999877929688,126.04000091552734,129.61000061035156,129.92999267578125,125.06999969482422,126.36000061035156,125.0199966430664,129.6199951171875,130.14999389648438,130.72999572753906,133.49000549316406,133.41000366210938,134.75999450683594,135.94000244140625,135.2100067138672,135.27000427246094,137.8699951171875,141.11000061035156,142.52999877929688,141.86000061035156,143.9600067138672,145.92999267578125,143.0,144.2899932861328,145.42999267578125,150.82000732421875,154.5,151.72999572753906,154.64999389648438,151.9199981689453,150.8699951171875,151.00999450683594,153.85000610351562,153.1999969482422,155.3300018310547,153.7100067138672,152.5500030517578,148.47999572753906,148.91000366210938,149.39999389648438,146.7100067138672,147.9199981689453,147.41000366210938,145.30999755859375,145.91000366210938,151.02999877929688,153.8300018310547,151.60000610351562,152.8699951171875,150.58999633789062,148.5,150.47000122070312,152.58999633789062,152.99000549316406,155.85000610351562],\"y\":[87.43000030517578,89.71749877929688,91.63249969482422,90.01499938964844,91.20999908447266,88.40750122070312,90.44499969482422,91.19999694824219,91.02749633789062,91.02749633789062,93.4625015258789,93.17250061035156,95.34249877929688,95.75250244140625,95.91999816894531,95.47750091552734,97.05750274658203,97.7249984741211,96.52249908447266,96.32749938964844,98.35749816894531,97.0,97.27249908447266,92.84500122070312,92.61499786376953,94.80999755859375,93.25250244140625,95.04000091552734,96.19000244140625,106.26000213623047,108.9375,109.66500091552734,110.0625,113.90249633789062,111.11250305175781,112.72750091552734,109.375,113.01000213623047,115.01000213623047,114.90750122070312,114.60749816894531,115.5625,115.7074966430664,118.2750015258789,124.37000274658203,125.85749816894531,124.82499694824219,126.52249908447266,125.01000213623047,124.80750274658203,129.0399932861328,134.17999267578125,131.39999389648438,120.87999725341797,120.95999908447266,112.81999969482422,117.31999969482422,113.48999786376953,112.0,115.36000061035156,115.54000091552734,112.12999725341797,110.33999633789062,106.83999633789062,110.08000183105469,111.80999755859375,107.12000274658203,108.22000122070312,112.27999877929688,114.95999908447266,114.08999633789062,115.80999755859375,116.79000091552734,113.0199966430664,116.5,113.16000366210938,115.08000183105469,114.97000122070312,116.97000122070312,124.4000015258789,121.0999984741211,121.19000244140625,120.70999908447266,119.0199966430664,115.9800033569336,117.51000213623047,116.87000274658203,115.75,115.04000091552734,115.05000305175781,116.5999984741211,111.19999694824219,115.31999969482422,108.86000061035156,108.7699966430664,110.44000244140625,114.94999694824219,119.02999877929688,118.69000244140625,116.31999969482422,115.97000122070312,119.48999786376953,119.20999908447266,119.26000213623047,120.30000305175781,119.38999938964844,118.02999877929688,118.63999938964844,117.33999633789062,113.8499984741211,115.16999816894531,116.02999877929688,116.58999633789062,119.05000305175781,122.72000122070312,123.08000183105469,122.94000244140625,122.25,123.75,124.37999725341797,121.77999877929688,123.23999786376953,122.41000366210938,121.77999877929688,127.87999725341797,127.80999755859375,128.6999969482422,126.66000366210938,128.22999572753906,131.8800048828125,130.9600067138672,131.97000122070312,136.69000244140625,134.8699951171875,133.72000122070312,132.69000244140625,129.41000366210938,131.00999450683594,126.5999984741211,130.9199981689453,132.0500030517578,128.97999572753906,128.8000030517578,130.88999938964844,128.91000366210938,127.13999938964844,127.83000183105469,132.02999877929688,136.8699951171875,139.07000732421875,142.9199981689453,143.16000366210938,142.05999755859375,137.08999633789062,131.9600067138672,134.13999938964844,134.99000549316406,133.94000244140625,137.38999938964844,136.75999450683594,136.91000366210938,136.00999450683594,135.38999938964844,135.1300048828125,135.3699951171875,133.19000244140625,130.83999633789062,129.7100067138672,129.8699951171875,126.0,125.86000061035156,125.3499984741211,120.98999786376953,121.26000213623047,127.79000091552734,125.12000274658203,122.05999755859375,120.12999725341797,121.41999816894531,116.36000061035156,121.08999633789062,119.9800033569336,121.95999908447266,121.02999877929688,123.98999786376953,125.56999969482422,124.76000213623047,120.52999877929688,119.98999786376953,123.38999938964844,122.54000091552734,120.08999633789062,120.58999633789062,121.20999908447266,121.38999938964844,119.9000015258789,122.1500015258789,123.0,125.9000015258789,126.20999908447266,127.9000015258789,130.36000061035156,133.0,131.24000549316406,134.42999267578125,132.02999877929688,134.5,134.16000366210938,134.83999633789062,133.11000061035156,133.5,131.94000244140625,134.32000732421875,134.72000122070312,134.38999938964844,133.5800018310547,133.47999572753906,131.4600067138672,132.5399932861328,127.8499984741211,128.10000610351562,129.74000549316406,130.2100067138672,126.8499984741211,125.91000366210938,122.7699966430664,124.97000122070312,127.44999694824219,126.2699966430664,124.8499984741211,124.69000244140625,127.30999755859375,125.43000030517578,127.0999984741211,126.9000015258789,126.8499984741211,125.27999877929688,124.61000061035156,124.27999877929688,125.05999755859375,123.54000091552734,125.88999938964844,125.9000015258789,126.73999786376953,127.12999725341797,126.11000061035156,127.3499984741211,130.47999572753906,129.63999938964844,130.14999389648438,131.7899932861328,130.4600067138672,132.3000030517578,133.97999572753906,133.6999969482422,133.41000366210938,133.11000061035156,134.77999877929688,136.3300018310547,136.9600067138672,137.27000427246094,139.9600067138672,142.02000427246094,144.57000732421875,143.24000549316406,145.11000061035156,144.5,145.63999938964844,149.14999389648438,148.47999572753906,146.38999938964844,142.4499969482422,146.14999389648438,145.39999389648438,146.8000030517578,148.55999755859375,148.99000549316406,146.77000427246094,144.97999572753906,145.63999938964844,145.86000061035156,145.52000427246094,147.36000061035156,146.9499969482422,147.05999755859375,146.13999938964844,146.08999633789062,145.60000610351562,145.86000061035156,148.88999938964844,149.10000610351562,151.1199951171875,150.19000244140625,146.36000061035156,146.6999969482422,148.19000244140625,149.7100067138672,149.6199951171875,148.36000061035156,147.5399932861328,148.60000610351562,153.1199951171875,151.8300018310547,152.50999450683594,153.64999389648438,154.3000030517578,156.69000244140625,155.11000061035156,154.07000732421875,148.97000122070312,149.5500030517578,148.1199951171875,149.02999877929688,148.7899932861328,146.05999755859375,142.94000244140625,143.42999267578125,145.85000610351562,146.8300018310547,146.9199981689453,145.3699951171875,141.91000366210938,142.8300018310547,141.5,142.64999389648438,139.13999938964844,141.11000061035156,142.0,143.2899932861328,142.89999389648438,142.80999755859375,141.50999450683594,140.91000366210938,143.75999450683594,144.83999633789062,146.5500030517578,148.75999450683594,149.25999450683594,149.47999572753906,148.69000244140625,148.63999938964844,149.32000732421875,148.85000610351562,152.57000732421875,149.8000030517578,148.9600067138672,150.02000427246094,151.49000549316406,150.9600067138672,151.27999877929688,150.44000244140625,150.80999755859375,147.9199981689453,147.8699951171875,149.99000549316406,150.0,151.0,153.49000549316406,157.8699951171875,160.5500030517578,161.02000427246094,161.41000366210938,161.94000244140625,156.80999755859375,160.24000549316406,165.3000030517578,164.77000427246094,163.75999450683594,161.83999633789062,165.32000732421875,171.17999267578125,175.0800018310547,174.55999755859375,179.4499969482422,175.74000549316406,174.3300018310547,179.3000030517578,172.25999450683594,171.13999938964844,169.75,172.99000549316406,175.63999938964844,176.27999877929688,180.3300018310547,179.2899932861328,179.3800048828125,178.1999969482422,177.57000732421875,182.00999450683594,179.6999969482422,174.9199981689453,172.0,172.1699981689453,172.19000244140625,175.0800018310547,175.52999877929688,172.19000244140625,173.07000732421875,169.8000030517578,166.22999572753906,164.50999450683594,162.41000366210938,161.6199951171875,159.77999877929688,159.69000244140625,159.22000122070312,170.3300018310547,174.77999877929688,174.61000061035156,175.83999633789062,172.89999389648438,172.38999938964844,171.66000366210938,174.8300018310547,176.27999877929688,172.1199951171875,168.63999938964844,168.8800048828125,172.7899932861328,172.5500030517578,168.8800048828125,167.3000030517578,164.32000732421875,160.07000732421875,162.74000549316406,164.85000610351562,165.1199951171875,163.1999969482422,166.55999755859375,166.22999572753906,163.1699981689453,159.3000030517578,157.44000244140625,162.9499969482422,158.52000427246094,154.72999572753906,150.6199951171875,155.08999633789062,159.58999633789062,160.6199951171875,163.97999572753906,165.3800048828125,168.82000732421875,170.2100067138672,174.07000732421875,174.72000122070312,175.60000610351562,178.9600067138672,177.77000427246094,174.61000061035156,174.30999755859375,178.44000244140625,175.05999755859375,171.8300018310547,172.13999938964844,170.08999633789062,165.75,167.66000366210938,170.39999389648438,165.2899932861328,165.07000732421875,167.39999389648438,167.22999572753906,166.4199981689453,161.7899932861328,162.8800048828125,156.8000030517578,156.57000732421875,163.63999938964844,157.64999389648438,157.9600067138672,159.47999572753906,166.02000427246094,156.77000427246094,157.27999877929688,152.05999755859375,154.50999450683594,146.5,142.55999755859375,147.11000061035156,145.5399932861328,149.24000549316406,140.82000732421875,137.35000610351562,137.58999633789062,143.11000061035156,140.36000061035156,140.52000427246094,143.77999877929688,149.63999938964844,148.83999633789062,148.7100067138672,151.2100067138672,145.3800048828125,146.13999938964844,148.7100067138672,147.9600067138672,142.63999938964844,137.1300048828125,131.8800048828125,132.75999450683594,135.42999267578125,130.05999755859375,131.55999755859375,135.8699951171875,135.35000610351562,138.27000427246094,141.66000366210938,141.66000366210938,137.44000244140625,139.22999572753906,136.72000122070312,138.92999267578125,141.55999755859375,142.9199981689453,146.35000610351562,147.0399932861328,144.8699951171875,145.86000061035156,145.49000549316406,148.47000122070312,150.1699981689453,147.07000732421875,151.0,153.0399932861328,155.35000610351562,154.08999633789062,152.9499969482422,151.60000610351562,156.7899932861328,157.35000610351562,162.50999450683594,161.50999450683594,160.00999450683594,166.1300048828125,165.80999755859375,165.35000610351562,164.8699951171875,164.9199981689453,169.24000549316406,168.49000549316406,172.10000610351562,173.19000244140625,173.02999877929688,174.5500030517578,174.14999389648438,171.52000427246094,167.57000732421875,167.22999572753906,167.52999877929688,170.02999877929688,163.6199951171875,161.3800048828125,158.91000366210938,157.22000122070312,157.9600067138672,155.80999755859375,154.52999877929688,155.9600067138672,154.4600067138672,157.3699951171875,163.42999267578125,153.83999633789062,155.30999755859375,152.3699951171875,150.6999969482422,154.47999572753906,156.89999389648438,153.72000122070312,152.74000549316406,150.42999267578125,150.77000427246094,151.75999450683594,149.83999633789062,142.47999572753906,138.1999969482422,142.4499969482422,146.10000610351562,146.39999389648438,145.42999267578125,140.08999633789062,140.4199981689453,138.97999572753906,138.33999633789062,142.99000549316406,138.3800048828125,142.41000366210938,143.75,143.86000061035156,143.38999938964844,147.27000427246094,149.4499969482422,152.33999633789062,149.35000610351562,144.8000030517578,155.74000549316406,153.33999633789062,150.64999389648438,145.02999877929688,138.8800048828125,138.3800048828125,138.9199981689453,139.5,134.8699951171875,146.8699951171875,149.6999969482422,148.27999877929688,150.0399932861328,148.7899932861328,150.72000122070312,151.2899932861328,148.00999450683594,150.17999267578125,151.07000732421875,148.11000061035156,144.22000122070312,141.1699981689453,148.02999877929688,148.30999755859375,147.80999755859375,146.6300048828125,142.91000366210938,140.94000244140625,142.64999389648438,142.16000366210938,144.49000549316406,145.47000122070312,143.2100067138672,136.5,134.50999450683594,132.3699951171875,132.3000030517578,135.4499969482422,132.22999572753906,131.86000061035156,130.02999877929688,126.04000091552734,129.61000061035156,129.92999267578125,125.06999969482422,126.36000061035156,125.0199966430664,129.6199951171875,130.14999389648438,130.72999572753906,133.49000549316406,133.41000366210938,134.75999450683594,135.94000244140625,135.2100067138672,135.27000427246094,137.8699951171875,141.11000061035156,142.52999877929688,141.86000061035156,143.9600067138672,145.92999267578125,143.0,144.2899932861328,145.42999267578125,150.82000732421875,154.5,151.72999572753906,154.64999389648438,151.9199981689453,150.8699951171875,151.00999450683594,153.85000610351562,153.1999969482422,155.3300018310547,153.7100067138672,152.5500030517578,148.47999572753906,148.91000366210938,149.39999389648438,146.7100067138672,147.9199981689453,147.41000366210938,145.30999755859375,145.91000366210938,151.02999877929688,153.8300018310547,151.60000610351562,152.8699951171875,150.58999633789062,148.5,150.47000122070312,152.58999633789062,152.99000549316406,155.85000610351562],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Stock\"},\"xaxis\":{\"title\":{\"text\":\"Date\"}},\"yaxis\":{\"title\":{\"text\":\"Close\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9d805f06-573d-4274-8b5c-95b16ea5d7cb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred frequency is: B\n",
            "Model Number: 1 with model ARIMA in generation 0 of 2 with params {\"p\": 4, \"d\": 0, \"q\": 12, \"regression_type\": null} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 2 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Mean\"} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 3 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Mean\"} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 4 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Mean\"} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {\"lag_1\": 7, \"method\": \"Mean\"}, \"1\": {\"model\": \"middle\", \"decimals\": 2, \"on_transform\": true, \"on_inverse\": false}}}\n",
            "Model Number: 5 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": 3, \"min_samples_split\": 2}}, \"datepart_method\": \"recurring\", \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 6 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"SVM\", \"model_params\": {}}, \"datepart_method\": \"recurring\", \"regression_type\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}, \"1\": {\"fixed\": true, \"window\": 10}}}\n",
            "[LibLinear]Model Number: 7 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"MLP\", \"model_params\": {\"hidden_layer_sizes\": [25, 15, 25], \"max_iter\": 1000, \"activation\": \"tanh\", \"solver\": \"lbfgs\", \"early_stopping\": false, \"learning_rate_init\": 0.001}}, \"datepart_method\": \"recurring\", \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 8 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"KerasRNN\", \"model_params\": {\"kernel_initializer\": \"glorot_uniform\", \"epochs\": 50, \"batch_size\": 32, \"optimizer\": \"adam\", \"loss\": \"Huber\", \"hidden_layer_sizes\": [32, 32, 32], \"rnn_type\": \"GRU\"}}, \"datepart_method\": \"recurring\", \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"Round\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"middle\", \"decimals\": 1, \"on_transform\": true, \"on_inverse\": false}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Epoch 1/50\n",
            "89/89 - 9s - loss: 0.0500 - 9s/epoch - 103ms/step\n",
            "Epoch 2/50\n",
            "89/89 - 1s - loss: 0.0435 - 506ms/epoch - 6ms/step\n",
            "Epoch 3/50\n",
            "89/89 - 1s - loss: 0.0433 - 502ms/epoch - 6ms/step\n",
            "Epoch 4/50\n",
            "89/89 - 1s - loss: 0.0429 - 503ms/epoch - 6ms/step\n",
            "Epoch 5/50\n",
            "89/89 - 1s - loss: 0.0424 - 514ms/epoch - 6ms/step\n",
            "Epoch 6/50\n",
            "89/89 - 1s - loss: 0.0424 - 543ms/epoch - 6ms/step\n",
            "Epoch 7/50\n",
            "89/89 - 1s - loss: 0.0422 - 529ms/epoch - 6ms/step\n",
            "Epoch 8/50\n",
            "89/89 - 1s - loss: 0.0420 - 512ms/epoch - 6ms/step\n",
            "Epoch 9/50\n",
            "89/89 - 1s - loss: 0.0424 - 551ms/epoch - 6ms/step\n",
            "Epoch 10/50\n",
            "89/89 - 1s - loss: 0.0420 - 507ms/epoch - 6ms/step\n",
            "Epoch 11/50\n",
            "89/89 - 1s - loss: 0.0420 - 510ms/epoch - 6ms/step\n",
            "Epoch 12/50\n",
            "89/89 - 1s - loss: 0.0421 - 515ms/epoch - 6ms/step\n",
            "Epoch 13/50\n",
            "89/89 - 1s - loss: 0.0420 - 506ms/epoch - 6ms/step\n",
            "Epoch 14/50\n",
            "89/89 - 0s - loss: 0.0419 - 484ms/epoch - 5ms/step\n",
            "Epoch 15/50\n",
            "89/89 - 1s - loss: 0.0420 - 720ms/epoch - 8ms/step\n",
            "Epoch 16/50\n",
            "89/89 - 1s - loss: 0.0421 - 727ms/epoch - 8ms/step\n",
            "Epoch 17/50\n",
            "89/89 - 1s - loss: 0.0419 - 692ms/epoch - 8ms/step\n",
            "Epoch 18/50\n",
            "89/89 - 1s - loss: 0.0419 - 753ms/epoch - 8ms/step\n",
            "Epoch 19/50\n",
            "89/89 - 1s - loss: 0.0419 - 685ms/epoch - 8ms/step\n",
            "Epoch 20/50\n",
            "89/89 - 1s - loss: 0.0420 - 542ms/epoch - 6ms/step\n",
            "Epoch 21/50\n",
            "89/89 - 1s - loss: 0.0420 - 530ms/epoch - 6ms/step\n",
            "Epoch 22/50\n",
            "89/89 - 1s - loss: 0.0418 - 512ms/epoch - 6ms/step\n",
            "Epoch 23/50\n",
            "89/89 - 1s - loss: 0.0420 - 508ms/epoch - 6ms/step\n",
            "Epoch 24/50\n",
            "89/89 - 1s - loss: 0.0418 - 504ms/epoch - 6ms/step\n",
            "Epoch 25/50\n",
            "89/89 - 1s - loss: 0.0418 - 509ms/epoch - 6ms/step\n",
            "Epoch 26/50\n",
            "89/89 - 0s - loss: 0.0419 - 492ms/epoch - 6ms/step\n",
            "Epoch 27/50\n",
            "89/89 - 0s - loss: 0.0418 - 498ms/epoch - 6ms/step\n",
            "Epoch 28/50\n",
            "89/89 - 1s - loss: 0.0419 - 536ms/epoch - 6ms/step\n",
            "Epoch 29/50\n",
            "89/89 - 1s - loss: 0.0419 - 510ms/epoch - 6ms/step\n",
            "Epoch 30/50\n",
            "89/89 - 1s - loss: 0.0417 - 538ms/epoch - 6ms/step\n",
            "Epoch 31/50\n",
            "89/89 - 1s - loss: 0.0418 - 503ms/epoch - 6ms/step\n",
            "Epoch 32/50\n",
            "89/89 - 1s - loss: 0.0418 - 522ms/epoch - 6ms/step\n",
            "Epoch 33/50\n",
            "89/89 - 1s - loss: 0.0419 - 517ms/epoch - 6ms/step\n",
            "Epoch 34/50\n",
            "89/89 - 1s - loss: 0.0418 - 523ms/epoch - 6ms/step\n",
            "Epoch 35/50\n",
            "89/89 - 0s - loss: 0.0418 - 493ms/epoch - 6ms/step\n",
            "Epoch 36/50\n",
            "89/89 - 1s - loss: 0.0418 - 523ms/epoch - 6ms/step\n",
            "Epoch 37/50\n",
            "89/89 - 0s - loss: 0.0418 - 487ms/epoch - 5ms/step\n",
            "Epoch 38/50\n",
            "89/89 - 1s - loss: 0.0418 - 504ms/epoch - 6ms/step\n",
            "Epoch 39/50\n",
            "89/89 - 1s - loss: 0.0417 - 675ms/epoch - 8ms/step\n",
            "Epoch 40/50\n",
            "89/89 - 1s - loss: 0.0419 - 740ms/epoch - 8ms/step\n",
            "Epoch 41/50\n",
            "89/89 - 1s - loss: 0.0418 - 753ms/epoch - 8ms/step\n",
            "Epoch 42/50\n",
            "89/89 - 1s - loss: 0.0418 - 771ms/epoch - 9ms/step\n",
            "Epoch 43/50\n",
            "89/89 - 1s - loss: 0.0420 - 651ms/epoch - 7ms/step\n",
            "Epoch 44/50\n",
            "89/89 - 1s - loss: 0.0418 - 552ms/epoch - 6ms/step\n",
            "Epoch 45/50\n",
            "89/89 - 1s - loss: 0.0418 - 520ms/epoch - 6ms/step\n",
            "Epoch 46/50\n",
            "89/89 - 1s - loss: 0.0418 - 554ms/epoch - 6ms/step\n",
            "Epoch 47/50\n",
            "89/89 - 1s - loss: 0.0418 - 572ms/epoch - 6ms/step\n",
            "Epoch 48/50\n",
            "89/89 - 1s - loss: 0.0417 - 557ms/epoch - 6ms/step\n",
            "Epoch 49/50\n",
            "89/89 - 1s - loss: 0.0418 - 518ms/epoch - 6ms/step\n",
            "Epoch 50/50\n",
            "89/89 - 1s - loss: 0.0417 - 506ms/epoch - 6ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 9 with model ETS in generation 0 of 2 with params {\"damped_trend\": false, \"trend\": \"additive\", \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 10 with model ETS in generation 0 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": 7} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"middle\", \"decimals\": 0, \"on_transform\": false, \"on_inverse\": true}}}\n",
            "Model Number: 11 with model GLM in generation 0 of 2 with params {\"family\": \"Binomial\", \"constant\": false, \"regression_type\": \"datepart\"} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 12 with model GLM in generation 0 of 2 with params {\"family\": \"Binomial\", \"constant\": false, \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 13 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"RollingMeanTransformer\", \"1\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {\"fixed\": true, \"window\": 3}, \"1\": {}}}\n",
            "Model Number: 14 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 15 with model GluonTS in generation 0 of 2 with params {\"gluon_model\": \"DeepAR\", \"epochs\": 150, \"learning_rate\": 0.001, \"context_length\": 10} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PowerTransformer\", \"1\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/gluonts.py\", line 95, in fit\n",
            "    raise ImportError(\n",
            "ImportError: GluonTS installation not found or installed version is incompatible with AutoTS.\n",
            " in model 15: GluonTS\n",
            "Model Number: 16 with model GluonTS in generation 0 of 2 with params {\"gluon_model\": \"NPTS\", \"epochs\": 20, \"learning_rate\": 0.001, \"context_length\": 10} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\"}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/gluonts.py\", line 95, in fit\n",
            "    raise ImportError(\n",
            "ImportError: GluonTS installation not found or installed version is incompatible with AutoTS.\n",
            " in model 16: GluonTS\n",
            "Model Number: 17 with model GluonTS in generation 0 of 2 with params {\"gluon_model\": \"WaveNet\", \"epochs\": 40, \"learning_rate\": 0.001, \"context_length\": 10} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/gluonts.py\", line 95, in fit\n",
            "    raise ImportError(\n",
            "ImportError: GluonTS installation not found or installed version is incompatible with AutoTS.\n",
            " in model 17: GluonTS\n",
            "Model Number: 18 with model GluonTS in generation 0 of 2 with params {\"gluon_model\": \"Transformer\", \"epochs\": 40, \"learning_rate\": 0.001, \"context_length\": 10} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/gluonts.py\", line 95, in fit\n",
            "    raise ImportError(\n",
            "ImportError: GluonTS installation not found or installed version is incompatible with AutoTS.\n",
            " in model 18: GluonTS\n",
            "Model Number: 19 with model GluonTS in generation 0 of 2 with params {\"gluon_model\": \"SFF\", \"epochs\": 40, \"learning_rate\": 0.01, \"context_length\": 10} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/gluonts.py\", line 95, in fit\n",
            "    raise ImportError(\n",
            "ImportError: GluonTS installation not found or installed version is incompatible with AutoTS.\n",
            " in model 19: GluonTS\n",
            "Model Number: 20 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"bkfilter\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 21 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"PositiveShift\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 22 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {\"lag_1\": 7, \"method\": \"LastValue\"}, \"1\": {}}}\n",
            "Model Number: 23 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 24 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"LastValue\", \"lag_1\": 2, \"lag_2\": 7} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"SinTrend\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"middle\", \"decimals\": 2, \"on_transform\": false, \"on_inverse\": true}}}\n",
            "Model Number: 25 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"LastValue\", \"lag_1\": 2, \"lag_2\": 1} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Median\"}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 26 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"LastValue\", \"lag_1\": 7, \"lag_2\": 2} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}, \"1\": {\"method\": \"clip\", \"std_threshold\": 2, \"fillna\": null}}}\n",
            "Model Number: 27 with model UnobservedComponents in generation 0 of 2 with params {\"level\": true, \"trend\": false, \"cycle\": true, \"damped_cycle\": true, \"irregular\": true, \"stochastic_trend\": false, \"stochastic_level\": true, \"stochastic_cycle\": true, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"PositiveShift\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"Linear\"}}}\n",
            "Model Number: 28 with model UnobservedComponents in generation 0 of 2 with params {\"level\": false, \"trend\": false, \"cycle\": true, \"damped_cycle\": false, \"irregular\": false, \"stochastic_trend\": false, \"stochastic_level\": true, \"stochastic_cycle\": false, \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 29 with model UnobservedComponents in generation 0 of 2 with params {\"level\": true, \"trend\": false, \"cycle\": false, \"damped_cycle\": false, \"irregular\": false, \"stochastic_trend\": false, \"stochastic_level\": true, \"stochastic_cycle\": true, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 5, \"fillna\": null}}}\n",
            "Model Number: 30 with model VAR in generation 0 of 2 with params {\"regression_type\": null, \"maxlags\": 5, \"ic\": \"fpe\"} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1756, in predict\n",
            "    self.model = VAR(self.df_train, freq=self.frequency).fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/var_model.py\", line 553, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VAR\")\n",
            "ValueError: Only gave one variable to VAR\n",
            " in model 30: VAR\n",
            "Model Number: 31 with model VAR in generation 0 of 2 with params {\"regression_type\": null, \"maxlags\": 15, \"ic\": \"aic\"} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"RollingMeanTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"fixed\": true, \"window\": 10}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1756, in predict\n",
            "    self.model = VAR(self.df_train, freq=self.frequency).fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/var_model.py\", line 553, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VAR\")\n",
            "ValueError: Only gave one variable to VAR\n",
            " in model 31: VAR\n",
            "Model Number: 32 with model VECM in generation 0 of 2 with params {\"deterministic\": \"cili\", \"k_ar_diff\": 2, \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"GLS\"}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1443, in predict\n",
            "    maModel = VECM(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/vecm.py\", line 958, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VECM\")\n",
            "ValueError: Only gave one variable to VECM\n",
            " in model 32: VECM\n",
            "Model Number: 33 with model VECM in generation 0 of 2 with params {\"deterministic\": \"li\", \"k_ar_diff\": 3, \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1443, in predict\n",
            "    maModel = VECM(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/vecm.py\", line 958, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VECM\")\n",
            "ValueError: Only gave one variable to VECM\n",
            " in model 33: VECM\n",
            "Model Number: 34 with model WindowRegression in generation 0 of 2 with params {\"window_size\": 10, \"regression_model\": {\"model\": \"MLP\", \"model_params\": {\"hidden_layer_sizes\": [72, 36, 72], \"max_iter\": 250, \"activation\": \"relu\", \"solver\": \"lbfgs\", \"early_stopping\": false, \"learning_rate_init\": 0.001}}, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": false, \"shuffle\": true, \"max_windows\": 5000} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 100}, \"1\": {}}}\n",
            "Model Number: 35 with model ConstantNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PowerTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 36 with model FBProphet in generation 0 of 2 with params {\"holiday\": true, \"regression_type\": null, \"growth\": \"linear\", \"n_changepoints\": 30, \"changepoint_prior_scale\": 0.05, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.98, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"Slice\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 1000}, \"1\": {\"method\": 0.5}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/_qm3ua4c.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/_004mwve.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=18811', 'data', 'file=/tmp/tmpav2iq6so/_qm3ua4c.json', 'init=/tmp/tmpav2iq6so/_004mwve.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modeln2kbcmdm/prophet_model-20230317052603.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:26:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:26:04 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 37 with model GluonTS in generation 0 of 2 with params {\"gluon_model\": \"Transformer\", \"epochs\": 80, \"learning_rate\": 0.01, \"context_length\": \"1ForecastLength\", \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/gluonts.py\", line 95, in fit\n",
            "    raise ImportError(\n",
            "ImportError: GluonTS installation not found or installed version is incompatible with AutoTS.\n",
            " in model 37: GluonTS\n",
            "Model Number: 38 with model MultivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 200, \"min_samples_leaf\": 1, \"bootstrap\": true}}, \"mean_rolling_periods\": 12, \"macd_periods\": 94, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 7, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 30, \"ewm_alpha\": 0.1, \"ewm_var_alpha\": 0.2, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": null, \"holiday\": true, \"probabilistic\": false} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {}}}\n",
            "building tree 1 of 200\n",
            "building tree 2 of 200\n",
            "building tree 3 of 200\n",
            "building tree 4 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 5 of 200\n",
            "building tree 6 of 200\n",
            "building tree 7 of 200\n",
            "building tree 8 of 200\n",
            "building tree 9 of 200\n",
            "building tree 10 of 200\n",
            "building tree 11 of 200\n",
            "building tree 12 of 200\n",
            "building tree 13 of 200\n",
            "building tree 14 of 200\n",
            "building tree 15 of 200\n",
            "building tree 16 of 200\n",
            "building tree 17 of 200\n",
            "building tree 18 of 200\n",
            "building tree 19 of 200\n",
            "building tree 20 of 200\n",
            "building tree 21 of 200\n",
            "building tree 22 of 200\n",
            "building tree 23 of 200\n",
            "building tree 24 of 200\n",
            "building tree 25 of 200\n",
            "building tree 26 of 200\n",
            "building tree 27 of 200\n",
            "building tree 28 of 200\n",
            "building tree 29 of 200\n",
            "building tree 30 of 200\n",
            "building tree 31 of 200\n",
            "building tree 32 of 200\n",
            "building tree 33 of 200\n",
            "building tree 34 of 200\n",
            "building tree 35 of 200\n",
            "building tree 36 of 200\n",
            "building tree 37 of 200\n",
            "building tree 38 of 200\n",
            "building tree 39 of 200\n",
            "building tree 40 of 200\n",
            "building tree 41 of 200\n",
            "building tree 42 of 200\n",
            "building tree 43 of 200\n",
            "building tree 44 of 200\n",
            "building tree 45 of 200\n",
            "building tree 46 of 200\n",
            "building tree 47 of 200\n",
            "building tree 48 of 200\n",
            "building tree 49 of 200\n",
            "building tree 50 of 200\n",
            "building tree 51 of 200\n",
            "building tree 52 of 200\n",
            "building tree 53 of 200\n",
            "building tree 54 of 200\n",
            "building tree 55 of 200\n",
            "building tree 56 of 200\n",
            "building tree 57 of 200\n",
            "building tree 58 of 200\n",
            "building tree 59 of 200\n",
            "building tree 60 of 200\n",
            "building tree 61 of 200\n",
            "building tree 62 of 200\n",
            "building tree 63 of 200\n",
            "building tree 64 of 200\n",
            "building tree 65 of 200\n",
            "building tree 66 of 200\n",
            "building tree 67 of 200\n",
            "building tree 68 of 200\n",
            "building tree 69 of 200\n",
            "building tree 70 of 200\n",
            "building tree 71 of 200\n",
            "building tree 72 of 200\n",
            "building tree 73 of 200\n",
            "building tree 74 of 200\n",
            "building tree 75 of 200\n",
            "building tree 76 of 200\n",
            "building tree 77 of 200\n",
            "building tree 78 of 200\n",
            "building tree 79 of 200\n",
            "building tree 80 of 200\n",
            "building tree 81 of 200\n",
            "building tree 82 of 200\n",
            "building tree 83 of 200\n",
            "building tree 84 of 200\n",
            "building tree 85 of 200\n",
            "building tree 86 of 200\n",
            "building tree 87 of 200\n",
            "building tree 88 of 200\n",
            "building tree 89 of 200\n",
            "building tree 90 of 200\n",
            "building tree 91 of 200\n",
            "building tree 92 of 200\n",
            "building tree 93 of 200\n",
            "building tree 94 of 200\n",
            "building tree 95 of 200\n",
            "building tree 96 of 200\n",
            "building tree 97 of 200\n",
            "building tree 98 of 200\n",
            "building tree 99 of 200\n",
            "building tree 100 of 200\n",
            "building tree 101 of 200\n",
            "building tree 102 of 200\n",
            "building tree 103 of 200\n",
            "building tree 104 of 200\n",
            "building tree 105 of 200\n",
            "building tree 106 of 200\n",
            "building tree 107 of 200\n",
            "building tree 108 of 200\n",
            "building tree 109 of 200\n",
            "building tree 110 of 200\n",
            "building tree 111 of 200\n",
            "building tree 112 of 200\n",
            "building tree 113 of 200\n",
            "building tree 114 of 200\n",
            "building tree 115 of 200\n",
            "building tree 116 of 200\n",
            "building tree 117 of 200\n",
            "building tree 118 of 200\n",
            "building tree 119 of 200\n",
            "building tree 120 of 200\n",
            "building tree 121 of 200\n",
            "building tree 122 of 200\n",
            "building tree 123 of 200\n",
            "building tree 124 of 200\n",
            "building tree 125 of 200\n",
            "building tree 126 of 200\n",
            "building tree 127 of 200\n",
            "building tree 128 of 200\n",
            "building tree 129 of 200\n",
            "building tree 130 of 200\n",
            "building tree 131 of 200\n",
            "building tree 132 of 200\n",
            "building tree 133 of 200\n",
            "building tree 134 of 200\n",
            "building tree 135 of 200\n",
            "building tree 136 of 200\n",
            "building tree 137 of 200\n",
            "building tree 138 of 200\n",
            "building tree 139 of 200\n",
            "building tree 140 of 200\n",
            "building tree 141 of 200\n",
            "building tree 142 of 200\n",
            "building tree 143 of 200\n",
            "building tree 144 of 200\n",
            "building tree 145 of 200\n",
            "building tree 146 of 200\n",
            "building tree 147 of 200\n",
            "building tree 148 of 200\n",
            "building tree 149 of 200\n",
            "building tree 150 of 200\n",
            "building tree 151 of 200\n",
            "building tree 152 of 200\n",
            "building tree 153 of 200\n",
            "building tree 154 of 200\n",
            "building tree 155 of 200\n",
            "building tree 156 of 200\n",
            "building tree 157 of 200\n",
            "building tree 158 of 200\n",
            "building tree 159 of 200\n",
            "building tree 160 of 200\n",
            "building tree 161 of 200\n",
            "building tree 162 of 200\n",
            "building tree 163 of 200\n",
            "building tree 164 of 200\n",
            "building tree 165 of 200\n",
            "building tree 166 of 200\n",
            "building tree 167 of 200\n",
            "building tree 168 of 200\n",
            "building tree 169 of 200\n",
            "building tree 170 of 200\n",
            "building tree 171 of 200\n",
            "building tree 172 of 200\n",
            "building tree 173 of 200\n",
            "building tree 174 of 200\n",
            "building tree 175 of 200\n",
            "building tree 176 of 200\n",
            "building tree 177 of 200\n",
            "building tree 178 of 200\n",
            "building tree 179 of 200\n",
            "building tree 180 of 200\n",
            "building tree 181 of 200\n",
            "building tree 182 of 200\n",
            "building tree 183 of 200\n",
            "building tree 184 of 200\n",
            "building tree 185 of 200\n",
            "building tree 186 of 200\n",
            "building tree 187 of 200\n",
            "building tree 188 of 200\n",
            "building tree 189 of 200\n",
            "building tree 190 of 200\n",
            "building tree 191 of 200\n",
            "building tree 192 of 200\n",
            "building tree 193 of 200\n",
            "building tree 194 of 200\n",
            "building tree 195 of 200\n",
            "building tree 196 of 200\n",
            "building tree 197 of 200\n",
            "building tree 198 of 200\n",
            "building tree 199 of 200\n",
            "building tree 200 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    3.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 39 with model MultivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"LightGBM\", \"model_params\": {\"objective\": \"regression\", \"learning_rate\": 0.1, \"num_leaves\": 70, \"max_depth\": -1, \"boosting_type\": \"gbdt\", \"n_estimators\": 100}}, \"mean_rolling_periods\": 12, \"macd_periods\": null, \"std_rolling_periods\": 30, \"max_rolling_periods\": null, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": null, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": \"User\", \"window\": 3, \"holiday\": false, \"probabilistic\": false} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 2629, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but not future_regressor supplied.\n",
            " in model 39: MultivariateRegression\n",
            "Model Number: 40 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"ExtraTrees\", \"model_params\": {\"n_estimators\": 500, \"min_samples_leaf\": 1, \"max_depth\": 10}}, \"datepart_method\": \"expanded\", \"polynomial_degree\": null, \"regression_type\": \"User\"} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"MaxAbsScaler\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1930, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor passed\n",
            " in model 40: DatepartRegression\n",
            "Model Number: 41 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 364, \"lag_2\": 28} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"lag_1\": 7, \"method\": \"LastValue\"}, \"1\": {}}}\n",
            "Model Number: 42 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"ExtraTrees\", \"model_params\": {\"n_estimators\": 100, \"min_samples_leaf\": 1, \"max_depth\": null}}, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"regression_type\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 43 with model UnobservedComponents in generation 0 of 2 with params {\"level\": false, \"maxiter\": 100, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": null, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"Slice\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"method\": 0.2}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n",
            "Model Number: 44 with model UnobservedComponents in generation 0 of 2 with params {\"level\": \"random walk with drift\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": null, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n",
            "Model Number: 45 with model ETS in generation 0 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": 28} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"MaxAbsScaler\", \"1\": \"Slice\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"method\": 100}}}\n",
            "Model Number: 46 with model VECM in generation 0 of 2 with params {\"deterministic\": \"n\", \"k_ar_diff\": 2, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"PCA\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1443, in predict\n",
            "    maModel = VECM(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/vecm.py\", line 958, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VECM\")\n",
            "ValueError: Only gave one variable to VECM\n",
            " in model 46: VECM\n",
            "Model Number: 47 with model ARDL in generation 0 of 2 with params {\"lags\": 4, \"trend\": \"n\", \"order\": 1, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"IntermittentOccurrence\"}, \"transformation_params\": {\"0\": {\"center\": \"mean\"}}}\n",
            "Model Number: 48 with model MultivariateMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"mahalanobis\", \"k\": 20, \"max_windows\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {\"output_distribution\": \"normal\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 49 with model MultivariateMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"sqeuclidean\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"bkfilter\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null}, \"1\": {}}}\n",
            "Model Number: 50 with model UnivariateMotif in generation 0 of 2 with params {\"window\": 60, \"point_method\": \"median\", \"distance_metric\": \"canberra\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 100}, \"1\": {\"lag_1\": 7, \"method\": \"Mean\"}}}\n",
            "Model Number: 51 with model UnivariateMotif in generation 0 of 2 with params {\"window\": 14, \"point_method\": \"median\", \"distance_metric\": \"minkowski\", \"k\": 5, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n",
            "Model Number: 52 with model SectionalMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"weighted_mean\", \"distance_metric\": \"sokalmichener\", \"include_differenced\": true, \"k\": 20, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 53 with model SectionalMotif in generation 0 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": false, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 54 with model MultivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 2}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": null, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 90, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": true, \"probabilistic\": false} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/4edvhh8a.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/oa87jplt.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=74858', 'data', 'file=/tmp/tmpav2iq6so/4edvhh8a.json', 'init=/tmp/tmpav2iq6so/oa87jplt.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_model079v3dsd/prophet_model-20230317052613.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:26:13 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 55 with model FBProphet in generation 0 of 2 with params {\"holiday\": true, \"regression_type\": null, \"growth\": \"linear\", \"n_changepoints\": 25, \"changepoint_prior_scale\": 30, \"seasonality_mode\": \"multiplicative\", \"changepoint_range\": 0.9, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"Slice\"}, \"transformation_params\": {\"0\": {\"method\": 0.5}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:14 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 56 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 364, \"lag_2\": 30} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"lag_1\": 7, \"method\": \"LastValue\"}, \"1\": {}}}\n",
            "Model Number: 57 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 100, \"min_samples_leaf\": 2, \"bootstrap\": true}}, \"datepart_method\": \"expanded\", \"polynomial_degree\": null, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null}}}\n",
            "building tree 1 of 100\n",
            "building tree 2 of 100\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Model Number: 58 with model NVAR in generation 0 of 2 with params {\"k\": 1, \"ridge_param\": 0.002, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 59 with model Theta in generation 0 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": false, \"method\": \"auto\", \"period\": null, \"theta\": 2.5, \"use_mle\": true} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": 90}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 60 with model UnivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 1.0}}, \"holiday\": false, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": 12, \"min_rolling_periods\": 58, \"ewm_var_alpha\": null, \"ewm_alpha\": 0.5, \"additional_lag_periods\": 363, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": \"simple_2_poly\", \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"MaxAbsScaler\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n",
            "Model Number: 61 with model ARCH in generation 0 of 2 with params {\"mean\": \"Zero\", \"lags\": 1, \"vol\": \"GARCH\", \"p\": 4, \"o\": 1, \"q\": 2, \"power\": 1.5, \"dist\": \"studentst\", \"rescale\": true, \"simulations\": 1000, \"maxiter\": 200, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/arch.py\", line 131, in fit\n",
            "    raise ImportError(\"`arch` package must be installed from pip\")\n",
            "ImportError: `arch` package must be installed from pip\n",
            " in model 61: ARCH\n",
            "Model Number: 62 with model ConstantNaive in generation 0 of 2 with params {\"constant\": 0} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 7}}}}}}\n",
            "Model Number: 63 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"HolidayTransformer\"}, \"transformation_params\": {\"0\": {\"threshold\": 1.0, \"splash_threshold\": null, \"use_dayofmonth_holidays\": true, \"use_wkdom_holidays\": true, \"use_wkdeom_holidays\": false, \"use_lunar_holidays\": false, \"use_lunar_weekday\": false, \"use_islamic_holidays\": false, \"use_hebrew_holidays\": true, \"anomaly_detector_params\": {\"method\": \"IQR\", \"method_params\": {\"iqr_threshold\": 2.0, \"iqr_quantiles\": [0.25, 0.75]}, \"fillna\": \"rolling_mean_24\", \"transform_dict\": {\"transformations\": {\"0\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"datepart_method\": \"simple_3\", \"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}}}}}, \"remove_excess_anomalies\": true, \"impact\": \"anomaly_score\", \"regression_params\": {}}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=3.88833e-26): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 64 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Exp_Weighted_Mean\", \"window\": null} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 0.5, \"first_value_only\": false}, \"1\": {}}}\n",
            "Model Number: 65 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}, \"1\": {}}}\n",
            "Model Number: 66 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 7, \"lag_2\": 60} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"AnomalyRemoval\"}, \"transformation_params\": {\"0\": {\"method\": \"zscore\", \"transform_dict\": {\"transformations\": {\"0\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"datepart_method\": \"simple_3\", \"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}}}}, \"method_params\": {\"distribution\": \"uniform\", \"alpha\": 0.05}}}}}}}\n",
            "Model Number: 67 with model GLM in generation 0 of 2 with params {\"family\": \"Gaussian\", \"constant\": false, \"regression_type\": \"User\"} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"RobustScaler\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"lag_1\": 12, \"method\": \"Mean\"}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 229, in fit\n",
            "    raise ValueError(\"regression_type=user and no future_regressor passed\")\n",
            "ValueError: regression_type=user and no future_regressor passed\n",
            " in model 67: GLM\n",
            "Model Number: 68 with model ETS in generation 0 of 2 with params {\"damped_trend\": true, \"trend\": \"multiplicative\", \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 2}}}}}}\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py:492: FutureWarning:\n",
            "\n",
            "the 'damped'' keyword is deprecated, use 'damped_trend' instead.\n",
            "\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 69 with model FBProphet in generation 0 of 2 with params {\"holiday\": false, \"regression_type\": null, \"changepoint_prior_scale\": 30, \"seasonality_prior_scale\": 25, \"holidays_prior_scale\": 10.0, \"seasonality_mode\": \"multiplicative\", \"changepoint_range\": 0.8, \"growth\": \"linear\", \"n_changepoints\": 25} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/c2t901d_.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/fkuu53jr.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=46402', 'data', 'file=/tmp/tmpav2iq6so/c2t901d_.json', 'init=/tmp/tmpav2iq6so/fkuu53jr.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modelwing7oce/prophet_model-20230317052620.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:26:20 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:26:22 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 70 with model GluonTS in generation 0 of 2 with params {\"gluon_model\": \"Rotbaum\", \"epochs\": 20, \"learning_rate\": 0.001, \"context_length\": 5, \"regression_type\": \"User\"} and transformations {\"fillna\": \"nearest\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/gluonts.py\", line 95, in fit\n",
            "    raise ImportError(\n",
            "ImportError: GluonTS installation not found or installed version is incompatible with AutoTS.\n",
            " in model 70: GluonTS\n",
            "Model Number: 71 with model UnobservedComponents in generation 0 of 2 with params {\"level\": \"fixed slope\", \"maxiter\": 100, \"cov_type\": \"oim\", \"method\": \"lbfgs\", \"autoregressive\": null, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"CenterLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 2}}}\n",
            "Model Number: 72 with model VAR in generation 0 of 2 with params {\"regression_type\": \"User\", \"maxlags\": 15, \"ic\": \"hqic\"} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1702, in fit\n",
            "    if (np.array(future_regressor).shape[0]) != (df.shape[0]):\n",
            "IndexError: tuple index out of range\n",
            " in model 72: VAR\n",
            "Model Number: 73 with model VECM in generation 0 of 2 with params {\"deterministic\": \"lo\", \"k_ar_diff\": 3, \"regression_type\": \"User\"} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"RobustScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1395, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor supplied\n",
            " in model 73: VECM\n",
            "Model Number: 74 with model ARIMA in generation 0 of 2 with params {\"p\": 12, \"d\": 0, \"q\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 75 with model WindowRegression in generation 0 of 2 with params {\"window_size\": 20, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": false, \"max_windows\": 5000, \"regression_type\": null, \"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"butter\", \"method_args\": {\"N\": 2, \"window_size\": 28, \"btype\": \"highpass\", \"analog\": false, \"output\": \"sos\"}}}}\n",
            "Model Number: 76 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"ExtraTrees\", \"model_params\": {\"n_estimators\": 100, \"min_samples_leaf\": 1, \"max_depth\": 30}}, \"datepart_method\": \"simple_binarized\", \"polynomial_degree\": null, \"regression_type\": null} and transformations {\"fillna\": \"time\", \"transformations\": {\"0\": \"RobustScaler\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3}}}}}}\n",
            "Model Number: 77 with model UnivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}, \"holiday\": false, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": 28, \"min_rolling_periods\": 364, \"ewm_var_alpha\": null, \"ewm_alpha\": 0.2, \"additional_lag_periods\": 12, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": null, \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": 7} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 78 with model MultivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"xgboost\", \"model_params\": {\"objective\": \"count:poisson\", \"eta\": 0.3, \"min_child_weight\": 1, \"max_depth\": 6, \"subsample\": 1.0}}, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": 364, \"min_rolling_periods\": null, \"quantile90_rolling_periods\": 7, \"quantile10_rolling_periods\": null, \"ewm_alpha\": null, \"ewm_var_alpha\": 0.2, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": 2, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": \"User\", \"window\": null, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 31, \"polyorder\": 3, \"deriv\": 0, \"mode\": \"interp\"}}}}}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 2629, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but not future_regressor supplied.\n",
            " in model 78: MultivariateRegression\n",
            "Model Number: 79 with model UnivariateMotif in generation 0 of 2 with params {\"window\": 28, \"point_method\": \"mean\", \"distance_metric\": \"matching\", \"k\": 5, \"max_windows\": 10000} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 80 with model MultivariateMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"rogerstanimoto\", \"k\": 3, \"max_windows\": 10000} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"RobustScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 81 with model SectionalMotif in generation 0 of 2 with params {\"window\": 15, \"point_method\": \"mean\", \"distance_metric\": \"sokalsneath\", \"include_differenced\": true, \"k\": 1, \"stride_size\": 2, \"regression_type\": null} and transformations {\"fillna\": \"akima\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"normal\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 82 with model NVAR in generation 0 of 2 with params {\"k\": 2, \"ridge_param\": 2e-06, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}}}\n",
            "Model Number: 83 with model Theta in generation 0 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 3, \"use_mle\": false} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"AnomalyRemoval\"}, \"transformation_params\": {\"0\": {\"method\": \"IQR\", \"method_params\": {\"iqr_threshold\": 3.0, \"iqr_quantiles\": [0.25, 0.75]}, \"fillna\": \"ffill\", \"transform_dict\": {\"transformations\": {\"0\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"datepart_method\": \"simple_3\", \"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}}}}}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=3.88833e-26): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 84 with model ARDL in generation 0 of 2 with params {\"lags\": 1, \"trend\": \"t\", \"order\": 3, \"causal\": false, \"regression_type\": \"User\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"STLFilter\", \"1\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {\"decomp_type\": \"STL\", \"part\": \"trend\", \"seasonal\": 7}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 2089, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but future_regressor not supplied\n",
            " in model 84: ARDL\n",
            "Model Number: 85 with model ARCH in generation 0 of 2 with params {\"mean\": \"HAR\", \"lags\": 0, \"vol\": \"FIGARCH\", \"p\": 0, \"o\": 0, \"q\": 1, \"power\": 1.0, \"dist\": \"ged\", \"rescale\": true, \"simulations\": 1000, \"maxiter\": 200, \"regression_type\": null} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/arch.py\", line 131, in fit\n",
            "    raise ImportError(\"`arch` package must be installed from pip\")\n",
            "ImportError: `arch` package must be installed from pip\n",
            " in model 85: ARCH\n",
            "Model Number: 86 with model MetricMotif in generation 0 of 2 with params {\"window\": 15, \"point_method\": \"median\", \"distance_metric\": \"mqae\", \"k\": 1, \"comparison_transformation\": {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 7, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": true}}}, \"combination_transformation\": {\"fillna\": \"nearest\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 0.999, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 2}}}}}}\n",
            "Model Number: 87 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PositiveShift\", \"1\": \"cffilter\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 88 with model MetricMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"mse\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear stochastic seasonal 7\", \"state_transition\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \"observation_model\": [[1, 0, 1, 0, 0, 0, 0, 0]], \"observation_noise\": 0.25, \"em_iter\": null}}}} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Log\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 89 with model ETS in generation 0 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": 60} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"MeanDifference\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 90 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}}}\n",
            "Model Number: 91 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Weighted_Mean\", \"window\": 7} and transformations {\"fillna\": \"linear\", \"transformations\": {\"0\": \"StandardScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 92 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Median\", \"window\": null} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 93 with model WindowRegression in generation 0 of 2 with params {\"window_size\": 10, \"input_dim\": \"univariate\", \"output_dim\": \"1step\", \"normalize_window\": false, \"max_windows\": 1000, \"regression_type\": null, \"regression_model\": {\"model\": \"KNN\", \"model_params\": {\"n_neighbors\": 3, \"weights\": \"uniform\", \"p\": 2, \"leaf_size\": 30}}} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 94 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Median\", \"window\": 44} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 95 with model NVAR in generation 0 of 2 with params {\"k\": 1, \"ridge_param\": 2, \"warmup_pts\": 1, \"seed_pts\": 10, \"seed_weighted\": \"linear\", \"batch_size\": 5, \"batch_method\": \"std_sorted\"} and transformations {\"fillna\": \"barycentric\", \"transformations\": {\"0\": \"RobustScaler\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 96 with model UnobservedComponents in generation 0 of 2 with params {\"level\": \"irregular\", \"maxiter\": 100, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": null, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"RobustScaler\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"lag_1\": 12, \"method\": \"LastValue\"}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning:\n",
            "\n",
            "overflow encountered in reduce\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/scipy/interpolate/_polyint.py:570: RuntimeWarning:\n",
            "\n",
            "overflow encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/scipy/interpolate/_polyint.py:570: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in reduce\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 97 with model ARIMA in generation 0 of 2 with params {\"p\": 2, \"d\": 0, \"q\": 0, \"regression_type\": \"User\"} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"RobustScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 697, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but future_regressor not supplied\n",
            " in model 97: ARIMA\n",
            "Model Number: 98 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 2}}, \"datepart_method\": \"expanded\", \"polynomial_degree\": null, \"regression_type\": \"User\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1930, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor passed\n",
            " in model 98: DatepartRegression\n",
            "Model Number: 99 with model ETS in generation 0 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PCA\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"whiten\": false}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n",
            "Model Number: 100 with model VECM in generation 0 of 2 with params {\"deterministic\": \"lo\", \"k_ar_diff\": 2, \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1443, in predict\n",
            "    maModel = VECM(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/vecm.py\", line 958, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VECM\")\n",
            "ValueError: Only gave one variable to VECM\n",
            " in model 100: VECM\n",
            "Model Number: 101 with model MultivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 30, \"macd_periods\": 364, \"std_rolling_periods\": null, \"max_rolling_periods\": 12, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": null, \"quantile10_rolling_periods\": 5, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 3, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"PCA\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Mean\"}, \"1\": {\"whiten\": false}}}\n",
            "Model Number: 102 with model VECM in generation 0 of 2 with params {\"deterministic\": \"n\", \"k_ar_diff\": 1, \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1443, in predict\n",
            "    maModel = VECM(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/vecm.py\", line 958, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VECM\")\n",
            "ValueError: Only gave one variable to VECM\n",
            " in model 102: VECM\n",
            "Model Number: 103 with model ARCH in generation 0 of 2 with params {\"mean\": \"HARX\", \"lags\": 2, \"vol\": \"ARCH\", \"p\": 7, \"o\": 1, \"q\": 2, \"power\": 2.0, \"dist\": \"studentst\", \"rescale\": false, \"simulations\": 1000, \"maxiter\": 200, \"regression_type\": \"User\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/arch.py\", line 131, in fit\n",
            "    raise ImportError(\"`arch` package must be installed from pip\")\n",
            "ImportError: `arch` package must be installed from pip\n",
            " in model 103: ARCH\n",
            "Model Number: 104 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"median\", \"lag_1\": 12, \"lag_2\": 45} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 105 with model ConstantNaive in generation 0 of 2 with params {\"constant\": 1} and transformations {\"fillna\": \"akima\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 106 with model ConstantNaive in generation 0 of 2 with params {\"constant\": 0} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 107 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 7, \"lag_2\": null} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"EWMAFilter\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"span\": 12}, \"1\": {\"lag_1\": 7, \"method\": \"Median\"}}}\n",
            "Model Number: 108 with model ETS in generation 0 of 2 with params {\"damped_trend\": true, \"trend\": \"multiplicative\", \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"HPFilter\"}, \"transformation_params\": {\"0\": {\"part\": \"trend\", \"lamb\": 6.25}}}\n",
            "Model Number: 109 with model MultivariateMotif in generation 0 of 2 with params {\"window\": 7, \"point_method\": \"midhinge\", \"distance_metric\": \"jensenshannon\", \"k\": 20, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/x4a3bact.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 110 with model FBProphet in generation 0 of 2 with params {\"holiday\": {\"threshold\": 0.8, \"splash_threshold\": null, \"use_dayofmonth_holidays\": true, \"use_wkdom_holidays\": true, \"use_wkdeom_holidays\": true, \"use_lunar_holidays\": false, \"use_lunar_weekday\": false, \"use_islamic_holidays\": false, \"use_hebrew_holidays\": false, \"anomaly_detector_params\": {\"method\": \"rolling_zscore\", \"transform_dict\": null, \"forecast_params\": null, \"method_params\": {\"distribution\": \"norm\", \"alpha\": 0.05, \"rolling_periods\": 200, \"center\": true}}}, \"regression_type\": null, \"changepoint_prior_scale\": 0.1, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 40, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.85, \"growth\": \"linear\", \"n_changepoints\": 20} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": 30, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 31, \"polyorder\": 3, \"deriv\": 0, \"mode\": \"interp\"}}}}}}}\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/b71e_e2q.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=57473', 'data', 'file=/tmp/tmpav2iq6so/x4a3bact.json', 'init=/tmp/tmpav2iq6so/b71e_e2q.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modelwevtwdd_/prophet_model-20230317052636.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:26:36 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:26:37 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 111 with model ARDL in generation 0 of 2 with params {\"lags\": 3, \"trend\": \"c\", \"order\": 0, \"causal\": false, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 112 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Weighted_Mean\", \"window\": null} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"RollingMeanTransformer\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"fixed\": true, \"window\": 10}, \"1\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 0.9, \"first_value_only\": false}}}\n",
            "Model Number: 113 with model VAR in generation 0 of 2 with params {\"regression_type\": null, \"maxlags\": 5, \"ic\": \"aic\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1756, in predict\n",
            "    self.model = VAR(self.df_train, freq=self.frequency).fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/var_model.py\", line 553, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VAR\")\n",
            "ValueError: Only gave one variable to VAR\n",
            " in model 113: VAR\n",
            "Model Number: 114 with model ARDL in generation 0 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 0, \"causal\": false, \"regression_type\": null} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}\n",
            "Model Number: 115 with model UnivariateMotif in generation 0 of 2 with params {\"window\": 28, \"point_method\": \"midhinge\", \"distance_metric\": \"cityblock\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 116 with model UnivariateMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"sokalsneath\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"PositiveShift\", \"1\": \"STLFilter\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"decomp_type\": \"seasonal_decompose\", \"part\": \"trend\"}}}\n",
            "Model Number: 117 with model ARDL in generation 0 of 2 with params {\"lags\": 3, \"trend\": \"c\", \"order\": 1, \"causal\": true, \"regression_type\": \"simple_2\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"PCA\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 7}}}}, \"1\": {\"whiten\": true}}}\n",
            "Model Number: 118 with model ConstantNaive in generation 0 of 2 with params {\"constant\": 0} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}}}\n",
            "Model Number: 119 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 120 with model ConstantNaive in generation 0 of 2 with params {\"constant\": 1} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 91, \"polyorder\": 2, \"deriv\": 0, \"mode\": \"mirror\"}}}}\n",
            "Model Number: 121 with model ARDL in generation 0 of 2 with params {\"lags\": 1, \"trend\": \"n\", \"order\": 0, \"causal\": false, \"regression_type\": \"User\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 2, \"fillna\": null}, \"1\": {\"span\": 7}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 2089, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but future_regressor not supplied\n",
            " in model 121: ARDL\n",
            "Model Number: 122 with model VECM in generation 0 of 2 with params {\"deterministic\": \"li\", \"k_ar_diff\": 2, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": 90, \"transform_dict\": null}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1443, in predict\n",
            "    maModel = VECM(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/vecm.py\", line 958, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VECM\")\n",
            "ValueError: Only gave one variable to VECM\n",
            " in model 122: VECM\n",
            "Model Number: 123 with model ARDL in generation 0 of 2 with params {\"lags\": 3, \"trend\": \"t\", \"order\": 2, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/tn5b96xu.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 124 with model VAR in generation 0 of 2 with params {\"regression_type\": null, \"maxlags\": null, \"ic\": \"fpe\"} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1756, in predict\n",
            "    self.model = VAR(self.df_train, freq=self.frequency).fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/var_model.py\", line 553, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VAR\")\n",
            "ValueError: Only gave one variable to VAR\n",
            " in model 124: VAR\n",
            "Model Number: 125 with model FBProphet in generation 0 of 2 with params {\"holiday\": false, \"regression_type\": null, \"changepoint_prior_scale\": 0.5, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.8, \"growth\": \"linear\", \"n_changepoints\": 25} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"LastValue\"}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/jag_kxvq.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=13599', 'data', 'file=/tmp/tmpav2iq6so/tn5b96xu.json', 'init=/tmp/tmpav2iq6so/jag_kxvq.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_model3xqt07dz/prophet_model-20230317052639.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:26:39 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:26:41 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 126 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 127 with model Theta in generation 0 of 2 with params {\"deseasonalize\": false, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 3, \"use_mle\": false} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 91, \"polyorder\": 1, \"deriv\": 0, \"mode\": \"nearest\"}}}}\n",
            "Model Number: 128 with model UnobservedComponents in generation 0 of 2 with params {\"level\": \"irregular\", \"maxiter\": 100, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": null, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"EWMAFilter\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"span\": 12}, \"1\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 129 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Exp_Weighted_Mean\", \"window\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 130 with model ETS in generation 0 of 2 with params {\"damped_trend\": false, \"trend\": \"additive\", \"seasonal\": \"multiplicative\", \"seasonal_periods\": 364} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 131 with model Theta in generation 0 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": false, \"method\": \"auto\", \"period\": null, \"theta\": 1.4, \"use_mle\": false} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"bkfilter\", \"1\": \"PositiveShift\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py:492: FutureWarning:\n",
            "\n",
            "the 'damped'' keyword is deprecated, use 'damped_trend' instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 132 with model AverageValueNaive in generation 0 of 2 with params {\"method\": \"Weighted_Mean\", \"window\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": 30, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 2}}}}}}\n",
            "Model Number: 133 with model UnobservedComponents in generation 0 of 2 with params {\"level\": \"random trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"barycentric\", \"transformations\": {\"0\": \"Round\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {\"decimals\": -1, \"on_transform\": true, \"on_inverse\": true}, \"1\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning:\n",
            "\n",
            "overflow encountered in reduce\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/scipy/interpolate/_polyint.py:570: RuntimeWarning:\n",
            "\n",
            "overflow encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/scipy/interpolate/_polyint.py:570: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in reduce\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 134 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 31, \"polyorder\": 3, \"deriv\": 0, \"mode\": \"interp\"}}}}}}}\n",
            "Model Number: 135 with model DatepartRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 300, \"min_samples_leaf\": 2, \"bootstrap\": true}}, \"datepart_method\": \"recurring\", \"polynomial_degree\": 3, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"StandardScaler\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "building tree 1 of 300\n",
            "building tree 2 of 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 3 of 300\n",
            "building tree 4 of 300\n",
            "building tree 5 of 300\n",
            "building tree 6 of 300\n",
            "building tree 7 of 300\n",
            "building tree 8 of 300\n",
            "building tree 9 of 300\n",
            "building tree 10 of 300\n",
            "building tree 11 of 300\n",
            "building tree 12 of 300\n",
            "building tree 13 of 300\n",
            "building tree 14 of 300\n",
            "building tree 15 of 300\n",
            "building tree 16 of 300\n",
            "building tree 17 of 300\n",
            "building tree 18 of 300\n",
            "building tree 19 of 300\n",
            "building tree 20 of 300\n",
            "building tree 21 of 300\n",
            "building tree 22 of 300\n",
            "building tree 23 of 300\n",
            "building tree 24 of 300\n",
            "building tree 25 of 300\n",
            "building tree 26 of 300\n",
            "building tree 27 of 300\n",
            "building tree 28 of 300\n",
            "building tree 29 of 300\n",
            "building tree 30 of 300\n",
            "building tree 31 of 300\n",
            "building tree 32 of 300\n",
            "building tree 33 of 300\n",
            "building tree 34 of 300\n",
            "building tree 35 of 300\n",
            "building tree 36 of 300\n",
            "building tree 37 of 300\n",
            "building tree 38 of 300\n",
            "building tree 39 of 300\n",
            "building tree 40 of 300\n",
            "building tree 41 of 300\n",
            "building tree 42 of 300\n",
            "building tree 43 of 300\n",
            "building tree 44 of 300\n",
            "building tree 45 of 300\n",
            "building tree 46 of 300\n",
            "building tree 47 of 300\n",
            "building tree 48 of 300\n",
            "building tree 49 of 300\n",
            "building tree 50 of 300\n",
            "building tree 51 of 300\n",
            "building tree 52 of 300\n",
            "building tree 53 of 300\n",
            "building tree 54 of 300\n",
            "building tree 55 of 300\n",
            "building tree 56 of 300\n",
            "building tree 57 of 300\n",
            "building tree 58 of 300\n",
            "building tree 59 of 300\n",
            "building tree 60 of 300\n",
            "building tree 61 of 300\n",
            "building tree 62 of 300\n",
            "building tree 63 of 300\n",
            "building tree 64 of 300\n",
            "building tree 65 of 300\n",
            "building tree 66 of 300\n",
            "building tree 67 of 300\n",
            "building tree 68 of 300\n",
            "building tree 69 of 300\n",
            "building tree 70 of 300\n",
            "building tree 71 of 300\n",
            "building tree 72 of 300\n",
            "building tree 73 of 300\n",
            "building tree 74 of 300\n",
            "building tree 75 of 300\n",
            "building tree 76 of 300\n",
            "building tree 77 of 300\n",
            "building tree 78 of 300\n",
            "building tree 79 of 300\n",
            "building tree 80 of 300\n",
            "building tree 81 of 300\n",
            "building tree 82 of 300\n",
            "building tree 83 of 300\n",
            "building tree 84 of 300\n",
            "building tree 85 of 300\n",
            "building tree 86 of 300\n",
            "building tree 87 of 300\n",
            "building tree 88 of 300\n",
            "building tree 89 of 300\n",
            "building tree 90 of 300\n",
            "building tree 91 of 300\n",
            "building tree 92 of 300\n",
            "building tree 93 of 300\n",
            "building tree 94 of 300\n",
            "building tree 95 of 300\n",
            "building tree 96 of 300\n",
            "building tree 97 of 300\n",
            "building tree 98 of 300\n",
            "building tree 99 of 300\n",
            "building tree 100 of 300\n",
            "building tree 101 of 300\n",
            "building tree 102 of 300\n",
            "building tree 103 of 300\n",
            "building tree 104 of 300\n",
            "building tree 105 of 300\n",
            "building tree 106 of 300\n",
            "building tree 107 of 300\n",
            "building tree 108 of 300\n",
            "building tree 109 of 300\n",
            "building tree 110 of 300\n",
            "building tree 111 of 300\n",
            "building tree 112 of 300\n",
            "building tree 113 of 300\n",
            "building tree 114 of 300\n",
            "building tree 115 of 300\n",
            "building tree 116 of 300\n",
            "building tree 117 of 300\n",
            "building tree 118 of 300\n",
            "building tree 119 of 300\n",
            "building tree 120 of 300\n",
            "building tree 121 of 300\n",
            "building tree 122 of 300\n",
            "building tree 123 of 300\n",
            "building tree 124 of 300\n",
            "building tree 125 of 300\n",
            "building tree 126 of 300\n",
            "building tree 127 of 300\n",
            "building tree 128 of 300\n",
            "building tree 129 of 300\n",
            "building tree 130 of 300\n",
            "building tree 131 of 300\n",
            "building tree 132 of 300\n",
            "building tree 133 of 300\n",
            "building tree 134 of 300\n",
            "building tree 135 of 300\n",
            "building tree 136 of 300\n",
            "building tree 137 of 300\n",
            "building tree 138 of 300\n",
            "building tree 139 of 300\n",
            "building tree 140 of 300\n",
            "building tree 141 of 300\n",
            "building tree 142 of 300\n",
            "building tree 143 of 300\n",
            "building tree 144 of 300\n",
            "building tree 145 of 300\n",
            "building tree 146 of 300\n",
            "building tree 147 of 300\n",
            "building tree 148 of 300\n",
            "building tree 149 of 300\n",
            "building tree 150 of 300\n",
            "building tree 151 of 300\n",
            "building tree 152 of 300\n",
            "building tree 153 of 300\n",
            "building tree 154 of 300\n",
            "building tree 155 of 300\n",
            "building tree 156 of 300\n",
            "building tree 157 of 300\n",
            "building tree 158 of 300\n",
            "building tree 159 of 300\n",
            "building tree 160 of 300\n",
            "building tree 161 of 300\n",
            "building tree 162 of 300\n",
            "building tree 163 of 300\n",
            "building tree 164 of 300\n",
            "building tree 165 of 300\n",
            "building tree 166 of 300\n",
            "building tree 167 of 300\n",
            "building tree 168 of 300\n",
            "building tree 169 of 300\n",
            "building tree 170 of 300\n",
            "building tree 171 of 300\n",
            "building tree 172 of 300\n",
            "building tree 173 of 300\n",
            "building tree 174 of 300\n",
            "building tree 175 of 300\n",
            "building tree 176 of 300\n",
            "building tree 177 of 300\n",
            "building tree 178 of 300\n",
            "building tree 179 of 300\n",
            "building tree 180 of 300\n",
            "building tree 181 of 300\n",
            "building tree 182 of 300\n",
            "building tree 183 of 300\n",
            "building tree 184 of 300\n",
            "building tree 185 of 300\n",
            "building tree 186 of 300\n",
            "building tree 187 of 300\n",
            "building tree 188 of 300\n",
            "building tree 189 of 300\n",
            "building tree 190 of 300\n",
            "building tree 191 of 300\n",
            "building tree 192 of 300\n",
            "building tree 193 of 300\n",
            "building tree 194 of 300\n",
            "building tree 195 of 300\n",
            "building tree 196 of 300\n",
            "building tree 197 of 300\n",
            "building tree 198 of 300\n",
            "building tree 199 of 300\n",
            "building tree 200 of 300\n",
            "building tree 201 of 300\n",
            "building tree 202 of 300\n",
            "building tree 203 of 300\n",
            "building tree 204 of 300\n",
            "building tree 205 of 300\n",
            "building tree 206 of 300\n",
            "building tree 207 of 300\n",
            "building tree 208 of 300\n",
            "building tree 209 of 300\n",
            "building tree 210 of 300\n",
            "building tree 211 of 300\n",
            "building tree 212 of 300\n",
            "building tree 213 of 300\n",
            "building tree 214 of 300\n",
            "building tree 215 of 300\n",
            "building tree 216 of 300\n",
            "building tree 217 of 300\n",
            "building tree 218 of 300\n",
            "building tree 219 of 300\n",
            "building tree 220 of 300\n",
            "building tree 221 of 300\n",
            "building tree 222 of 300\n",
            "building tree 223 of 300\n",
            "building tree 224 of 300\n",
            "building tree 225 of 300\n",
            "building tree 226 of 300\n",
            "building tree 227 of 300\n",
            "building tree 228 of 300\n",
            "building tree 229 of 300\n",
            "building tree 230 of 300\n",
            "building tree 231 of 300\n",
            "building tree 232 of 300\n",
            "building tree 233 of 300\n",
            "building tree 234 of 300\n",
            "building tree 235 of 300\n",
            "building tree 236 of 300\n",
            "building tree 237 of 300\n",
            "building tree 238 of 300\n",
            "building tree 239 of 300\n",
            "building tree 240 of 300\n",
            "building tree 241 of 300\n",
            "building tree 242 of 300\n",
            "building tree 243 of 300\n",
            "building tree 244 of 300\n",
            "building tree 245 of 300\n",
            "building tree 246 of 300\n",
            "building tree 247 of 300\n",
            "building tree 248 of 300\n",
            "building tree 249 of 300\n",
            "building tree 250 of 300\n",
            "building tree 251 of 300\n",
            "building tree 252 of 300\n",
            "building tree 253 of 300\n",
            "building tree 254 of 300\n",
            "building tree 255 of 300\n",
            "building tree 256 of 300\n",
            "building tree 257 of 300\n",
            "building tree 258 of 300\n",
            "building tree 259 of 300\n",
            "building tree 260 of 300\n",
            "building tree 261 of 300\n",
            "building tree 262 of 300\n",
            "building tree 263 of 300\n",
            "building tree 264 of 300\n",
            "building tree 265 of 300\n",
            "building tree 266 of 300\n",
            "building tree 267 of 300\n",
            "building tree 268 of 300\n",
            "building tree 269 of 300\n",
            "building tree 270 of 300\n",
            "building tree 271 of 300\n",
            "building tree 272 of 300\n",
            "building tree 273 of 300\n",
            "building tree 274 of 300\n",
            "building tree 275 of 300\n",
            "building tree 276 of 300\n",
            "building tree 277 of 300\n",
            "building tree 278 of 300\n",
            "building tree 279 of 300\n",
            "building tree 280 of 300\n",
            "building tree 281 of 300\n",
            "building tree 282 of 300\n",
            "building tree 283 of 300\n",
            "building tree 284 of 300\n",
            "building tree 285 of 300\n",
            "building tree 286 of 300\n",
            "building tree 287 of 300\n",
            "building tree 288 of 300\n",
            "building tree 289 of 300\n",
            "building tree 290 of 300\n",
            "building tree 291 of 300\n",
            "building tree 292 of 300\n",
            "building tree 293 of 300\n",
            "building tree 294 of 300\n",
            "building tree 295 of 300\n",
            "building tree 296 of 300\n",
            "building tree 297 of 300\n",
            "building tree 298 of 300\n",
            "building tree 299 of 300\n",
            "building tree 300 of 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:   16.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 136 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"median\", \"lag_1\": 86, \"lag_2\": 28} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 137 with model UnivariateMotif in generation 0 of 2 with params {\"window\": 7, \"point_method\": \"median\", \"distance_metric\": \"yule\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 2, \"fillna\": null}, \"1\": {}}}\n",
            "Model Number: 138 with model ConstantNaive in generation 0 of 2 with params {\"constant\": 1} and transformations {\"fillna\": \"nearest\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}}}\n",
            "Model Number: 139 with model NVAR in generation 0 of 2 with params {\"k\": 1, \"ridge_param\": 2e-07, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 140 with model ARDL in generation 0 of 2 with params {\"lags\": 2, \"trend\": \"c\", \"order\": 3, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"RollingMean100thN\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 141 with model ARDL in generation 0 of 2 with params {\"lags\": 3, \"trend\": \"c\", \"order\": 2, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"Slice\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Median\"}, \"1\": {\"method\": 0.5}}}\n",
            "Model Number: 142 with model VECM in generation 0 of 2 with params {\"deterministic\": \"li\", \"k_ar_diff\": 1, \"regression_type\": null} and transformations {\"fillna\": \"time\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1443, in predict\n",
            "    maModel = VECM(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/vecm.py\", line 958, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VECM\")\n",
            "ValueError: Only gave one variable to VECM\n",
            " in model 142: VECM\n",
            "Model Number: 143 with model MetricMotif in generation 0 of 2 with params {\"window\": 5, \"point_method\": \"median\", \"distance_metric\": \"mse\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 12}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"StandardScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 144 with model ARDL in generation 0 of 2 with params {\"lags\": 1, \"trend\": \"c\", \"order\": 1, \"causal\": false, \"regression_type\": \"User\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 2089, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but future_regressor not supplied\n",
            " in model 144: ARDL\n",
            "Model Number: 145 with model VAR in generation 0 of 2 with params {\"regression_type\": \"Holiday\", \"maxlags\": null, \"ic\": \"hqic\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 7, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1747, in predict\n",
            "    self.model = VAR(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/var_model.py\", line 553, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VAR\")\n",
            "ValueError: Only gave one variable to VAR\n",
            " in model 145: VAR\n",
            "Model Number: 146 with model ConstantNaive in generation 0 of 2 with params {\"constant\": 0} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}\n",
            "Model Number: 147 with model ETS in generation 0 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"multiplicative\", \"seasonal_periods\": 12} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 28, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {}}}\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 148 with model Theta in generation 0 of 2 with params {\"deseasonalize\": true, \"difference\": true, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 1.2, \"use_mle\": false} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py:492: FutureWarning:\n",
            "\n",
            "the 'damped'' keyword is deprecated, use 'damped_trend' instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 149 with model SectionalMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"chebyshev\", \"include_differenced\": true, \"k\": 3, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 7, \"method\": \"Mean\"}}}\n",
            "Model Number: 150 with model MultivariateMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"correlation\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 151 with model MetricMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"mae\", \"k\": 1, \"comparison_transformation\": {\"fillna\": \"median\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 7, \"method\": \"additive\", \"strength\": 0.5, \"first_value_only\": false}}}, \"combination_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Slice\"}, \"transformation_params\": {\"0\": {\"method\": 100}}}\n",
            "Model Number: 152 with model VAR in generation 0 of 2 with params {\"regression_type\": null, \"maxlags\": null, \"ic\": \"aic\"} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1756, in predict\n",
            "    self.model = VAR(self.df_train, freq=self.frequency).fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/var_model.py\", line 553, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VAR\")\n",
            "ValueError: Only gave one variable to VAR\n",
            " in model 152: VAR\n",
            "Model Number: 153 with model UnivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}, \"holiday\": false, \"mean_rolling_periods\": 30, \"macd_periods\": 1440, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 28, \"ewm_var_alpha\": null, \"ewm_alpha\": null, \"additional_lag_periods\": 63, \"abs_energy\": true, \"rolling_autocorr_periods\": null, \"add_date_part\": null, \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"fixed\": true, \"window\": 3}}}\n",
            "Model Number: 154 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 7, \"lag_2\": null} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 5, \"fillna\": null}}}\n",
            "Model Number: 155 with model MetricMotif in generation 0 of 2 with params {\"window\": 50, \"point_method\": \"weighted_mean\", \"distance_metric\": \"mae\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"fixed\": true, \"window\": 3}}}\n",
            "Model Number: 156 with model VAR in generation 0 of 2 with params {\"regression_type\": null, \"maxlags\": 5, \"ic\": \"bic\"} and transformations {\"fillna\": \"barycentric\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 0.7, \"first_value_only\": false}, \"1\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 1756, in predict\n",
            "    self.model = VAR(self.df_train, freq=self.frequency).fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/vector_ar/var_model.py\", line 553, in __init__\n",
            "    raise ValueError(\"Only gave one variable to VAR\")\n",
            "ValueError: Only gave one variable to VAR\n",
            " in model 156: VAR\n",
            "Model Number: 157 with model SectionalMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"matching\", \"include_differenced\": true, \"k\": 5, \"stride_size\": 10, \"regression_type\": null} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 2, \"method\": \"additive\", \"strength\": 0.2, \"first_value_only\": false}, \"1\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning:\n",
            "\n",
            "overflow encountered in reduce\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/scipy/interpolate/_polyint.py:570: RuntimeWarning:\n",
            "\n",
            "overflow encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/scipy/interpolate/_polyint.py:570: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in reduce\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 158 with model ARDL in generation 0 of 2 with params {\"lags\": 3, \"trend\": \"c\", \"order\": 1, \"causal\": false, \"regression_type\": \"simple_binarized_poly\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}\n",
            "Model Number: 159 with model UnivariateMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"minkowski\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PowerTransformer\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"decimals\": 1, \"on_transform\": true, \"on_inverse\": false}}}\n",
            "Model Number: 160 with model SectionalMotif in generation 0 of 2 with params {\"window\": 50, \"point_method\": \"weighted_mean\", \"distance_metric\": \"sqeuclidean\", \"include_differenced\": false, \"k\": 100, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": \"zero\", \"transformations\": {\"0\": \"CumSumTransformer\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"decimals\": -1, \"on_transform\": false, \"on_inverse\": true}}}}, \"1\": {\"lag_1\": 12, \"method\": \"LastValue\"}}}\n",
            "Model Number: 161 with model ARCH in generation 0 of 2 with params {\"mean\": \"HARX\", \"lags\": 1, \"vol\": \"GARCH\", \"p\": 12, \"o\": 0, \"q\": 2, \"power\": 1.5, \"dist\": \"studentst\", \"rescale\": true, \"simulations\": 1000, \"maxiter\": 200, \"regression_type\": null} and transformations {\"fillna\": \"linear\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/arch.py\", line 131, in fit\n",
            "    raise ImportError(\"`arch` package must be installed from pip\")\n",
            "ImportError: `arch` package must be installed from pip\n",
            " in model 161: ARCH\n",
            "Model Number: 162 with model ETS in generation 0 of 2 with params {\"damped_trend\": true, \"trend\": \"additive\", \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}}}\n",
            "Model Number: 163 with model ARDL in generation 0 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 1, \"causal\": false, \"regression_type\": \"simple_binarized\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}}}\n",
            "Model Number: 164 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 165 with model MetricMotif in generation 0 of 2 with params {\"window\": 50, \"point_method\": \"weighted_mean\", \"distance_metric\": \"mse\", \"k\": 1, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 2, \"fillna\": null}}}, \"combination_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 7, \"polyorder\": 4, \"deriv\": 0, \"mode\": \"interp\"}}}}} and transformations {\"fillna\": \"time\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 166 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 167 with model UnobservedComponents in generation 0 of 2 with params {\"level\": \"deterministic constant\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"cg\", \"autoregressive\": null, \"regression_type\": \"User\"} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 917, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor supplied\n",
            " in model 167: UnobservedComponents\n",
            "Model Number: 168 with model SeasonalNaive in generation 0 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 24, \"lag_2\": 7} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"rows\": 7, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 2}}}}}}\n",
            "Model Number: 169 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\", \"1\": \"PositiveShift\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear trend\", \"state_transition\": [[1, 1], [0, 1]], \"process_noise\": [[0.1, 0.0], [0.0, 0.01]], \"observation_model\": [[1, 0]], \"observation_noise\": 0.05, \"em_iter\": null}, \"1\": {}}}\n",
            "Model Number: 170 with model MetricMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"mean\", \"distance_metric\": \"mae\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"nearest\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"butter\", \"method_args\": {\"N\": 1, \"window_size\": 2, \"btype\": \"highpass\", \"analog\": false, \"output\": \"sos\"}}}}, \"combination_transformation\": {\"fillna\": \"akima\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}\n",
            "Model Number: 171 with model ARDL in generation 0 of 2 with params {\"lags\": 3, \"trend\": \"t\", \"order\": 1, \"causal\": false, \"regression_type\": \"common_fourier_rw\"} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"LastValue\"}}}\n",
            "Model Number: 172 with model ARCH in generation 0 of 2 with params {\"mean\": \"HARX\", \"lags\": 1, \"vol\": \"HARCH\", \"p\": 4, \"o\": 0, \"q\": 2, \"power\": 1.0, \"dist\": \"skewt\", \"rescale\": true, \"simulations\": 1000, \"maxiter\": 200, \"regression_type\": \"User\"} and transformations {\"fillna\": \"linear\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/arch.py\", line 131, in fit\n",
            "    raise ImportError(\"`arch` package must be installed from pip\")\n",
            "ImportError: `arch` package must be installed from pip\n",
            " in model 172: ARCH\n",
            "Model Number: 173 with model MetricMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"mse\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"butter\", \"method_args\": {\"N\": 7, \"window_size\": 364, \"btype\": \"lowpass\", \"analog\": false, \"output\": \"sos\"}}}}} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"LocalLinearTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"rolling_window\": 0.05, \"n_tails\": 0.1, \"n_future\": 0.05, \"method\": \"median\"}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/br2pfphm.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 174 with model FBProphet in generation 0 of 2 with params {\"holiday\": false, \"regression_type\": null, \"changepoint_prior_scale\": 0.1, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.8, \"growth\": \"linear\", \"n_changepoints\": 25} and transformations {\"fillna\": \"piecewise_polynomial\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/nvho22wb.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=72551', 'data', 'file=/tmp/tmpav2iq6so/br2pfphm.json', 'init=/tmp/tmpav2iq6so/nvho22wb.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modelmeqa6cgp/prophet_model-20230317052709.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:27:09 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:27:11 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 175 with model ARCH in generation 0 of 2 with params {\"mean\": \"HARX\", \"lags\": 0, \"vol\": \"EGARCH\", \"p\": 7, \"o\": 1, \"q\": 1, \"power\": 2.0, \"dist\": \"skewt\", \"rescale\": false, \"simulations\": 1000, \"maxiter\": 200, \"regression_type\": \"User\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"fixed\": true, \"window\": 7}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/arch.py\", line 131, in fit\n",
            "    raise ImportError(\"`arch` package must be installed from pip\")\n",
            "ImportError: `arch` package must be installed from pip\n",
            " in model 175: ARCH\n",
            "Model Number: 176 with model UnobservedComponents in generation 0 of 2 with params {\"level\": \"random walk with drift\", \"maxiter\": 50, \"cov_type\": \"approx\", \"method\": \"nm\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Mean\"}}}\n",
            "Model Number: 177 with model ARDL in generation 0 of 2 with params {\"lags\": 4, \"trend\": \"c\", \"order\": 3, \"causal\": true, \"regression_type\": \"simple\"} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"Discretize\"}, \"transformation_params\": {\"0\": {\"discretization\": \"center\", \"n_bins\": 20}}}}}}\n",
            "Model Number: 178 with model GLS in generation 0 of 2 with params {} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 5, \"fillna\": null}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": \"zero\", \"transformations\": {\"0\": \"Slice\"}, \"transformation_params\": {\"0\": {\"method\": 0.5}}}}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 292, in fit_transform\n",
            "    self.fit(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 282, in fit\n",
            "    self.trained_model.fit(X, Y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_base.py\", line 648, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 584, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 1124, in check_X_y\n",
            "    check_consistent_length(X, y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 397, in check_consistent_length\n",
            "    raise ValueError(\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [2728, 1364]\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer Detrend failed on fit\n",
            " in model 178: GLS\n",
            "Model Number: 179 with model LastValueNaive in generation 0 of 2 with params {} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"PositiveShift\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 180 with model NVAR in generation 0 of 2 with params {\"k\": 3, \"ridge_param\": 2e-06, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 7}}}}}}\n",
            "Model Number: 181 with model SectionalMotif in generation 0 of 2 with params {\"window\": 10, \"point_method\": \"weighted_mean\", \"distance_metric\": \"jaccard\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}}}\n",
            "Model Number: 182 with model UnivariateRegression in generation 0 of 2 with params {\"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}, \"holiday\": true, \"mean_rolling_periods\": 5, \"macd_periods\": 60, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 96, \"ewm_var_alpha\": null, \"ewm_alpha\": null, \"additional_lag_periods\": 70, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": \"simple_binarized\", \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": 3} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 2, \"fillna\": null}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": 10, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 31, \"polyorder\": 3, \"deriv\": 0, \"mode\": \"interp\"}}}}}}}\n",
            "Model Number: 183 with model ConstantNaive in generation 0 of 2 with params {\"constant\": -1} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:2418: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations. Duality gap: 101490.0253481151, tolerance: 1105.1062525002844\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 184 with model WindowRegression in generation 0 of 2 with params {\"window_size\": 10, \"input_dim\": \"univariate\", \"output_dim\": \"1step\", \"normalize_window\": true, \"max_windows\": 5000, \"regression_type\": \"User\", \"regression_model\": {\"model\": \"LightGBM\", \"model_params\": {\"objective\": \"huber\", \"learning_rate\": 0.01, \"num_leaves\": 70, \"max_depth\": 10, \"boosting_type\": \"gbdt\", \"n_estimators\": 100, \"linear_tree\": false}}} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1440, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor passed\n",
            " in model 184: WindowRegression\n",
            "Model Number: 185 with model WindowRegression in generation 0 of 2 with params {\"window_size\": 20, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": false, \"max_windows\": 5000, \"regression_type\": null, \"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 300, \"min_samples_leaf\": 1, \"bootstrap\": true}}} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "building tree 1 of 300\n",
            "building tree 2 of 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 3 of 300\n",
            "building tree 4 of 300\n",
            "building tree 5 of 300\n",
            "building tree 6 of 300\n",
            "building tree 7 of 300\n",
            "building tree 8 of 300\n",
            "building tree 9 of 300\n",
            "building tree 10 of 300\n",
            "building tree 11 of 300\n",
            "building tree 12 of 300\n",
            "building tree 13 of 300\n",
            "building tree 14 of 300\n",
            "building tree 15 of 300\n",
            "building tree 16 of 300\n",
            "building tree 17 of 300\n",
            "building tree 18 of 300\n",
            "building tree 19 of 300\n",
            "building tree 20 of 300\n",
            "building tree 21 of 300\n",
            "building tree 22 of 300\n",
            "building tree 23 of 300\n",
            "building tree 24 of 300\n",
            "building tree 25 of 300\n",
            "building tree 26 of 300\n",
            "building tree 27 of 300\n",
            "building tree 28 of 300\n",
            "building tree 29 of 300\n",
            "building tree 30 of 300\n",
            "building tree 31 of 300\n",
            "building tree 32 of 300\n",
            "building tree 33 of 300\n",
            "building tree 34 of 300\n",
            "building tree 35 of 300\n",
            "building tree 36 of 300\n",
            "building tree 37 of 300\n",
            "building tree 38 of 300\n",
            "building tree 39 of 300\n",
            "building tree 40 of 300\n",
            "building tree 41 of 300\n",
            "building tree 42 of 300\n",
            "building tree 43 of 300\n",
            "building tree 44 of 300\n",
            "building tree 45 of 300\n",
            "building tree 46 of 300\n",
            "building tree 47 of 300\n",
            "building tree 48 of 300\n",
            "building tree 49 of 300\n",
            "building tree 50 of 300\n",
            "building tree 51 of 300\n",
            "building tree 52 of 300\n",
            "building tree 53 of 300\n",
            "building tree 54 of 300\n",
            "building tree 55 of 300\n",
            "building tree 56 of 300\n",
            "building tree 57 of 300\n",
            "building tree 58 of 300\n",
            "building tree 59 of 300\n",
            "building tree 60 of 300\n",
            "building tree 61 of 300\n",
            "building tree 62 of 300\n",
            "building tree 63 of 300\n",
            "building tree 64 of 300\n",
            "building tree 65 of 300\n",
            "building tree 66 of 300\n",
            "building tree 67 of 300\n",
            "building tree 68 of 300\n",
            "building tree 69 of 300\n",
            "building tree 70 of 300\n",
            "building tree 71 of 300\n",
            "building tree 72 of 300\n",
            "building tree 73 of 300\n",
            "building tree 74 of 300\n",
            "building tree 75 of 300\n",
            "building tree 76 of 300\n",
            "building tree 77 of 300\n",
            "building tree 78 of 300\n",
            "building tree 79 of 300\n",
            "building tree 80 of 300\n",
            "building tree 81 of 300\n",
            "building tree 82 of 300\n",
            "building tree 83 of 300\n",
            "building tree 84 of 300\n",
            "building tree 85 of 300\n",
            "building tree 86 of 300\n",
            "building tree 87 of 300\n",
            "building tree 88 of 300\n",
            "building tree 89 of 300\n",
            "building tree 90 of 300\n",
            "building tree 91 of 300\n",
            "building tree 92 of 300\n",
            "building tree 93 of 300\n",
            "building tree 94 of 300\n",
            "building tree 95 of 300\n",
            "building tree 96 of 300\n",
            "building tree 97 of 300\n",
            "building tree 98 of 300\n",
            "building tree 99 of 300\n",
            "building tree 100 of 300\n",
            "building tree 101 of 300\n",
            "building tree 102 of 300\n",
            "building tree 103 of 300\n",
            "building tree 104 of 300\n",
            "building tree 105 of 300\n",
            "building tree 106 of 300\n",
            "building tree 107 of 300\n",
            "building tree 108 of 300\n",
            "building tree 109 of 300\n",
            "building tree 110 of 300\n",
            "building tree 111 of 300\n",
            "building tree 112 of 300\n",
            "building tree 113 of 300\n",
            "building tree 114 of 300\n",
            "building tree 115 of 300\n",
            "building tree 116 of 300\n",
            "building tree 117 of 300\n",
            "building tree 118 of 300\n",
            "building tree 119 of 300\n",
            "building tree 120 of 300\n",
            "building tree 121 of 300\n",
            "building tree 122 of 300\n",
            "building tree 123 of 300\n",
            "building tree 124 of 300\n",
            "building tree 125 of 300\n",
            "building tree 126 of 300\n",
            "building tree 127 of 300\n",
            "building tree 128 of 300\n",
            "building tree 129 of 300\n",
            "building tree 130 of 300\n",
            "building tree 131 of 300\n",
            "building tree 132 of 300\n",
            "building tree 133 of 300\n",
            "building tree 134 of 300\n",
            "building tree 135 of 300\n",
            "building tree 136 of 300\n",
            "building tree 137 of 300\n",
            "building tree 138 of 300\n",
            "building tree 139 of 300\n",
            "building tree 140 of 300\n",
            "building tree 141 of 300\n",
            "building tree 142 of 300\n",
            "building tree 143 of 300\n",
            "building tree 144 of 300\n",
            "building tree 145 of 300\n",
            "building tree 146 of 300\n",
            "building tree 147 of 300\n",
            "building tree 148 of 300\n",
            "building tree 149 of 300\n",
            "building tree 150 of 300\n",
            "building tree 151 of 300\n",
            "building tree 152 of 300\n",
            "building tree 153 of 300\n",
            "building tree 154 of 300\n",
            "building tree 155 of 300\n",
            "building tree 156 of 300\n",
            "building tree 157 of 300\n",
            "building tree 158 of 300\n",
            "building tree 159 of 300\n",
            "building tree 160 of 300\n",
            "building tree 161 of 300\n",
            "building tree 162 of 300\n",
            "building tree 163 of 300\n",
            "building tree 164 of 300\n",
            "building tree 165 of 300\n",
            "building tree 166 of 300\n",
            "building tree 167 of 300\n",
            "building tree 168 of 300\n",
            "building tree 169 of 300\n",
            "building tree 170 of 300\n",
            "building tree 171 of 300\n",
            "building tree 172 of 300\n",
            "building tree 173 of 300\n",
            "building tree 174 of 300\n",
            "building tree 175 of 300\n",
            "building tree 176 of 300\n",
            "building tree 177 of 300\n",
            "building tree 178 of 300\n",
            "building tree 179 of 300\n",
            "building tree 180 of 300\n",
            "building tree 181 of 300\n",
            "building tree 182 of 300\n",
            "building tree 183 of 300\n",
            "building tree 184 of 300\n",
            "building tree 185 of 300\n",
            "building tree 186 of 300\n",
            "building tree 187 of 300\n",
            "building tree 188 of 300\n",
            "building tree 189 of 300\n",
            "building tree 190 of 300\n",
            "building tree 191 of 300\n",
            "building tree 192 of 300\n",
            "building tree 193 of 300\n",
            "building tree 194 of 300\n",
            "building tree 195 of 300\n",
            "building tree 196 of 300\n",
            "building tree 197 of 300\n",
            "building tree 198 of 300\n",
            "building tree 199 of 300\n",
            "building tree 200 of 300\n",
            "building tree 201 of 300\n",
            "building tree 202 of 300\n",
            "building tree 203 of 300\n",
            "building tree 204 of 300\n",
            "building tree 205 of 300\n",
            "building tree 206 of 300\n",
            "building tree 207 of 300\n",
            "building tree 208 of 300\n",
            "building tree 209 of 300\n",
            "building tree 210 of 300\n",
            "building tree 211 of 300\n",
            "building tree 212 of 300\n",
            "building tree 213 of 300\n",
            "building tree 214 of 300\n",
            "building tree 215 of 300\n",
            "building tree 216 of 300\n",
            "building tree 217 of 300\n",
            "building tree 218 of 300\n",
            "building tree 219 of 300\n",
            "building tree 220 of 300\n",
            "building tree 221 of 300\n",
            "building tree 222 of 300\n",
            "building tree 223 of 300\n",
            "building tree 224 of 300\n",
            "building tree 225 of 300\n",
            "building tree 226 of 300\n",
            "building tree 227 of 300\n",
            "building tree 228 of 300\n",
            "building tree 229 of 300\n",
            "building tree 230 of 300\n",
            "building tree 231 of 300\n",
            "building tree 232 of 300\n",
            "building tree 233 of 300\n",
            "building tree 234 of 300\n",
            "building tree 235 of 300\n",
            "building tree 236 of 300\n",
            "building tree 237 of 300\n",
            "building tree 238 of 300\n",
            "building tree 239 of 300\n",
            "building tree 240 of 300\n",
            "building tree 241 of 300\n",
            "building tree 242 of 300\n",
            "building tree 243 of 300\n",
            "building tree 244 of 300\n",
            "building tree 245 of 300\n",
            "building tree 246 of 300\n",
            "building tree 247 of 300\n",
            "building tree 248 of 300\n",
            "building tree 249 of 300\n",
            "building tree 250 of 300\n",
            "building tree 251 of 300\n",
            "building tree 252 of 300\n",
            "building tree 253 of 300\n",
            "building tree 254 of 300\n",
            "building tree 255 of 300\n",
            "building tree 256 of 300\n",
            "building tree 257 of 300\n",
            "building tree 258 of 300\n",
            "building tree 259 of 300\n",
            "building tree 260 of 300\n",
            "building tree 261 of 300\n",
            "building tree 262 of 300\n",
            "building tree 263 of 300\n",
            "building tree 264 of 300\n",
            "building tree 265 of 300\n",
            "building tree 266 of 300\n",
            "building tree 267 of 300\n",
            "building tree 268 of 300\n",
            "building tree 269 of 300\n",
            "building tree 270 of 300\n",
            "building tree 271 of 300\n",
            "building tree 272 of 300\n",
            "building tree 273 of 300\n",
            "building tree 274 of 300\n",
            "building tree 275 of 300\n",
            "building tree 276 of 300\n",
            "building tree 277 of 300\n",
            "building tree 278 of 300\n",
            "building tree 279 of 300\n",
            "building tree 280 of 300\n",
            "building tree 281 of 300\n",
            "building tree 282 of 300\n",
            "building tree 283 of 300\n",
            "building tree 284 of 300\n",
            "building tree 285 of 300\n",
            "building tree 286 of 300\n",
            "building tree 287 of 300\n",
            "building tree 288 of 300\n",
            "building tree 289 of 300\n",
            "building tree 290 of 300\n",
            "building tree 291 of 300\n",
            "building tree 292 of 300\n",
            "building tree 293 of 300\n",
            "building tree 294 of 300\n",
            "building tree 295 of 300\n",
            "building tree 296 of 300\n",
            "building tree 297 of 300\n",
            "building tree 298 of 300\n",
            "building tree 299 of 300\n",
            "building tree 300 of 300\n",
            "Model Number: 186 with model UnobservedComponents in generation 0 of 2 with params {\"level\": \"deterministic trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:   29.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Generation: 1 of 2\n",
            "Model Number: 187 with model NVAR in generation 1 of 2 with params {\"k\": 3, \"ridge_param\": 0.002, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"barycentric\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning:\n",
            "\n",
            "overflow encountered in reduce\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/scipy/interpolate/_polyint.py:570: RuntimeWarning:\n",
            "\n",
            "overflow encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/scipy/interpolate/_polyint.py:570: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in reduce\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 188 with model MultivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 200, \"min_samples_leaf\": 1, \"bootstrap\": true}}, \"mean_rolling_periods\": 5, \"macd_periods\": 96, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 7, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": null, \"ewm_alpha\": 0.5, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 3, \"holiday\": false, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"nearest\", \"transformations\": {\"0\": \"AnomalyRemoval\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"method\": \"IQR\", \"method_params\": {\"iqr_threshold\": 3.0, \"iqr_quantiles\": [0.25, 0.75]}, \"fillna\": \"ffill\", \"transform_dict\": {\"transformations\": {\"0\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"datepart_method\": \"simple_3\", \"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}}}}}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=3.88833e-26): result may not be accurate.\n",
            "\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 1 of 200\n",
            "building tree 2 of 200\n",
            "building tree 3 of 200\n",
            "building tree 4 of 200\n",
            "building tree 5 of 200\n",
            "building tree 6 of 200\n",
            "building tree 7 of 200\n",
            "building tree 8 of 200\n",
            "building tree 9 of 200\n",
            "building tree 10 of 200\n",
            "building tree 11 of 200\n",
            "building tree 12 of 200\n",
            "building tree 13 of 200\n",
            "building tree 14 of 200\n",
            "building tree 15 of 200\n",
            "building tree 16 of 200\n",
            "building tree 17 of 200\n",
            "building tree 18 of 200\n",
            "building tree 19 of 200\n",
            "building tree 20 of 200\n",
            "building tree 21 of 200\n",
            "building tree 22 of 200\n",
            "building tree 23 of 200\n",
            "building tree 24 of 200\n",
            "building tree 25 of 200\n",
            "building tree 26 of 200\n",
            "building tree 27 of 200\n",
            "building tree 28 of 200\n",
            "building tree 29 of 200\n",
            "building tree 30 of 200\n",
            "building tree 31 of 200\n",
            "building tree 32 of 200\n",
            "building tree 33 of 200\n",
            "building tree 34 of 200\n",
            "building tree 35 of 200\n",
            "building tree 36 of 200\n",
            "building tree 37 of 200\n",
            "building tree 38 of 200\n",
            "building tree 39 of 200\n",
            "building tree 40 of 200\n",
            "building tree 41 of 200\n",
            "building tree 42 of 200\n",
            "building tree 43 of 200\n",
            "building tree 44 of 200\n",
            "building tree 45 of 200\n",
            "building tree 46 of 200\n",
            "building tree 47 of 200\n",
            "building tree 48 of 200\n",
            "building tree 49 of 200\n",
            "building tree 50 of 200\n",
            "building tree 51 of 200\n",
            "building tree 52 of 200\n",
            "building tree 53 of 200\n",
            "building tree 54 of 200\n",
            "building tree 55 of 200\n",
            "building tree 56 of 200\n",
            "building tree 57 of 200\n",
            "building tree 58 of 200\n",
            "building tree 59 of 200\n",
            "building tree 60 of 200\n",
            "building tree 61 of 200\n",
            "building tree 62 of 200\n",
            "building tree 63 of 200\n",
            "building tree 64 of 200\n",
            "building tree 65 of 200\n",
            "building tree 66 of 200\n",
            "building tree 67 of 200\n",
            "building tree 68 of 200\n",
            "building tree 69 of 200\n",
            "building tree 70 of 200\n",
            "building tree 71 of 200\n",
            "building tree 72 of 200\n",
            "building tree 73 of 200\n",
            "building tree 74 of 200\n",
            "building tree 75 of 200\n",
            "building tree 76 of 200\n",
            "building tree 77 of 200\n",
            "building tree 78 of 200\n",
            "building tree 79 of 200\n",
            "building tree 80 of 200\n",
            "building tree 81 of 200\n",
            "building tree 82 of 200\n",
            "building tree 83 of 200\n",
            "building tree 84 of 200\n",
            "building tree 85 of 200\n",
            "building tree 86 of 200\n",
            "building tree 87 of 200\n",
            "building tree 88 of 200\n",
            "building tree 89 of 200\n",
            "building tree 90 of 200\n",
            "building tree 91 of 200\n",
            "building tree 92 of 200\n",
            "building tree 93 of 200\n",
            "building tree 94 of 200\n",
            "building tree 95 of 200\n",
            "building tree 96 of 200\n",
            "building tree 97 of 200\n",
            "building tree 98 of 200\n",
            "building tree 99 of 200\n",
            "building tree 100 of 200\n",
            "building tree 101 of 200\n",
            "building tree 102 of 200\n",
            "building tree 103 of 200\n",
            "building tree 104 of 200\n",
            "building tree 105 of 200\n",
            "building tree 106 of 200\n",
            "building tree 107 of 200\n",
            "building tree 108 of 200\n",
            "building tree 109 of 200\n",
            "building tree 110 of 200\n",
            "building tree 111 of 200\n",
            "building tree 112 of 200\n",
            "building tree 113 of 200\n",
            "building tree 114 of 200\n",
            "building tree 115 of 200\n",
            "building tree 116 of 200\n",
            "building tree 117 of 200\n",
            "building tree 118 of 200\n",
            "building tree 119 of 200\n",
            "building tree 120 of 200\n",
            "building tree 121 of 200\n",
            "building tree 122 of 200\n",
            "building tree 123 of 200\n",
            "building tree 124 of 200\n",
            "building tree 125 of 200\n",
            "building tree 126 of 200\n",
            "building tree 127 of 200\n",
            "building tree 128 of 200\n",
            "building tree 129 of 200\n",
            "building tree 130 of 200\n",
            "building tree 131 of 200\n",
            "building tree 132 of 200\n",
            "building tree 133 of 200\n",
            "building tree 134 of 200\n",
            "building tree 135 of 200\n",
            "building tree 136 of 200\n",
            "building tree 137 of 200\n",
            "building tree 138 of 200\n",
            "building tree 139 of 200\n",
            "building tree 140 of 200\n",
            "building tree 141 of 200\n",
            "building tree 142 of 200\n",
            "building tree 143 of 200\n",
            "building tree 144 of 200\n",
            "building tree 145 of 200\n",
            "building tree 146 of 200\n",
            "building tree 147 of 200\n",
            "building tree 148 of 200\n",
            "building tree 149 of 200\n",
            "building tree 150 of 200\n",
            "building tree 151 of 200\n",
            "building tree 152 of 200\n",
            "building tree 153 of 200\n",
            "building tree 154 of 200\n",
            "building tree 155 of 200\n",
            "building tree 156 of 200\n",
            "building tree 157 of 200\n",
            "building tree 158 of 200\n",
            "building tree 159 of 200\n",
            "building tree 160 of 200\n",
            "building tree 161 of 200\n",
            "building tree 162 of 200\n",
            "building tree 163 of 200\n",
            "building tree 164 of 200\n",
            "building tree 165 of 200\n",
            "building tree 166 of 200\n",
            "building tree 167 of 200\n",
            "building tree 168 of 200\n",
            "building tree 169 of 200\n",
            "building tree 170 of 200\n",
            "building tree 171 of 200\n",
            "building tree 172 of 200\n",
            "building tree 173 of 200\n",
            "building tree 174 of 200\n",
            "building tree 175 of 200\n",
            "building tree 176 of 200\n",
            "building tree 177 of 200\n",
            "building tree 178 of 200\n",
            "building tree 179 of 200\n",
            "building tree 180 of 200\n",
            "building tree 181 of 200\n",
            "building tree 182 of 200\n",
            "building tree 183 of 200\n",
            "building tree 184 of 200\n",
            "building tree 185 of 200\n",
            "building tree 186 of 200\n",
            "building tree 187 of 200\n",
            "building tree 188 of 200\n",
            "building tree 189 of 200\n",
            "building tree 190 of 200\n",
            "building tree 191 of 200\n",
            "building tree 192 of 200\n",
            "building tree 193 of 200\n",
            "building tree 194 of 200\n",
            "building tree 195 of 200\n",
            "building tree 196 of 200\n",
            "building tree 197 of 200\n",
            "building tree 198 of 200\n",
            "building tree 199 of 200\n",
            "building tree 200 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    4.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 189 with model MetricMotif in generation 1 of 2 with params {\"window\": 5, \"point_method\": \"median\", \"distance_metric\": \"mqae\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"butter\", \"method_args\": {\"N\": 7, \"btype\": \"lowpass\", \"analog\": false, \"output\": \"sos\", \"Wn\": 0.0027472527472527475}}}}} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 0.7, \"first_value_only\": false}, \"1\": {\"model\": \"GLS\", \"phi\": 0.999, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 2}}}}}}\n",
            "Model Number: 190 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"PositiveShift\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 191 with model WindowRegression in generation 1 of 2 with params {\"window_size\": 10, \"input_dim\": \"univariate\", \"output_dim\": \"1step\", \"normalize_window\": false, \"max_windows\": 1000, \"regression_type\": null, \"regression_model\": {\"model\": \"KNN\", \"model_params\": {\"n_neighbors\": 3, \"weights\": \"uniform\", \"p\": 2, \"leaf_size\": 30}}} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"StandardScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 192 with model GLS in generation 1 of 2 with params {} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"fixed\": true, \"window\": 3}}}\n",
            "Model Number: 193 with model ETS in generation 1 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"MeanDifference\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"middle\", \"decimals\": 0, \"on_transform\": false, \"on_inverse\": true}}}\n",
            "Model Number: 194 with model Theta in generation 1 of 2 with params {\"deseasonalize\": true, \"difference\": true, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 1.2, \"use_mle\": false} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 195 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 1440, \"method\": \"Median\"}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning:\n",
            "\n",
            "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 196 with model ETS in generation 1 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": null} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 197 with model SectionalMotif in generation 1 of 2 with params {\"window\": 5, \"point_method\": \"median\", \"distance_metric\": \"russellrao\", \"include_differenced\": false, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 198 with model SectionalMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 199 with model Theta in generation 1 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 1.2, \"use_mle\": false} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"PowerTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 200 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 28, \"point_method\": \"midhinge\", \"distance_metric\": \"cityblock\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"akima\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 201 with model MultivariateMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"mahalanobis\", \"k\": 15, \"max_windows\": null} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"bkfilter\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null}, \"1\": {}}}\n",
            "Model Number: 202 with model ConstantNaive in generation 1 of 2 with params {\"constant\": 0} and transformations {\"fillna\": \"nearest\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"remove\", \"std_threshold\": 3.5, \"fillna\": \"rolling_mean_24\"}}}\n",
            "Model Number: 203 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 24, \"lag_2\": 84} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 204 with model ARDL in generation 1 of 2 with params {\"lags\": 4, \"trend\": \"c\", \"order\": 3, \"causal\": true, \"regression_type\": \"lunar_phase\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 205 with model MultivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 30, \"macd_periods\": 17, \"std_rolling_periods\": 7, \"max_rolling_periods\": 2, \"min_rolling_periods\": null, \"quantile90_rolling_periods\": null, \"quantile10_rolling_periods\": 5, \"ewm_alpha\": null, \"ewm_var_alpha\": 0.5, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": \"simple\", \"polynomial_degree\": null, \"regression_type\": null, \"window\": 3, \"holiday\": false, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 206 with model MultivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 200, \"min_samples_leaf\": 1, \"bootstrap\": true}}, \"mean_rolling_periods\": 12, \"macd_periods\": 94, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 7, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 30, \"ewm_alpha\": 0.1, \"ewm_var_alpha\": 0.2, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": null, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}}}\n",
            "building tree 1 of 200\n",
            "building tree 2 of 200\n",
            "building tree 3 of 200\n",
            "building tree 4 of 200\n",
            "building tree 5 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 6 of 200\n",
            "building tree 7 of 200\n",
            "building tree 8 of 200\n",
            "building tree 9 of 200\n",
            "building tree 10 of 200\n",
            "building tree 11 of 200\n",
            "building tree 12 of 200\n",
            "building tree 13 of 200\n",
            "building tree 14 of 200\n",
            "building tree 15 of 200\n",
            "building tree 16 of 200\n",
            "building tree 17 of 200\n",
            "building tree 18 of 200\n",
            "building tree 19 of 200\n",
            "building tree 20 of 200\n",
            "building tree 21 of 200\n",
            "building tree 22 of 200\n",
            "building tree 23 of 200\n",
            "building tree 24 of 200\n",
            "building tree 25 of 200\n",
            "building tree 26 of 200\n",
            "building tree 27 of 200\n",
            "building tree 28 of 200\n",
            "building tree 29 of 200\n",
            "building tree 30 of 200\n",
            "building tree 31 of 200\n",
            "building tree 32 of 200\n",
            "building tree 33 of 200\n",
            "building tree 34 of 200\n",
            "building tree 35 of 200\n",
            "building tree 36 of 200\n",
            "building tree 37 of 200\n",
            "building tree 38 of 200\n",
            "building tree 39 of 200\n",
            "building tree 40 of 200\n",
            "building tree 41 of 200\n",
            "building tree 42 of 200\n",
            "building tree 43 of 200\n",
            "building tree 44 of 200\n",
            "building tree 45 of 200\n",
            "building tree 46 of 200\n",
            "building tree 47 of 200\n",
            "building tree 48 of 200\n",
            "building tree 49 of 200\n",
            "building tree 50 of 200\n",
            "building tree 51 of 200\n",
            "building tree 52 of 200\n",
            "building tree 53 of 200\n",
            "building tree 54 of 200\n",
            "building tree 55 of 200\n",
            "building tree 56 of 200\n",
            "building tree 57 of 200\n",
            "building tree 58 of 200\n",
            "building tree 59 of 200\n",
            "building tree 60 of 200\n",
            "building tree 61 of 200\n",
            "building tree 62 of 200\n",
            "building tree 63 of 200\n",
            "building tree 64 of 200\n",
            "building tree 65 of 200\n",
            "building tree 66 of 200\n",
            "building tree 67 of 200\n",
            "building tree 68 of 200\n",
            "building tree 69 of 200\n",
            "building tree 70 of 200\n",
            "building tree 71 of 200\n",
            "building tree 72 of 200\n",
            "building tree 73 of 200\n",
            "building tree 74 of 200\n",
            "building tree 75 of 200\n",
            "building tree 76 of 200\n",
            "building tree 77 of 200\n",
            "building tree 78 of 200\n",
            "building tree 79 of 200\n",
            "building tree 80 of 200\n",
            "building tree 81 of 200\n",
            "building tree 82 of 200\n",
            "building tree 83 of 200\n",
            "building tree 84 of 200\n",
            "building tree 85 of 200\n",
            "building tree 86 of 200\n",
            "building tree 87 of 200\n",
            "building tree 88 of 200\n",
            "building tree 89 of 200\n",
            "building tree 90 of 200\n",
            "building tree 91 of 200\n",
            "building tree 92 of 200\n",
            "building tree 93 of 200\n",
            "building tree 94 of 200\n",
            "building tree 95 of 200\n",
            "building tree 96 of 200\n",
            "building tree 97 of 200\n",
            "building tree 98 of 200\n",
            "building tree 99 of 200\n",
            "building tree 100 of 200\n",
            "building tree 101 of 200\n",
            "building tree 102 of 200\n",
            "building tree 103 of 200\n",
            "building tree 104 of 200\n",
            "building tree 105 of 200\n",
            "building tree 106 of 200\n",
            "building tree 107 of 200\n",
            "building tree 108 of 200\n",
            "building tree 109 of 200\n",
            "building tree 110 of 200\n",
            "building tree 111 of 200\n",
            "building tree 112 of 200\n",
            "building tree 113 of 200\n",
            "building tree 114 of 200\n",
            "building tree 115 of 200\n",
            "building tree 116 of 200\n",
            "building tree 117 of 200\n",
            "building tree 118 of 200\n",
            "building tree 119 of 200\n",
            "building tree 120 of 200\n",
            "building tree 121 of 200\n",
            "building tree 122 of 200\n",
            "building tree 123 of 200\n",
            "building tree 124 of 200\n",
            "building tree 125 of 200\n",
            "building tree 126 of 200\n",
            "building tree 127 of 200\n",
            "building tree 128 of 200\n",
            "building tree 129 of 200\n",
            "building tree 130 of 200\n",
            "building tree 131 of 200\n",
            "building tree 132 of 200\n",
            "building tree 133 of 200\n",
            "building tree 134 of 200\n",
            "building tree 135 of 200\n",
            "building tree 136 of 200\n",
            "building tree 137 of 200\n",
            "building tree 138 of 200\n",
            "building tree 139 of 200\n",
            "building tree 140 of 200\n",
            "building tree 141 of 200\n",
            "building tree 142 of 200\n",
            "building tree 143 of 200\n",
            "building tree 144 of 200\n",
            "building tree 145 of 200\n",
            "building tree 146 of 200\n",
            "building tree 147 of 200\n",
            "building tree 148 of 200\n",
            "building tree 149 of 200\n",
            "building tree 150 of 200\n",
            "building tree 151 of 200\n",
            "building tree 152 of 200\n",
            "building tree 153 of 200\n",
            "building tree 154 of 200\n",
            "building tree 155 of 200\n",
            "building tree 156 of 200\n",
            "building tree 157 of 200\n",
            "building tree 158 of 200\n",
            "building tree 159 of 200\n",
            "building tree 160 of 200\n",
            "building tree 161 of 200\n",
            "building tree 162 of 200\n",
            "building tree 163 of 200\n",
            "building tree 164 of 200\n",
            "building tree 165 of 200\n",
            "building tree 166 of 200\n",
            "building tree 167 of 200\n",
            "building tree 168 of 200\n",
            "building tree 169 of 200\n",
            "building tree 170 of 200\n",
            "building tree 171 of 200\n",
            "building tree 172 of 200\n",
            "building tree 173 of 200\n",
            "building tree 174 of 200\n",
            "building tree 175 of 200\n",
            "building tree 176 of 200\n",
            "building tree 177 of 200\n",
            "building tree 178 of 200\n",
            "building tree 179 of 200\n",
            "building tree 180 of 200\n",
            "building tree 181 of 200\n",
            "building tree 182 of 200\n",
            "building tree 183 of 200\n",
            "building tree 184 of 200\n",
            "building tree 185 of 200\n",
            "building tree 186 of 200\n",
            "building tree 187 of 200\n",
            "building tree 188 of 200\n",
            "building tree 189 of 200\n",
            "building tree 190 of 200\n",
            "building tree 191 of 200\n",
            "building tree 192 of 200\n",
            "building tree 193 of 200\n",
            "building tree 194 of 200\n",
            "building tree 195 of 200\n",
            "building tree 196 of 200\n",
            "building tree 197 of 200\n",
            "building tree 198 of 200\n",
            "building tree 199 of 200\n",
            "building tree 200 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    4.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 207 with model MetricMotif in generation 1 of 2 with params {\"window\": 3, \"point_method\": \"midhinge\", \"distance_metric\": \"mqae\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear stochastic seasonal 7\", \"state_transition\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \"observation_model\": [[1, 0, 1, 0, 0, 0, 0, 0]], \"observation_noise\": 0.25, \"em_iter\": null}}}} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 420, \"method\": \"LastValue\"}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/nhcfhzid.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 208 with model FBProphet in generation 1 of 2 with params {\"holiday\": {\"threshold\": 0.8, \"splash_threshold\": null, \"use_dayofmonth_holidays\": true, \"use_wkdom_holidays\": true, \"use_wkdeom_holidays\": true, \"use_lunar_holidays\": false, \"use_lunar_weekday\": false, \"use_islamic_holidays\": false, \"use_hebrew_holidays\": false, \"anomaly_detector_params\": {\"method\": \"rolling_zscore\", \"transform_dict\": null, \"forecast_params\": null, \"method_params\": {\"distribution\": \"norm\", \"alpha\": 0.05, \"rolling_periods\": 200, \"center\": true}}}, \"regression_type\": null, \"growth\": \"linear\", \"n_changepoints\": 20, \"changepoint_prior_scale\": 0.1, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.85, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 40} and transformations {\"fillna\": \"piecewise_polynomial\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Log\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}, \"1\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/xaqinccx.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=41729', 'data', 'file=/tmp/tmpav2iq6so/nhcfhzid.json', 'init=/tmp/tmpav2iq6so/xaqinccx.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modeltnbzvcjn/prophet_model-20230317052804.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:28:04 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:28:06 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 209 with model MultivariateMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"jensenshannon\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 210 with model Theta in generation 1 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 3, \"use_mle\": false} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 211 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 2, \"lag_2\": 7} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"lag_1\": 24, \"method\": \"Mean\"}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 2}}}}}}\n",
            "Model Number: 212 with model ARDL in generation 1 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 1, \"causal\": true, \"regression_type\": \"simple_binarized\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}}}\n",
            "Model Number: 213 with model MultivariateMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"mahalanobis\", \"k\": 10, \"max_windows\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"RobustScaler\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"lag_1\": 4, \"method\": \"Mean\"}}}\n",
            "Model Number: 214 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"sokalsneath\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"RobustScaler\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 215 with model UnobservedComponents in generation 1 of 2 with params {\"level\": false, \"maxiter\": 100, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": null, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": 10, \"transform_dict\": null}}}\n",
            "Model Number: 216 with model MetricMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"mse\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}}}} and transformations {\"fillna\": \"time\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 420, \"method\": \"LastValue\"}}}\n",
            "Model Number: 217 with model ETS in generation 1 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"middle\", \"decimals\": 0, \"on_transform\": false, \"on_inverse\": true}}}\n",
            "Model Number: 218 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"minkowski\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 219 with model MultivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"base_score\": 0.5, \"booster\": \"gbtree\", \"colsample_bylevel\": 0.541426, \"colsample_bynode\": 1, \"colsample_bytree\": 1.0, \"early_stopping_rounds\": null, \"enable_categorical\": false, \"eval_metric\": null, \"feature_types\": null, \"gamma\": 0, \"grow_policy\": \"depthwise\", \"importance_type\": null, \"interaction_constraints\": \"\", \"learning_rate\": 0.012543, \"max_bin\": 256, \"max_cat_threshold\": 64, \"max_cat_to_onehot\": 4, \"max_delta_step\": 0, \"max_depth\": 11, \"max_leaves\": 0, \"min_child_weight\": 0.0127203, \"monotone_constraints\": \"()\", \"n_estimators\": 319, \"num_parallel_tree\": 1, \"predictor\": \"auto\"}, \"mean_rolling_periods\": 30, \"macd_periods\": 2, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": null, \"quantile10_rolling_periods\": 5, \"ewm_alpha\": null, \"ewm_var_alpha\": 0.5, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": \"expanded\", \"polynomial_degree\": null, \"regression_type\": null, \"window\": null, \"holiday\": false, \"probabilistic\": false, \"cointegration\": \"BTCD\", \"cointegration_lag\": 7} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"PCA\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Mean\"}, \"1\": {\"whiten\": false}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 2699, in fit\n",
            "    self.model = retrieve_regressor(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 218, in retrieve_regressor\n",
            "    model_class = regression_model['model']\n",
            "KeyError: 'model'\n",
            " in model 219: MultivariateRegression\n",
            "Model Number: 220 with model AverageValueNaive in generation 1 of 2 with params {\"method\": \"Median\", \"window\": 10} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 221 with model ARDL in generation 1 of 2 with params {\"lags\": 2, \"trend\": \"ct\", \"order\": 1, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"Discretize\"}, \"transformation_params\": {\"0\": {\"discretization\": \"center\", \"n_bins\": 20}}}}}}\n",
            "Model Number: 222 with model GLS in generation 1 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PctChangeTransformer\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 223 with model DatepartRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"Transformer\", \"model_params\": {\"epochs\": 50, \"batch_size\": 16, \"optimizer\": \"rmsprop\", \"loss\": \"mse\", \"head_size\": 256, \"num_heads\": 2, \"ff_dim\": 4, \"num_transformer_blocks\": 2, \"mlp_units\": [128], \"mlp_dropout\": 0.2, \"dropout\": 0.05}}, \"datepart_method\": \"common_fourier\", \"polynomial_degree\": null, \"regression_type\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"AnomalyRemoval\"}, \"transformation_params\": {\"0\": {\"method\": \"remove\", \"std_threshold\": 3.5, \"fillna\": \"mean\"}, \"1\": {\"method\": \"mad\", \"method_params\": {\"distribution\": \"norm\", \"alpha\": 0.05}, \"fillna\": \"rolling_mean_24\", \"transform_dict\": null}}}\n",
            "Epoch 1/50\n",
            "142/142 - 11s - loss: 212.4220 - val_loss: 768.2531 - 11s/epoch - 77ms/step\n",
            "Epoch 2/50\n",
            "142/142 - 7s - loss: 114.2296 - val_loss: 722.5429 - 7s/epoch - 49ms/step\n",
            "Epoch 3/50\n",
            "142/142 - 6s - loss: 112.1455 - val_loss: 757.2997 - 6s/epoch - 45ms/step\n",
            "Epoch 4/50\n",
            "142/142 - 7s - loss: 110.5061 - val_loss: 713.7642 - 7s/epoch - 50ms/step\n",
            "Epoch 5/50\n",
            "142/142 - 6s - loss: 109.9671 - val_loss: 745.1329 - 6s/epoch - 44ms/step\n",
            "Epoch 6/50\n",
            "142/142 - 7s - loss: 112.4573 - val_loss: 777.7686 - 7s/epoch - 49ms/step\n",
            "Epoch 7/50\n",
            "142/142 - 6s - loss: 109.9315 - val_loss: 714.7237 - 6s/epoch - 45ms/step\n",
            "Epoch 8/50\n",
            "142/142 - 7s - loss: 109.5999 - val_loss: 758.1295 - 7s/epoch - 52ms/step\n",
            "Epoch 9/50\n",
            "142/142 - 6s - loss: 110.1614 - val_loss: 814.3820 - 6s/epoch - 42ms/step\n",
            "Epoch 10/50\n",
            "142/142 - 7s - loss: 110.0400 - val_loss: 764.4848 - 7s/epoch - 47ms/step\n",
            "Epoch 11/50\n",
            "142/142 - 6s - loss: 109.7902 - val_loss: 786.8414 - 6s/epoch - 45ms/step\n",
            "Epoch 12/50\n",
            "142/142 - 7s - loss: 110.2076 - val_loss: 720.9858 - 7s/epoch - 48ms/step\n",
            "Epoch 13/50\n",
            "142/142 - 6s - loss: 109.9440 - val_loss: 813.9072 - 6s/epoch - 44ms/step\n",
            "Epoch 14/50\n",
            "142/142 - 7s - loss: 109.8450 - val_loss: 840.1558 - 7s/epoch - 48ms/step\n",
            "1/1 [==============================] - 0s 431ms/step\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 721, in ModelPrediction\n",
            "    raise ValueError(\n",
            "ValueError: Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True\n",
            " in model 223: DatepartRegression\n",
            "Model Number: 224 with model MultivariateMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"correlation\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 225 with model MultivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"ExtraTrees\", \"model_params\": {\"n_estimators\": 100, \"min_samples_leaf\": 1, \"max_depth\": 30}}, \"mean_rolling_periods\": 12, \"macd_periods\": 94, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 168, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 30, \"ewm_alpha\": 0.1, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": \"simple_2\", \"polynomial_degree\": null, \"regression_type\": null, \"window\": 3, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AnomalyRemoval\"}, \"transformation_params\": {\"0\": {\"method\": \"IQR\", \"method_params\": {\"iqr_threshold\": 3.0, \"iqr_quantiles\": [0.25, 0.75]}, \"fillna\": \"ffill\", \"transform_dict\": {\"transformations\": {\"0\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"datepart_method\": \"simple_3\", \"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}}}}}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=3.88833e-26): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 226 with model AverageValueNaive in generation 1 of 2 with params {\"method\": \"Exp_Weighted_Mean\", \"window\": null} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"AnomalyRemoval\"}, \"transformation_params\": {\"0\": {\"method\": \"zscore\", \"transform_dict\": {\"transformations\": {\"0\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"datepart_method\": \"simple_3\", \"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}}}}, \"method_params\": {\"distribution\": \"uniform\", \"alpha\": 0.05}}}}}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 227 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 228 with model NVAR in generation 1 of 2 with params {\"k\": 1, \"ridge_param\": 2e-07, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 28, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 229 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 230 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"ScipyFilter\", \"1\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"butter\", \"method_args\": {\"N\": 1, \"window_size\": 96, \"btype\": \"highpass\", \"analog\": false, \"output\": \"sos\"}}, \"1\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 31, \"polyorder\": 2, \"deriv\": 0, \"mode\": \"interp\"}}}}\n",
            "Model Number: 231 with model NVAR in generation 1 of 2 with params {\"k\": 1, \"ridge_param\": 0.002, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"std_sorted\"} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"Discretize\"}, \"transformation_params\": {\"0\": {\"discretization\": \"lower\", \"n_bins\": 10}}}\n",
            "Model Number: 232 with model AverageValueNaive in generation 1 of 2 with params {\"method\": \"Mean\", \"window\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"model\": \"GLS\", \"phi\": 0.99, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 233 with model WindowRegression in generation 1 of 2 with params {\"window_size\": 10, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": false, \"max_windows\": 5000, \"regression_type\": null, \"regression_model\": {\"model\": \"MLP\", \"model_params\": {\"hidden_layer_sizes\": [72, 36, 72], \"max_iter\": 250, \"activation\": \"relu\", \"solver\": \"lbfgs\", \"early_stopping\": false, \"learning_rate_init\": 0.001}}} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"PctChangeTransformer\"}, \"transformation_params\": {\"0\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 234 with model ARIMA in generation 1 of 2 with params {\"p\": 0, \"d\": 1, \"q\": 12, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"Log\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 235 with model NVAR in generation 1 of 2 with params {\"k\": 1, \"ridge_param\": 0.002, \"warmup_pts\": 50, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"std_sorted\"} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 7}}}}, \"1\": {\"fixed\": false, \"window\": 2}}}\n",
            "Model Number: 236 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 24, \"lag_2\": 84} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Median\"}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 237 with model Theta in generation 1 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 2, \"use_mle\": false} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": 3, \"min_samples_split\": 1.0}}, \"datepart_method\": \"simple_2\", \"polynomial_degree\": 2, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3}}}}}}\n",
            "Model Number: 238 with model UnivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 1.0}}, \"holiday\": true, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": 12, \"min_rolling_periods\": 58, \"ewm_var_alpha\": null, \"ewm_alpha\": null, \"additional_lag_periods\": 11, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": \"simple_2_poly\", \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": \"User\", \"window\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"cffilter\"}, \"transformation_params\": {\"0\": {\"model\": \"Tweedie\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 2177, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but not future_regressor supplied.\n",
            " in model 238: UnivariateRegression\n",
            "Model Number: 239 with model ARDL in generation 1 of 2 with params {\"lags\": 2, \"trend\": \"c\", \"order\": 1, \"causal\": false, \"regression_type\": \"simple_2\"} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 7, \"method\": \"additive\", \"strength\": 0.7, \"first_value_only\": false}}}\n",
            "Model Number: 240 with model SectionalMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"weighted_mean\", \"distance_metric\": \"sokalsneath\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 241 with model GLS in generation 1 of 2 with params {} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"RollingMeanTransformer\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"fixed\": true, \"window\": 3}, \"1\": {\"model\": \"Poisson\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 242 with model ARDL in generation 1 of 2 with params {\"lags\": 1, \"trend\": \"c\", \"order\": 0, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"STLFilter\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {\"decomp_type\": \"seasonal_decompose\", \"part\": \"trend\"}, \"1\": {}}}\n",
            "Model Number: 243 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"mean\", \"lag_1\": 2, \"lag_2\": 364} and transformations {\"fillna\": \"piecewise_polynomial\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/i2lqeqrx.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 244 with model FBProphet in generation 1 of 2 with params {\"holiday\": false, \"regression_type\": null, \"growth\": \"linear\", \"n_changepoints\": 25, \"changepoint_prior_scale\": 30, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.8, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/g3tg6cnr.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=84071', 'data', 'file=/tmp/tmpav2iq6so/i2lqeqrx.json', 'init=/tmp/tmpav2iq6so/g3tg6cnr.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modeloj6k0uwf/prophet_model-20230317053049.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:30:49 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:30:51 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 245 with model AverageValueNaive in generation 1 of 2 with params {\"method\": \"Median\", \"window\": 78} and transformations {\"fillna\": \"linear\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {}}}\n",
            "Model Number: 246 with model ARDL in generation 1 of 2 with params {\"lags\": 2, \"trend\": \"c\", \"order\": 1, \"causal\": false, \"regression_type\": \"common_fourier\"} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 247 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"mean\", \"lag_1\": 12, \"lag_2\": 7} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 248 with model UnobservedComponents in generation 1 of 2 with params {\"level\": false, \"maxiter\": 100, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": null, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"Slice\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"method\": 0.2}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 249 with model Theta in generation 1 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": false, \"method\": \"auto\", \"period\": null, \"theta\": 1.4, \"use_mle\": false} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 250 with model MetricMotif in generation 1 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"mae\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"RobustScaler\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {}}}\n",
            "Model Number: 251 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Discretize\"}, \"transformation_params\": {\"0\": {\"discretization\": \"center\", \"n_bins\": 10}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/vvwjpasm.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 252 with model FBProphet in generation 1 of 2 with params {\"holiday\": false, \"regression_type\": null, \"growth\": \"linear\", \"n_changepoints\": 25, \"changepoint_prior_scale\": 0.1, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.8, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AnomalyRemoval\", \"1\": \"Log\"}, \"transformation_params\": {\"0\": {\"method\": \"nonparametric\", \"method_params\": {\"p\": null, \"z_init\": 1.5, \"z_limit\": 10, \"z_step\": 0.25, \"inverse\": false, \"max_contamination\": 0.25, \"mean_weight\": 25, \"sd_weight\": 25, \"anomaly_count_weight\": 1.0}, \"fillna\": \"ffill\", \"transform_dict\": null}, \"1\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/9z300cbo.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=80772', 'data', 'file=/tmp/tmpav2iq6so/vvwjpasm.json', 'init=/tmp/tmpav2iq6so/9z300cbo.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modelfrunzn8y/prophet_model-20230317053053.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:30:53 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:30:55 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 253 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 28, \"point_method\": \"midhinge\", \"distance_metric\": \"cityblock\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"akima\", \"transformations\": {\"0\": \"CenterLastValue\", \"1\": \"STLFilter\"}, \"transformation_params\": {\"0\": {\"rows\": 1}, \"1\": {\"decomp_type\": \"seasonal_decompose\", \"part\": \"trend\"}}}\n",
            "Model Number: 254 with model DatepartRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"ExtraTrees\", \"model_params\": {\"n_estimators\": 100, \"min_samples_leaf\": 1, \"max_depth\": 20}}, \"datepart_method\": \"recurring\", \"polynomial_degree\": 2, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"RobustScaler\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3}}}}}}\n",
            "Model Number: 255 with model UnobservedComponents in generation 1 of 2 with params {\"level\": \"random trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 256 with model UnobservedComponents in generation 1 of 2 with params {\"level\": \"random trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 257 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 24, \"lag_2\": 7} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"lag_1\": 24, \"method\": \"Mean\"}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 258 with model UnivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}, \"holiday\": false, \"mean_rolling_periods\": 5, \"macd_periods\": 60, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 96, \"ewm_var_alpha\": null, \"ewm_alpha\": null, \"additional_lag_periods\": 63, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": null, \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": 3} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"wiener\", \"method_args\": null}}}\n",
            "Model Number: 259 with model Theta in generation 1 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 1.4, \"use_mle\": true} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"StandardScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 260 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 60, \"point_method\": \"median\", \"distance_metric\": \"canberra\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"EWMAFilter\", \"1\": \"PowerTransformer\"}, \"transformation_params\": {\"0\": {\"span\": 2}, \"1\": {}}}\n",
            "Model Number: 261 with model AverageValueNaive in generation 1 of 2 with params {\"method\": \"Weighted_Mean\", \"window\": null} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"model\": \"Gamma\", \"phi\": 0.999, \"window\": 10, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}}, \"1\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 0.9, \"first_value_only\": false}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 292, in fit_transform\n",
            "    self.fit(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 282, in fit\n",
            "    self.trained_model.fit(X, Y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/multioutput.py\", line 216, in fit\n",
            "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1048, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 782, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/multioutput.py\", line 49, in _fit_estimator\n",
            "    estimator.fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_glm/glm.py\", line 193, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 584, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 1124, in check_X_y\n",
            "    check_consistent_length(X, y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 397, in check_consistent_length\n",
            "    raise ValueError(\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [10, 2827]\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer Detrend failed on fit\n",
            " in model 261: AverageValueNaive\n",
            "Model Number: 262 with model UnivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 1.0}}, \"holiday\": false, \"mean_rolling_periods\": null, \"macd_periods\": 1440, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": null, \"ewm_var_alpha\": null, \"ewm_alpha\": null, \"additional_lag_periods\": 59, \"abs_energy\": true, \"rolling_autocorr_periods\": null, \"add_date_part\": \"simple_2\", \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": null} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 263 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 2, \"lag_2\": 1} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 264 with model MultivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 2}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 4, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 7, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n",
            "Model Number: 265 with model UnivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}, \"holiday\": false, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": 12, \"min_rolling_periods\": null, \"ewm_var_alpha\": 0.5, \"ewm_alpha\": 0.5, \"additional_lag_periods\": 2, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": null, \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"fixed\": true, \"window\": 3}}}\n",
            "Model Number: 266 with model UnobservedComponents in generation 1 of 2 with params {\"level\": \"random walk with drift\", \"maxiter\": 50, \"cov_type\": \"approx\", \"method\": \"nm\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}}}\n",
            "Model Number: 267 with model SectionalMotif in generation 1 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"MaxAbsScaler\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 268 with model SectionalMotif in generation 1 of 2 with params {\"window\": 7, \"point_method\": \"weighted_mean\", \"distance_metric\": \"canberra\", \"include_differenced\": false, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}}}\n",
            "Model Number: 269 with model MetricMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"mse\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"time\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 2, \"lag\": 7, \"method\": \"multiplicative\", \"strength\": 0.9, \"first_value_only\": false}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear stochastic seasonal 7\", \"state_transition\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \"observation_model\": [[1, 0, 1, 0, 0, 0, 0, 0]], \"observation_noise\": 0.25, \"em_iter\": null}}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Log\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 270 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"dice\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PowerTransformer\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 271 with model ARDL in generation 1 of 2 with params {\"lags\": 3, \"trend\": \"t\", \"order\": 2, \"causal\": false, \"regression_type\": \"simple\"} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": \"quarter\"}, \"1\": {}}}\n",
            "Model Number: 272 with model MultivariateMotif in generation 1 of 2 with params {\"window\": 7, \"point_method\": \"midhinge\", \"distance_metric\": \"jensenshannon\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Cointegration\"}, \"transformation_params\": {\"0\": {\"det_order\": -1, \"k_ar_diff\": 1}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2361, in fit_transform\n",
            "    return self.fit(df).transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2324, in fit\n",
            "    raise ValueError(\"Coint only works on multivarate series\")\n",
            "ValueError: Coint only works on multivarate series\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer Cointegration failed on fit\n",
            " in model 272: MultivariateMotif\n",
            "Model Number: 273 with model ARDL in generation 1 of 2 with params {\"lags\": 2, \"trend\": \"ct\", \"order\": 1, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Gamma\", \"phi\": 1, \"window\": 10, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"Discretize\"}, \"transformation_params\": {\"0\": {\"discretization\": \"center\", \"n_bins\": 20}}}}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 292, in fit_transform\n",
            "    self.fit(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 282, in fit\n",
            "    self.trained_model.fit(X, Y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/multioutput.py\", line 216, in fit\n",
            "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1048, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 782, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/multioutput.py\", line 49, in _fit_estimator\n",
            "    estimator.fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_glm/glm.py\", line 193, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 584, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 1124, in check_X_y\n",
            "    check_consistent_length(X, y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 397, in check_consistent_length\n",
            "    raise ValueError(\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [10, 2827]\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer Detrend failed on fit\n",
            " in model 273: ARDL\n",
            "Model Number: 274 with model ETS in generation 1 of 2 with params {\"damped_trend\": true, \"trend\": \"multiplicative\", \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PCA\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"whiten\": false}, \"1\": {\"lag_1\": 7, \"method\": \"LastValue\"}}}\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on 0 with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 275 with model ARDL in generation 1 of 2 with params {\"lags\": 4, \"trend\": \"c\", \"order\": 2, \"causal\": false, \"regression_type\": \"simple\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py:492: FutureWarning:\n",
            "\n",
            "the 'damped'' keyword is deprecated, use 'damped_trend' instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 276 with model UnivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"LinearRegression\", \"model_params\": {}}, \"holiday\": false, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": 12, \"min_rolling_periods\": null, \"ewm_var_alpha\": null, \"ewm_alpha\": 0.5, \"additional_lag_periods\": 2, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": null, \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"RollingMeanTransformer\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"fixed\": true, \"window\": 3}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 277 with model NVAR in generation 1 of 2 with params {\"k\": 3, \"ridge_param\": 0.002, \"warmup_pts\": 50, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"std_sorted\"} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 0.99, \"window\": null, \"transform_dict\": null}, \"1\": {\"fixed\": false, \"window\": 2}}}\n",
            "Model Number: 278 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 12, \"lag_2\": null} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 5, \"fillna\": null}, \"1\": {\"decimals\": 0, \"on_transform\": true, \"on_inverse\": false}}}\n",
            "Model Number: 279 with model ETS in generation 1 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"middle\", \"decimals\": 0, \"on_transform\": false, \"on_inverse\": true}}}\n",
            "Model Number: 280 with model ARDL in generation 1 of 2 with params {\"lags\": 2, \"trend\": \"ct\", \"order\": 3, \"causal\": false, \"regression_type\": \"simple_binarized\"} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 281 with model MultivariateMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"mahalanobis\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 282 with model ARDL in generation 1 of 2 with params {\"lags\": 1, \"trend\": \"c\", \"order\": 0, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"STLFilter\"}, \"transformation_params\": {\"0\": {\"decomp_type\": \"seasonal_decompose\", \"part\": \"trend\"}}}\n",
            "Model Number: 283 with model SectionalMotif in generation 1 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 3, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"normal\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 284 with model UnobservedComponents in generation 1 of 2 with params {\"level\": \"random trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 285 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 286 with model GLS in generation 1 of 2 with params {} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Poisson\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 287 with model FBProphet in generation 1 of 2 with params {\"holiday\": true, \"regression_type\": null, \"changepoint_prior_scale\": 30, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0, \"seasonality_mode\": \"multiplicative\", \"changepoint_range\": 0.8, \"growth\": \"linear\", \"n_changepoints\": 30} and transformations {\"fillna\": \"piecewise_polynomial\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/kysl4bgo.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/6umi9uxg.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=73708', 'data', 'file=/tmp/tmpav2iq6so/kysl4bgo.json', 'init=/tmp/tmpav2iq6so/6umi9uxg.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_model0sdyk6za/prophet_model-20230317053107.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:31:07 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:31:10 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 288 with model MultivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 90, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 289 with model GLS in generation 1 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"RobustScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 290 with model UnivariateRegression in generation 1 of 2 with params {\"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}, \"holiday\": false, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 364, \"ewm_var_alpha\": null, \"ewm_alpha\": 0.2, \"additional_lag_periods\": 12, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": \"expanded\", \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": null} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": 10, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 31, \"polyorder\": 3, \"deriv\": 0, \"mode\": \"interp\"}}}}}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=3.3661e-26): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 291 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 28, \"point_method\": \"weighted_mean\", \"distance_metric\": \"canberra\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 292 with model SeasonalNaive in generation 1 of 2 with params {\"method\": \"mean\", \"lag_1\": 24, \"lag_2\": 1} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Median\"}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 293 with model WindowRegression in generation 1 of 2 with params {\"window_size\": 10, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": false, \"max_windows\": 5000, \"regression_type\": \"User\", \"regression_model\": {\"model\": \"MLP\", \"model_params\": {\"hidden_layer_sizes\": [100], \"max_iter\": 250, \"activation\": \"tanh\", \"solver\": \"adam\", \"early_stopping\": false, \"learning_rate_init\": 0.001}}} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1440, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor passed\n",
            " in model 293: WindowRegression\n",
            "Model Number: 294 with model Theta in generation 1 of 2 with params {\"deseasonalize\": false, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 3, \"use_mle\": false} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {\"model\": \"Poisson\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"decimals\": 1, \"on_transform\": false, \"on_inverse\": true}}}\n",
            "Model Number: 295 with model SectionalMotif in generation 1 of 2 with params {\"window\": 15, \"point_method\": \"mean\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 1, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 296 with model AverageValueNaive in generation 1 of 2 with params {\"method\": \"Mean\", \"window\": null} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"MaxAbsScaler\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 297 with model MetricMotif in generation 1 of 2 with params {\"window\": 5, \"point_method\": \"median\", \"distance_metric\": \"mqae\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 31, \"polyorder\": 1, \"deriv\": 0, \"mode\": \"nearest\"}}}}, \"combination_transformation\": {\"fillna\": \"nearest\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"DatepartRegression\", \"1\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": 9, \"min_samples_split\": 1.0}}, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Model Number: 298 with model MetricMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"weighted_mean\", \"distance_metric\": \"mse\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear stochastic seasonal 7\", \"state_transition\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \"observation_model\": [[1, 0, 1, 0, 0, 0, 0, 0]], \"observation_noise\": 0.25, \"em_iter\": null}}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}}}\n",
            "Model Number: 299 with model ETS in generation 1 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": 7} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 300 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 60, \"point_method\": \"median\", \"distance_metric\": \"canberra\", \"k\": 5, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PowerTransformer\", \"1\": \"PowerTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 301 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"bkfilter\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 302 with model MetricMotif in generation 1 of 2 with params {\"window\": 5, \"point_method\": \"weighted_mean\", \"distance_metric\": \"mae\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"X1\", \"state_transition\": [[1, 1, 0], [0, 1, 0], [0, 0, 1]], \"process_noise\": [[0.1, 0.0, 0.0], [0.0, 0.01, 0.0], [0.0, 0.0, 0.1]], \"observation_model\": [[1, 1, 1]], \"observation_noise\": 1.0, \"em_iter\": null}}}, \"combination_transformation\": {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"fixed\": true, \"window\": 3}}}\n",
            "Model Number: 303 with model LastValueNaive in generation 1 of 2 with params {} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 304 with model ARDL in generation 1 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 1, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 305 with model ETS in generation 1 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": 7} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"model\": \"Tweedie\", \"phi\": 1, \"window\": 10, \"transform_dict\": null}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 292, in fit_transform\n",
            "    self.fit(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 282, in fit\n",
            "    self.trained_model.fit(X, Y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/multioutput.py\", line 216, in fit\n",
            "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1048, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 782, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/multioutput.py\", line 49, in _fit_estimator\n",
            "    estimator.fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_glm/glm.py\", line 193, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 584, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 1124, in check_X_y\n",
            "    check_consistent_length(X, y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 397, in check_consistent_length\n",
            "    raise ValueError(\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [10, 2728]\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer Detrend failed on fit\n",
            " in model 305: ETS\n",
            "Model Number: 306 with model MetricMotif in generation 1 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"mae\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"median\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 7, \"method\": \"additive\", \"strength\": 0.5, \"first_value_only\": false}}}, \"combination_transformation\": {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}}}} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 307 with model ARDL in generation 1 of 2 with params {\"lags\": 3, \"trend\": \"t\", \"order\": 2, \"causal\": false, \"regression_type\": \"simple\"} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": \"quarter\"}}}\n",
            "Model Number: 308 with model UnivariateMotif in generation 1 of 2 with params {\"window\": 14, \"point_method\": \"median\", \"distance_metric\": \"canberra\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"remove\", \"std_threshold\": 1, \"fillna\": \"mean\"}}}\n",
            "Model Number: 309 with model NVAR in generation 1 of 2 with params {\"k\": 1, \"ridge_param\": 2e-07, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 310 with model WindowRegression in generation 1 of 2 with params {\"window_size\": 28, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": false, \"max_windows\": 5000, \"regression_type\": null, \"regression_model\": {\"base_score\": 0.5, \"booster\": \"gbtree\", \"colsample_bylevel\": 0.541426, \"colsample_bynode\": 1, \"colsample_bytree\": 1.0, \"early_stopping_rounds\": null, \"enable_categorical\": false, \"eval_metric\": null, \"feature_types\": null, \"gamma\": 0, \"grow_policy\": \"depthwise\", \"importance_type\": null, \"interaction_constraints\": \"\", \"learning_rate\": 0.012543, \"max_bin\": 256, \"max_cat_threshold\": 64, \"max_cat_to_onehot\": 4, \"max_delta_step\": 0, \"max_depth\": 11, \"max_leaves\": 0, \"min_child_weight\": 0.0127203, \"monotone_constraints\": \"()\", \"n_estimators\": 319, \"num_parallel_tree\": 1, \"predictor\": \"auto\"}} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1464, in fit\n",
            "    self.regr = retrieve_regressor(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 218, in retrieve_regressor\n",
            "    model_class = regression_model['model']\n",
            "KeyError: 'model'\n",
            " in model 310: WindowRegression\n",
            "Model Number: 311 with model NVAR in generation 1 of 2 with params {\"k\": 2, \"ridge_param\": 0.002, \"warmup_pts\": 50, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"MaxAbsScaler\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"fixed\": false, \"window\": 2}}}\n",
            "New Generation: 2 of 2\n",
            "Model Number: 312 with model UnobservedComponents in generation 2 of 2 with params {\"level\": \"random trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 7, \"lag\": 1, \"method\": \"additive\", \"strength\": 0.2, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 313 with model LastValueNaive in generation 2 of 2 with params {} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"PositiveShift\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 314 with model UnobservedComponents in generation 2 of 2 with params {\"level\": \"random trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Mean\"}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 315 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"minkowski\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"RobustScaler\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Model Number: 316 with model ARIMA in generation 2 of 2 with params {\"p\": 0, \"d\": 1, \"q\": 12, \"regression_type\": null} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"Log\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 317 with model MetricMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"mqae\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"linear\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear hidden state with seasonal 7\", \"state_transition\": [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[0.0016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], \"observation_model\": [[1, 1, 0, 0, 0, 0, 0, 0]], \"observation_noise\": 0.04, \"em_iter\": null}}}, \"combination_transformation\": {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"BTCD\"}, \"transformation_params\": {\"0\": {\"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}, \"max_lags\": 2}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2442, in fit_transform\n",
            "    return self.fit(df).transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2396, in fit\n",
            "    raise ValueError(\"BTCD only works on multivarate series\")\n",
            "ValueError: BTCD only works on multivarate series\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer BTCD failed on fit\n",
            " in model 317: MetricMotif\n",
            "Model Number: 318 with model ETS in generation 2 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": null} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"MeanDifference\", \"1\": \"StandardScaler\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 319 with model ConstantNaive in generation 2 of 2 with params {\"constant\": 0} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 0.9, \"first_value_only\": false}}}\n",
            "Model Number: 320 with model SeasonalNaive in generation 2 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 2, \"lag_2\": 1} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"BTCD\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {\"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}, \"max_lags\": 1}, \"1\": {\"model\": \"middle\", \"decimals\": 2, \"on_transform\": false, \"on_inverse\": true}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2442, in fit_transform\n",
            "    return self.fit(df).transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2396, in fit\n",
            "    raise ValueError(\"BTCD only works on multivarate series\")\n",
            "ValueError: BTCD only works on multivarate series\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer BTCD failed on fit\n",
            " in model 320: SeasonalNaive\n",
            "Model Number: 321 with model LastValueNaive in generation 2 of 2 with params {} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"PositiveShift\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {}}}\n",
            "Model Number: 322 with model NVAR in generation 2 of 2 with params {\"k\": 1, \"ridge_param\": 0.002, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"fixed\": false, \"window\": 2}}}\n",
            "Model Number: 323 with model ARDL in generation 2 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 0, \"causal\": true, \"regression_type\": \"simple_binarized\"} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"CenterLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 4}, \"1\": {\"lag_1\": 4, \"method\": \"Median\"}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 2129, in ardl_per_column\n",
            "    maModel = ARDL(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/ardl/model.py\", line 368, in __init__\n",
            "    self._order = self._check_order(order)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/ardl/model.py\", line 445, in _check_order\n",
            "    return _format_order(self.data.orig_exog, order, self._causal)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/ardl/model.py\", line 163, in _format_order\n",
            "    _check_order(order, causal)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/ardl/model.py\", line 106, in _check_order\n",
            "    raise ValueError(\n",
            "ValueError: integer orders must be at least 1 when causal is True.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 2215, in predict\n",
            "    df_list.append(ardl_per_column(self.df_train[col], args))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 2162, in ardl_per_column\n",
            "    raise ValueError(\n",
            "ValueError: ARDL series Close failed with error ValueError('integer orders must be at least 1 when causal is True.') exog train             day  weekend      epoch  month_1  month_2  month_3  month_4  \\\n",
            "Date                                                                      \n",
            "2009-07-08    8        0  2455020.5        0        0        0        0   \n",
            "2009-07-09    9        0  2455021.5        0        0        0        0   \n",
            "2009-07-10   10        0  2455022.5        0        0        0        0   \n",
            "2009-07-13   13        0  2455025.5        0        0        0        0   \n",
            "2009-07-14   14        0  2455026.5        0        0        0        0   \n",
            "...         ...      ...        ...      ...      ...      ...      ...   \n",
            "2020-05-01    1        0  2458970.5        0        0        0        0   \n",
            "2020-05-04    4        0  2458973.5        0        0        0        0   \n",
            "2020-05-05    5        0  2458974.5        0        0        0        0   \n",
            "2020-05-06    6        0  2458975.5        0        0        0        0   \n",
            "2020-05-07    7        0  2458976.5        0        0        0        0   \n",
            "\n",
            "            month_5  month_6  month_7  ...  month_10  month_11  month_12  \\\n",
            "Date                                   ...                                 \n",
            "2009-07-08        0        0        1  ...         0         0         0   \n",
            "2009-07-09        0        0        1  ...         0         0         0   \n",
            "2009-07-10        0        0        1  ...         0         0         0   \n",
            "2009-07-13        0        0        1  ...         0         0         0   \n",
            "2009-07-14        0        0        1  ...         0         0         0   \n",
            "...             ...      ...      ...  ...       ...       ...       ...   \n",
            "2020-05-01        1        0        0  ...         0         0         0   \n",
            "2020-05-04        1        0        0  ...         0         0         0   \n",
            "2020-05-05        1        0        0  ...         0         0         0   \n",
            "2020-05-06        1        0        0  ...         0         0         0   \n",
            "2020-05-07        1        0        0  ...         0         0         0   \n",
            "\n",
            "            weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\n",
            "Date                                                                           \n",
            "2009-07-08          0          0          1          0          0          0   \n",
            "2009-07-09          0          0          0          1          0          0   \n",
            "2009-07-10          0          0          0          0          1          0   \n",
            "2009-07-13          1          0          0          0          0          0   \n",
            "2009-07-14          0          1          0          0          0          0   \n",
            "...               ...        ...        ...        ...        ...        ...   \n",
            "2020-05-01          0          0          0          0          1          0   \n",
            "2020-05-04          1          0          0          0          0          0   \n",
            "2020-05-05          0          1          0          0          0          0   \n",
            "2020-05-06          0          0          1          0          0          0   \n",
            "2020-05-07          0          0          0          1          0          0   \n",
            "\n",
            "            weekday_6  \n",
            "Date                   \n",
            "2009-07-08          0  \n",
            "2009-07-09          0  \n",
            "2009-07-10          0  \n",
            "2009-07-13          0  \n",
            "2009-07-14          0  \n",
            "...               ...  \n",
            "2020-05-01          0  \n",
            "2020-05-04          0  \n",
            "2020-05-05          0  \n",
            "2020-05-06          0  \n",
            "2020-05-07          0  \n",
            "\n",
            "[2827 rows x 22 columns] and predict             day  weekend      epoch  month_1  month_2  month_3  month_4  \\\n",
            "2020-05-08    8        0  2458977.5        0        0        0        0   \n",
            "2020-05-11   11        0  2458980.5        0        0        0        0   \n",
            "2020-05-12   12        0  2458981.5        0        0        0        0   \n",
            "2020-05-13   13        0  2458982.5        0        0        0        0   \n",
            "2020-05-14   14        0  2458983.5        0        0        0        0   \n",
            "2020-05-15   15        0  2458984.5        0        0        0        0   \n",
            "2020-05-18   18        0  2458987.5        0        0        0        0   \n",
            "2020-05-19   19        0  2458988.5        0        0        0        0   \n",
            "2020-05-20   20        0  2458989.5        0        0        0        0   \n",
            "2020-05-21   21        0  2458990.5        0        0        0        0   \n",
            "2020-05-22   22        0  2458991.5        0        0        0        0   \n",
            "2020-05-25   25        0  2458994.5        0        0        0        0   \n",
            "2020-05-26   26        0  2458995.5        0        0        0        0   \n",
            "2020-05-27   27        0  2458996.5        0        0        0        0   \n",
            "2020-05-28   28        0  2458997.5        0        0        0        0   \n",
            "2020-05-29   29        0  2458998.5        0        0        0        0   \n",
            "2020-06-01    1        0  2459001.5        0        0        0        0   \n",
            "2020-06-02    2        0  2459002.5        0        0        0        0   \n",
            "2020-06-03    3        0  2459003.5        0        0        0        0   \n",
            "2020-06-04    4        0  2459004.5        0        0        0        0   \n",
            "2020-06-05    5        0  2459005.5        0        0        0        0   \n",
            "2020-06-08    8        0  2459008.5        0        0        0        0   \n",
            "2020-06-09    9        0  2459009.5        0        0        0        0   \n",
            "2020-06-10   10        0  2459010.5        0        0        0        0   \n",
            "2020-06-11   11        0  2459011.5        0        0        0        0   \n",
            "2020-06-12   12        0  2459012.5        0        0        0        0   \n",
            "2020-06-15   15        0  2459015.5        0        0        0        0   \n",
            "2020-06-16   16        0  2459016.5        0        0        0        0   \n",
            "2020-06-17   17        0  2459017.5        0        0        0        0   \n",
            "2020-06-18   18        0  2459018.5        0        0        0        0   \n",
            "\n",
            "            month_5  month_6  month_7  ...  month_10  month_11  month_12  \\\n",
            "2020-05-08        1        0        0  ...         0         0         0   \n",
            "2020-05-11        1        0        0  ...         0         0         0   \n",
            "2020-05-12        1        0        0  ...         0         0         0   \n",
            "2020-05-13        1        0        0  ...         0         0         0   \n",
            "2020-05-14        1        0        0  ...         0         0         0   \n",
            "2020-05-15        1        0        0  ...         0         0         0   \n",
            "2020-05-18        1        0        0  ...         0         0         0   \n",
            "2020-05-19        1        0        0  ...         0         0         0   \n",
            "2020-05-20        1        0        0  ...         0         0         0   \n",
            "2020-05-21        1        0        0  ...         0         0         0   \n",
            "2020-05-22        1        0        0  ...         0         0         0   \n",
            "2020-05-25        1        0        0  ...         0         0         0   \n",
            "2020-05-26        1        0        0  ...         0         0         0   \n",
            "2020-05-27        1        0        0  ...         0         0         0   \n",
            "2020-05-28        1        0        0  ...         0         0         0   \n",
            "2020-05-29        1        0        0  ...         0         0         0   \n",
            "2020-06-01        0        1        0  ...         0         0         0   \n",
            "2020-06-02        0        1        0  ...         0         0         0   \n",
            "2020-06-03        0        1        0  ...         0         0         0   \n",
            "2020-06-04        0        1        0  ...         0         0         0   \n",
            "2020-06-05        0        1        0  ...         0         0         0   \n",
            "2020-06-08        0        1        0  ...         0         0         0   \n",
            "2020-06-09        0        1        0  ...         0         0         0   \n",
            "2020-06-10        0        1        0  ...         0         0         0   \n",
            "2020-06-11        0        1        0  ...         0         0         0   \n",
            "2020-06-12        0        1        0  ...         0         0         0   \n",
            "2020-06-15        0        1        0  ...         0         0         0   \n",
            "2020-06-16        0        1        0  ...         0         0         0   \n",
            "2020-06-17        0        1        0  ...         0         0         0   \n",
            "2020-06-18        0        1        0  ...         0         0         0   \n",
            "\n",
            "            weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\n",
            "2020-05-08          0          0          0          0          1          0   \n",
            "2020-05-11          1          0          0          0          0          0   \n",
            "2020-05-12          0          1          0          0          0          0   \n",
            "2020-05-13          0          0          1          0          0          0   \n",
            "2020-05-14          0          0          0          1          0          0   \n",
            "2020-05-15          0          0          0          0          1          0   \n",
            "2020-05-18          1          0          0          0          0          0   \n",
            "2020-05-19          0          1          0          0          0          0   \n",
            "2020-05-20          0          0          1          0          0          0   \n",
            "2020-05-21          0          0          0          1          0          0   \n",
            "2020-05-22          0          0          0          0          1          0   \n",
            "2020-05-25          1          0          0          0          0          0   \n",
            "2020-05-26          0          1          0          0          0          0   \n",
            "2020-05-27          0          0          1          0          0          0   \n",
            "2020-05-28          0          0          0          1          0          0   \n",
            "2020-05-29          0          0          0          0          1          0   \n",
            "2020-06-01          1          0          0          0          0          0   \n",
            "2020-06-02          0          1          0          0          0          0   \n",
            "2020-06-03          0          0          1          0          0          0   \n",
            "2020-06-04          0          0          0          1          0          0   \n",
            "2020-06-05          0          0          0          0          1          0   \n",
            "2020-06-08          1          0          0          0          0          0   \n",
            "2020-06-09          0          1          0          0          0          0   \n",
            "2020-06-10          0          0          1          0          0          0   \n",
            "2020-06-11          0          0          0          1          0          0   \n",
            "2020-06-12          0          0          0          0          1          0   \n",
            "2020-06-15          1          0          0          0          0          0   \n",
            "2020-06-16          0          1          0          0          0          0   \n",
            "2020-06-17          0          0          1          0          0          0   \n",
            "2020-06-18          0          0          0          1          0          0   \n",
            "\n",
            "            weekday_6  \n",
            "2020-05-08          0  \n",
            "2020-05-11          0  \n",
            "2020-05-12          0  \n",
            "2020-05-13          0  \n",
            "2020-05-14          0  \n",
            "2020-05-15          0  \n",
            "2020-05-18          0  \n",
            "2020-05-19          0  \n",
            "2020-05-20          0  \n",
            "2020-05-21          0  \n",
            "2020-05-22          0  \n",
            "2020-05-25          0  \n",
            "2020-05-26          0  \n",
            "2020-05-27          0  \n",
            "2020-05-28          0  \n",
            "2020-05-29          0  \n",
            "2020-06-01          0  \n",
            "2020-06-02          0  \n",
            "2020-06-03          0  \n",
            "2020-06-04          0  \n",
            "2020-06-05          0  \n",
            "2020-06-08          0  \n",
            "2020-06-09          0  \n",
            "2020-06-10          0  \n",
            "2020-06-11          0  \n",
            "2020-06-12          0  \n",
            "2020-06-15          0  \n",
            "2020-06-16          0  \n",
            "2020-06-17          0  \n",
            "2020-06-18          0  \n",
            "\n",
            "[30 rows x 22 columns]\n",
            " in model 323: ARDL\n",
            "Model Number: 324 with model DatepartRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"Adaboost\", \"model_params\": {\"n_estimators\": 50, \"loss\": \"linear\", \"base_estimator\": \"SVR\", \"learning_rate\": 0.5}}, \"datepart_method\": \"expanded\", \"polynomial_degree\": null, \"regression_type\": \"User\"} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1930, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor passed\n",
            " in model 324: DatepartRegression\n",
            "Model Number: 325 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 12, \"macd_periods\": 94, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 90, \"ewm_alpha\": 0.1, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": null, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 326 with model SectionalMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 3, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"Cointegration\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"det_order\": 1, \"k_ar_diff\": 1}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2361, in fit_transform\n",
            "    return self.fit(df).transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2324, in fit\n",
            "    raise ValueError(\"Coint only works on multivarate series\")\n",
            "ValueError: Coint only works on multivarate series\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer Cointegration failed on fit\n",
            " in model 326: SectionalMotif\n",
            "Model Number: 327 with model SectionalMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": false, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 0.9, \"first_value_only\": false}}}\n",
            "Model Number: 328 with model SectionalMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 329 with model MetricMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"mae\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"X1\", \"state_transition\": [[1, 1, 0], [0, 1, 0], [0, 0, 1]], \"process_noise\": [[0.1, 0.0, 0.0], [0.0, 0.01, 0.0], [0.0, 0.0, 0.1]], \"observation_model\": [[1, 1, 1]], \"observation_noise\": 1.0, \"em_iter\": null}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear stochastic seasonal 7\", \"state_transition\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \"observation_model\": [[1, 0, 1, 0, 0, 0, 0, 0]], \"observation_noise\": 0.25, \"em_iter\": null}}}} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 330 with model DatepartRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"ExtraTrees\", \"model_params\": {\"n_estimators\": 100, \"min_samples_leaf\": 1, \"max_depth\": 20}}, \"datepart_method\": \"recurring\", \"polynomial_degree\": 2, \"regression_type\": null} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": true}, \"1\": {}}}\n",
            "Model Number: 331 with model LastValueNaive in generation 2 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 4, \"fillna\": null}}}\n",
            "Model Number: 332 with model Theta in generation 2 of 2 with params {\"deseasonalize\": true, \"difference\": true, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 2.5, \"use_mle\": false} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 333 with model WindowRegression in generation 2 of 2 with params {\"window_size\": 5, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": false, \"max_windows\": 1000, \"regression_type\": \"User\", \"regression_model\": {\"model\": \"BayesianRidge\", \"model_params\": {}}} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"FastICA\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"algorithm\": \"deflation\", \"fun\": \"exp\", \"max_iter\": 250, \"whiten\": true}, \"1\": {\"rows\": 7, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1440, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor passed\n",
            " in model 333: WindowRegression\n",
            "Model Number: 334 with model SeasonalNaive in generation 2 of 2 with params {\"method\": \"median\", \"lag_1\": 2, \"lag_2\": 1} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 335 with model ARDL in generation 2 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 1, \"causal\": true, \"regression_type\": \"simple_binarized\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"transform_dict\": null}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning:\n",
            "\n",
            "Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 336 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"cityblock\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 337 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 200, \"min_samples_leaf\": 1, \"bootstrap\": true}}, \"mean_rolling_periods\": 12, \"macd_periods\": 94, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 7, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 30, \"ewm_alpha\": 0.5, \"ewm_var_alpha\": 0.2, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": null, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"PCA\"}, \"transformation_params\": {\"0\": {\"lag_1\": 12, \"method\": \"Mean\"}, \"1\": {\"whiten\": false}}}\n",
            "building tree 1 of 200\n",
            "building tree 2 of 200\n",
            "building tree 3 of 200\n",
            "building tree 4 of 200\n",
            "building tree 5 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 6 of 200\n",
            "building tree 7 of 200\n",
            "building tree 8 of 200\n",
            "building tree 9 of 200\n",
            "building tree 10 of 200\n",
            "building tree 11 of 200\n",
            "building tree 12 of 200\n",
            "building tree 13 of 200\n",
            "building tree 14 of 200\n",
            "building tree 15 of 200\n",
            "building tree 16 of 200\n",
            "building tree 17 of 200\n",
            "building tree 18 of 200\n",
            "building tree 19 of 200\n",
            "building tree 20 of 200\n",
            "building tree 21 of 200\n",
            "building tree 22 of 200\n",
            "building tree 23 of 200\n",
            "building tree 24 of 200\n",
            "building tree 25 of 200\n",
            "building tree 26 of 200\n",
            "building tree 27 of 200\n",
            "building tree 28 of 200\n",
            "building tree 29 of 200\n",
            "building tree 30 of 200\n",
            "building tree 31 of 200\n",
            "building tree 32 of 200\n",
            "building tree 33 of 200\n",
            "building tree 34 of 200\n",
            "building tree 35 of 200\n",
            "building tree 36 of 200\n",
            "building tree 37 of 200\n",
            "building tree 38 of 200\n",
            "building tree 39 of 200\n",
            "building tree 40 of 200\n",
            "building tree 41 of 200\n",
            "building tree 42 of 200\n",
            "building tree 43 of 200\n",
            "building tree 44 of 200\n",
            "building tree 45 of 200\n",
            "building tree 46 of 200\n",
            "building tree 47 of 200\n",
            "building tree 48 of 200\n",
            "building tree 49 of 200\n",
            "building tree 50 of 200\n",
            "building tree 51 of 200\n",
            "building tree 52 of 200\n",
            "building tree 53 of 200\n",
            "building tree 54 of 200\n",
            "building tree 55 of 200\n",
            "building tree 56 of 200\n",
            "building tree 57 of 200\n",
            "building tree 58 of 200\n",
            "building tree 59 of 200\n",
            "building tree 60 of 200\n",
            "building tree 61 of 200\n",
            "building tree 62 of 200\n",
            "building tree 63 of 200\n",
            "building tree 64 of 200\n",
            "building tree 65 of 200\n",
            "building tree 66 of 200\n",
            "building tree 67 of 200\n",
            "building tree 68 of 200\n",
            "building tree 69 of 200\n",
            "building tree 70 of 200\n",
            "building tree 71 of 200\n",
            "building tree 72 of 200\n",
            "building tree 73 of 200\n",
            "building tree 74 of 200\n",
            "building tree 75 of 200\n",
            "building tree 76 of 200\n",
            "building tree 77 of 200\n",
            "building tree 78 of 200\n",
            "building tree 79 of 200\n",
            "building tree 80 of 200\n",
            "building tree 81 of 200\n",
            "building tree 82 of 200\n",
            "building tree 83 of 200\n",
            "building tree 84 of 200\n",
            "building tree 85 of 200\n",
            "building tree 86 of 200\n",
            "building tree 87 of 200\n",
            "building tree 88 of 200\n",
            "building tree 89 of 200\n",
            "building tree 90 of 200\n",
            "building tree 91 of 200\n",
            "building tree 92 of 200\n",
            "building tree 93 of 200\n",
            "building tree 94 of 200\n",
            "building tree 95 of 200\n",
            "building tree 96 of 200\n",
            "building tree 97 of 200\n",
            "building tree 98 of 200\n",
            "building tree 99 of 200\n",
            "building tree 100 of 200\n",
            "building tree 101 of 200\n",
            "building tree 102 of 200\n",
            "building tree 103 of 200\n",
            "building tree 104 of 200\n",
            "building tree 105 of 200\n",
            "building tree 106 of 200\n",
            "building tree 107 of 200\n",
            "building tree 108 of 200\n",
            "building tree 109 of 200\n",
            "building tree 110 of 200\n",
            "building tree 111 of 200\n",
            "building tree 112 of 200\n",
            "building tree 113 of 200\n",
            "building tree 114 of 200\n",
            "building tree 115 of 200\n",
            "building tree 116 of 200\n",
            "building tree 117 of 200\n",
            "building tree 118 of 200\n",
            "building tree 119 of 200\n",
            "building tree 120 of 200\n",
            "building tree 121 of 200\n",
            "building tree 122 of 200\n",
            "building tree 123 of 200\n",
            "building tree 124 of 200\n",
            "building tree 125 of 200\n",
            "building tree 126 of 200\n",
            "building tree 127 of 200\n",
            "building tree 128 of 200\n",
            "building tree 129 of 200\n",
            "building tree 130 of 200\n",
            "building tree 131 of 200\n",
            "building tree 132 of 200\n",
            "building tree 133 of 200\n",
            "building tree 134 of 200\n",
            "building tree 135 of 200\n",
            "building tree 136 of 200\n",
            "building tree 137 of 200\n",
            "building tree 138 of 200\n",
            "building tree 139 of 200\n",
            "building tree 140 of 200\n",
            "building tree 141 of 200\n",
            "building tree 142 of 200\n",
            "building tree 143 of 200\n",
            "building tree 144 of 200\n",
            "building tree 145 of 200\n",
            "building tree 146 of 200\n",
            "building tree 147 of 200\n",
            "building tree 148 of 200\n",
            "building tree 149 of 200\n",
            "building tree 150 of 200\n",
            "building tree 151 of 200\n",
            "building tree 152 of 200\n",
            "building tree 153 of 200\n",
            "building tree 154 of 200\n",
            "building tree 155 of 200\n",
            "building tree 156 of 200\n",
            "building tree 157 of 200\n",
            "building tree 158 of 200\n",
            "building tree 159 of 200\n",
            "building tree 160 of 200\n",
            "building tree 161 of 200\n",
            "building tree 162 of 200\n",
            "building tree 163 of 200\n",
            "building tree 164 of 200\n",
            "building tree 165 of 200\n",
            "building tree 166 of 200\n",
            "building tree 167 of 200\n",
            "building tree 168 of 200\n",
            "building tree 169 of 200\n",
            "building tree 170 of 200\n",
            "building tree 171 of 200\n",
            "building tree 172 of 200\n",
            "building tree 173 of 200\n",
            "building tree 174 of 200\n",
            "building tree 175 of 200\n",
            "building tree 176 of 200\n",
            "building tree 177 of 200\n",
            "building tree 178 of 200\n",
            "building tree 179 of 200\n",
            "building tree 180 of 200\n",
            "building tree 181 of 200\n",
            "building tree 182 of 200\n",
            "building tree 183 of 200\n",
            "building tree 184 of 200\n",
            "building tree 185 of 200\n",
            "building tree 186 of 200\n",
            "building tree 187 of 200\n",
            "building tree 188 of 200\n",
            "building tree 189 of 200\n",
            "building tree 190 of 200\n",
            "building tree 191 of 200\n",
            "building tree 192 of 200\n",
            "building tree 193 of 200\n",
            "building tree 194 of 200\n",
            "building tree 195 of 200\n",
            "building tree 196 of 200\n",
            "building tree 197 of 200\n",
            "building tree 198 of 200\n",
            "building tree 199 of 200\n",
            "building tree 200 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    3.7s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 338 with model LastValueNaive in generation 2 of 2 with params {} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"bkfilter\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Model Number: 339 with model UnobservedComponents in generation 2 of 2 with params {\"level\": \"local linear trend\", \"maxiter\": 250, \"cov_type\": \"opg\", \"method\": \"newton\", \"autoregressive\": 1, \"regression_type\": \"User\"} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"PositiveShift\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 917, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor supplied\n",
            " in model 339: UnobservedComponents\n",
            "Model Number: 340 with model NVAR in generation 2 of 2 with params {\"k\": 1, \"ridge_param\": 0.002, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 341 with model AverageValueNaive in generation 2 of 2 with params {\"method\": \"Median\", \"window\": 44} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 342 with model UnobservedComponents in generation 2 of 2 with params {\"level\": \"random walk with drift\", \"maxiter\": 50, \"cov_type\": \"approx\", \"method\": \"nm\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"EWMAFilter\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"span\": 12}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 343 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 90, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"nearest\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 344 with model UnivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}, \"holiday\": false, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": 12, \"min_rolling_periods\": null, \"ewm_var_alpha\": 0.5, \"ewm_alpha\": 0.5, \"additional_lag_periods\": 2, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": null, \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 345 with model MetricMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"mean\", \"distance_metric\": \"mqae\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"cubic\", \"transformations\": {\"0\": null}, \"transformation_params\": {\"0\": {}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear stochastic seasonal 7\", \"state_transition\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \"observation_model\": [[1, 0, 1, 0, 0, 0, 0, 0]], \"observation_noise\": 0.25, \"em_iter\": null}}}} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 346 with model ETS in generation 2 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 347 with model MetricMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"weighted_mean\", \"distance_metric\": \"mae\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"time\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 2, \"lag\": 7, \"method\": \"multiplicative\", \"strength\": 0.9, \"first_value_only\": false}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear stochastic seasonal 7\", \"state_transition\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \"observation_model\": [[1, 0, 1, 0, 0, 0, 0, 0]], \"observation_noise\": 0.25, \"em_iter\": null}}}} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 348 with model MetricMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"weighted_mean\", \"distance_metric\": \"mae\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"X1\", \"state_transition\": [[1, 1, 0], [0, 1, 0], [0, 0, 1]], \"process_noise\": [[0.1, 0.0, 0.0], [0.0, 0.01, 0.0], [0.0, 0.0, 0.1]], \"observation_model\": [[1, 1, 1]], \"observation_noise\": 1.0, \"em_iter\": null}}}, \"combination_transformation\": {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Log\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 349 with model NVAR in generation 2 of 2 with params {\"k\": 3, \"ridge_param\": 2e-06, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 350 with model ETS in generation 2 of 2 with params {\"damped_trend\": true, \"trend\": \"multiplicative\", \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 29, \"method\": \"Median\"}}}\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 351 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"Ridge\", \"model_params\": {\"alpha\": 1.0}}, \"mean_rolling_periods\": 30, \"macd_periods\": 24, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": null, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 90, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": false, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py:492: FutureWarning:\n",
            "\n",
            "the 'damped'' keyword is deprecated, use 'damped_trend' instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 352 with model AverageValueNaive in generation 2 of 2 with params {\"method\": \"Mean\", \"window\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"SeasonalDifference\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {\"lag_1\": 364, \"method\": \"LastValue\"}, \"1\": {}}}\n",
            "Model Number: 353 with model Theta in generation 2 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 3, \"use_mle\": false} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 354 with model ETS in generation 2 of 2 with params {\"damped_trend\": true, \"trend\": null, \"seasonal\": \"multiplicative\", \"seasonal_periods\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"Round\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"model\": \"middle\", \"decimals\": 0, \"on_transform\": false, \"on_inverse\": true}}}\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 355 with model FBProphet in generation 2 of 2 with params {\"holiday\": {\"threshold\": 0.8, \"splash_threshold\": null, \"use_dayofmonth_holidays\": true, \"use_wkdom_holidays\": true, \"use_wkdeom_holidays\": true, \"use_lunar_holidays\": false, \"use_lunar_weekday\": false, \"use_islamic_holidays\": false, \"use_hebrew_holidays\": false, \"anomaly_detector_params\": {\"method\": \"rolling_zscore\", \"transform_dict\": null, \"forecast_params\": null, \"method_params\": {\"distribution\": \"norm\", \"alpha\": 0.05, \"rolling_periods\": 200, \"center\": true}}}, \"regression_type\": null, \"changepoint_prior_scale\": 0.1, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0, \"seasonality_mode\": \"multiplicative\", \"changepoint_range\": 0.8, \"growth\": \"linear\", \"n_changepoints\": 20} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py:492: FutureWarning:\n",
            "\n",
            "the 'damped'' keyword is deprecated, use 'damped_trend' instead.\n",
            "\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/3juciepi.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/k0d_n8ie.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=71381', 'data', 'file=/tmp/tmpav2iq6so/3juciepi.json', 'init=/tmp/tmpav2iq6so/k0d_n8ie.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_model13rd9ikj/prophet_model-20230317053145.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:31:45 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:31:48 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 356 with model Theta in generation 2 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 3, \"use_mle\": false} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 357 with model ARDL in generation 2 of 2 with params {\"lags\": 3, \"trend\": \"c\", \"order\": 1, \"causal\": true, \"regression_type\": \"simple_binarized\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 358 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 2}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 4, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 7, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 359 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 7, \"point_method\": \"midhinge\", \"distance_metric\": \"cityblock\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"span\": 12}}}\n",
            "Model Number: 360 with model SectionalMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"weighted_mean\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 0.9, \"first_value_only\": false}}}\n",
            "Model Number: 361 with model MetricMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"mse\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"time\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 2, \"lag\": 7, \"method\": \"multiplicative\", \"strength\": 0.9, \"first_value_only\": false}}}, \"combination_transformation\": {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"fixed\": true, \"window\": 3}}}\n",
            "Model Number: 362 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 7, \"point_method\": \"midhinge\", \"distance_metric\": \"correlation\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 363 with model SectionalMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"normal\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 364 with model FBProphet in generation 2 of 2 with params {\"holiday\": {\"threshold\": 0.8, \"splash_threshold\": null, \"use_dayofmonth_holidays\": true, \"use_wkdom_holidays\": true, \"use_wkdeom_holidays\": true, \"use_lunar_holidays\": false, \"use_lunar_weekday\": false, \"use_islamic_holidays\": false, \"use_hebrew_holidays\": false, \"anomaly_detector_params\": {\"method\": \"rolling_zscore\", \"transform_dict\": null, \"forecast_params\": null, \"method_params\": {\"distribution\": \"norm\", \"alpha\": 0.05, \"rolling_periods\": 200, \"center\": true}}}, \"regression_type\": null, \"changepoint_prior_scale\": 0.05, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.8, \"growth\": \"linear\", \"n_changepoints\": 20} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AnomalyRemoval\", \"1\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"nonparametric\", \"method_params\": {\"p\": null, \"z_init\": 1.5, \"z_limit\": 10, \"z_step\": 0.25, \"inverse\": false, \"max_contamination\": 0.25, \"mean_weight\": 25, \"sd_weight\": 25, \"anomaly_count_weight\": 1.0}, \"fillna\": \"ffill\", \"transform_dict\": null}, \"1\": {\"method\": \"remove\", \"std_threshold\": 4, \"fillna\": \"rolling_mean_24\"}}}\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/5zx8o7m8.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/9v4hpuj8.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=34397', 'data', 'file=/tmp/tmpav2iq6so/5zx8o7m8.json', 'init=/tmp/tmpav2iq6so/9v4hpuj8.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modeld6p42i55/prophet_model-20230317053150.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:31:50 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:31:51 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py:492: FutureWarning:\n",
            "\n",
            "the 'damped'' keyword is deprecated, use 'damped_trend' instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 365 with model ETS in generation 2 of 2 with params {\"damped_trend\": false, \"trend\": \"multiplicative\", \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 366 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"PoissonRegresssion\", \"model_params\": {}}, \"mean_rolling_periods\": 12, \"macd_periods\": 364, \"std_rolling_periods\": null, \"max_rolling_periods\": 12, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": 30, \"quantile10_rolling_periods\": 30, \"ewm_alpha\": 0.8, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 3, \"holiday\": false, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"rows\": 7, \"lag\": 7, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {}}}\n",
            "Model Number: 367 with model SectionalMotif in generation 2 of 2 with params {\"window\": 15, \"point_method\": \"midhinge\", \"distance_metric\": \"correlation\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"Cointegration\"}, \"transformation_params\": {\"0\": {\"det_order\": 1, \"k_ar_diff\": 1}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3731, in _fit\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2361, in fit_transform\n",
            "    return self.fit(df).transform(df)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 2324, in fit\n",
            "    raise ValueError(\"Coint only works on multivarate series\")\n",
            "ValueError: Coint only works on multivarate series\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 693, in ModelPrediction\n",
            "    df_train_transformed = transformer_object._fit(df_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/tools/transform.py\", line 3741, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer Cointegration failed on fit\n",
            " in model 367: SectionalMotif\n",
            "Model Number: 368 with model LastValueNaive in generation 2 of 2 with params {} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 369 with model SeasonalNaive in generation 2 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 12, \"lag_2\": 7} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 7, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 370 with model ARDL in generation 2 of 2 with params {\"lags\": 2, \"trend\": \"n\", \"order\": 2, \"causal\": false, \"regression_type\": \"User\"} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 2089, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but future_regressor not supplied\n",
            " in model 370: ARDL\n",
            "Model Number: 371 with model GLS in generation 2 of 2 with params {} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 372 with model AverageValueNaive in generation 2 of 2 with params {\"method\": \"Mean\", \"window\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 373 with model Theta in generation 2 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 1.2, \"use_mle\": false} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PowerTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 374 with model MetricMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"weighted_mean\", \"distance_metric\": \"mae\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"X1\", \"state_transition\": [[1, 1, 0], [0, 1, 0], [0, 0, 1]], \"process_noise\": [[0.1, 0.0, 0.0], [0.0, 0.01, 0.0], [0.0, 0.0, 0.1]], \"observation_model\": [[1, 1, 1]], \"observation_noise\": 1.0, \"em_iter\": null}}}, \"combination_transformation\": {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"RollingMeanTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"fixed\": true, \"window\": 3}}}\n",
            "Model Number: 375 with model SeasonalNaive in generation 2 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 2, \"lag_2\": 84} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 376 with model AverageValueNaive in generation 2 of 2 with params {\"method\": \"Median\", \"window\": null} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 377 with model ARDL in generation 2 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 3, \"causal\": false, \"regression_type\": \"User\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"method\": \"clip\", \"std_threshold\": 1, \"fillna\": null}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/statsmodels.py\", line 2089, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but future_regressor not supplied\n",
            " in model 377: ARDL\n",
            "Model Number: 378 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"canberra\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"StandardScaler\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 379 with model MultivariateMotif in generation 2 of 2 with params {\"window\": 28, \"point_method\": \"mean\", \"distance_metric\": \"jensenshannon\", \"k\": 20, \"max_windows\": 10000} and transformations {\"fillna\": \"cubic\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"StandardScaler\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {}}}\n",
            "Model Number: 380 with model LastValueNaive in generation 2 of 2 with params {} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"bkfilter\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 381 with model ARIMA in generation 2 of 2 with params {\"p\": 0, \"d\": 0, \"q\": 7, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"median\", \"transformations\": {\"0\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 382 with model ARDL in generation 2 of 2 with params {\"lags\": 1, \"trend\": \"t\", \"order\": 2, \"causal\": false, \"regression_type\": \"simple\"} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"butter\", \"method_args\": {\"N\": 8, \"window_size\": 4, \"btype\": \"highpass\", \"analog\": false, \"output\": \"sos\"}}}}\n",
            "Model Number: 383 with model ARIMA in generation 2 of 2 with params {\"p\": 12, \"d\": 1, \"q\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"HolidayTransformer\"}, \"transformation_params\": {\"0\": {\"threshold\": 0.9, \"splash_threshold\": null, \"use_dayofmonth_holidays\": true, \"use_wkdom_holidays\": true, \"use_wkdeom_holidays\": false, \"use_lunar_holidays\": false, \"use_lunar_weekday\": false, \"use_islamic_holidays\": false, \"use_hebrew_holidays\": true, \"anomaly_detector_params\": {\"method\": \"zscore\", \"method_params\": {\"distribution\": \"chi2\", \"alpha\": 0.05}, \"fillna\": \"ffill\", \"transform_dict\": null}, \"remove_excess_anomalies\": true, \"impact\": \"anomaly_score\", \"regression_params\": {}}}}\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 384 with model UnobservedComponents in generation 2 of 2 with params {\"level\": \"deterministic trend\", \"maxiter\": 100, \"cov_type\": \"opg\", \"method\": \"bfgs\", \"autoregressive\": null, \"regression_type\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 385 with model UnobservedComponents in generation 2 of 2 with params {\"level\": \"local linear deterministic trend\", \"maxiter\": 250, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": null, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 7, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"method\": \"remove\", \"std_threshold\": 3.5, \"fillna\": \"rolling_mean_24\"}}}\n",
            "Model Number: 386 with model SectionalMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"chebyshev\", \"include_differenced\": true, \"k\": 1, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill_mean_biased\", \"transformations\": {\"0\": \"CumSumTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 387 with model UnivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"FastRidge\", \"model_params\": {}}, \"holiday\": false, \"mean_rolling_periods\": null, \"macd_periods\": null, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 364, \"ewm_var_alpha\": null, \"ewm_alpha\": 0.2, \"additional_lag_periods\": 12, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"add_date_part\": \"expanded\", \"polynomial_degree\": null, \"x_transform\": null, \"regression_type\": null, \"window\": null} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 2, \"lag\": 28, \"method\": \"additive\", \"strength\": 0.5, \"first_value_only\": false}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning:\n",
            "\n",
            "Ill-conditioned matrix (rcond=3.36623e-26): result may not be accurate.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 388 with model MultivariateMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"median\", \"distance_metric\": \"jensenshannon\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"bkfilter\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Model Number: 389 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 28, \"point_method\": \"midhinge\", \"distance_metric\": \"minkowski\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"akima\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 390 with model SectionalMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": true, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"MinMaxScaler\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"normal\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 391 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 28, \"point_method\": \"midhinge\", \"distance_metric\": \"rogerstanimoto\", \"k\": 10, \"max_windows\": 1000} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"EWMAFilter\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"span\": 2}, \"1\": {\"lag_1\": 12, \"method\": \"Mean\"}}}\n",
            "Model Number: 392 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 2}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 4, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 7, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 393 with model UnobservedComponents in generation 2 of 2 with params {\"level\": \"random trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 394 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 90, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"normal\", \"n_quantiles\": 20}, \"1\": {}}}\n",
            "Model Number: 395 with model WindowRegression in generation 2 of 2 with params {\"window_size\": 10, \"input_dim\": \"univariate\", \"output_dim\": \"1step\", \"normalize_window\": false, \"max_windows\": 5000, \"regression_type\": null, \"regression_model\": {\"base_score\": 0.5, \"booster\": \"gbtree\", \"colsample_bylevel\": 0.541426, \"colsample_bynode\": 1, \"colsample_bytree\": 1.0, \"early_stopping_rounds\": null, \"enable_categorical\": false, \"eval_metric\": null, \"feature_types\": null, \"gamma\": 0, \"grow_policy\": \"depthwise\", \"importance_type\": null, \"interaction_constraints\": \"\", \"learning_rate\": 0.012543, \"max_bin\": 256, \"max_cat_threshold\": 64, \"max_cat_to_onehot\": 4, \"max_delta_step\": 0, \"max_depth\": 11, \"max_leaves\": 0, \"min_child_weight\": 0.0127203, \"monotone_constraints\": \"()\", \"n_estimators\": 319, \"num_parallel_tree\": 1, \"predictor\": \"auto\"}} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"StandardScaler\", \"1\": \"Discretize\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"discretization\": \"center\", \"n_bins\": 10}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1464, in fit\n",
            "    self.regr = retrieve_regressor(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 218, in retrieve_regressor\n",
            "    model_class = regression_model['model']\n",
            "KeyError: 'model'\n",
            " in model 395: WindowRegression\n",
            "Model Number: 396 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"weighted_mean\", \"distance_metric\": \"minkowski\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"EWMAFilter\", \"1\": \"PowerTransformer\"}, \"transformation_params\": {\"0\": {\"span\": 2}, \"1\": {}}}\n",
            "Model Number: 397 with model DatepartRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"ExtraTrees\", \"model_params\": {\"n_estimators\": 100, \"min_samples_leaf\": 1, \"max_depth\": 30}}, \"datepart_method\": \"simple_binarized\", \"polynomial_degree\": null, \"regression_type\": null} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 4, \"method\": \"LastValue\"}}}\n",
            "Model Number: 398 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 28, \"point_method\": \"midhinge\", \"distance_metric\": \"cityblock\", \"k\": 3, \"max_windows\": 10000} and transformations {\"fillna\": \"akima\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 399 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 12, \"macd_periods\": 364, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 7, \"quantile90_rolling_periods\": null, \"quantile10_rolling_periods\": 30, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 3, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Model Number: 400 with model Theta in generation 2 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 3, \"use_mle\": false} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"PowerTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 401 with model SectionalMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"mean\", \"distance_metric\": \"chebyshev\", \"include_differenced\": true, \"k\": 3, \"stride_size\": 2, \"regression_type\": null} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"lag_1\": 7, \"method\": \"Mean\"}}}\n",
            "Model Number: 402 with model WindowRegression in generation 2 of 2 with params {\"window_size\": 10, \"input_dim\": \"univariate\", \"output_dim\": \"1step\", \"normalize_window\": false, \"max_windows\": 1000, \"regression_type\": null, \"regression_model\": {\"model\": \"KNN\", \"model_params\": {\"n_neighbors\": 3, \"weights\": \"uniform\", \"p\": 2, \"leaf_size\": 30}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 403 with model NVAR in generation 2 of 2 with params {\"k\": 1, \"ridge_param\": 0.002, \"warmup_pts\": 1, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 404 with model MultivariateMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"yule\", \"k\": 3, \"max_windows\": 10000} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"bkfilter\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null}, \"1\": {}}}\n",
            "Model Number: 405 with model SectionalMotif in generation 2 of 2 with params {\"window\": 15, \"point_method\": \"mean\", \"distance_metric\": \"sokalsneath\", \"include_differenced\": false, \"k\": 10, \"stride_size\": 2, \"regression_type\": null} and transformations {\"fillna\": \"akima\", \"transformations\": {\"0\": \"DifferencedTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"normal\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 406 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"DecisionTree\", \"model_params\": {\"max_depth\": null, \"min_samples_split\": 2}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 4, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 7, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"regression_type\": null, \"window\": 10, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"time\", \"transformations\": {\"0\": \"CenterLastValue\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"rows\": 4}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 407 with model Theta in generation 2 of 2 with params {\"deseasonalize\": true, \"difference\": false, \"use_test\": true, \"method\": \"auto\", \"period\": null, \"theta\": 2, \"use_mle\": false} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"PowerTransformer\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 408 with model ARIMA in generation 2 of 2 with params {\"p\": 12, \"d\": 2, \"q\": 1, \"regression_type\": \"Holiday\"} and transformations {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 409 with model MultivariateMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"mahalanobis\", \"k\": 15, \"max_windows\": 10000} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"PctChangeTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 410 with model WindowRegression in generation 2 of 2 with params {\"window_size\": 20, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": false, \"max_windows\": 5000, \"regression_type\": \"User\", \"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 100, \"min_samples_leaf\": 1, \"bootstrap\": true}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"rows\": 7, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1440, in fit\n",
            "    raise ValueError(\n",
            "ValueError: regression_type='User' but no future_regressor passed\n",
            " in model 410: WindowRegression\n",
            "Model Number: 411 with model AverageValueNaive in generation 2 of 2 with params {\"method\": \"Exp_Weighted_Mean\", \"window\": null} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"SinTrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Model Number: 412 with model MetricMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"weighted_mean\", \"distance_metric\": \"mse\", \"k\": 3, \"comparison_transformation\": {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"X1\", \"state_transition\": [[1, 1, 0], [0, 1, 0], [0, 0, 1]], \"process_noise\": [[0.1, 0.0, 0.0], [0.0, 0.01, 0.0], [0.0, 0.0, 0.1]], \"observation_model\": [[1, 1, 1]], \"observation_noise\": 1.0, \"em_iter\": null}}}, \"combination_transformation\": {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"local linear stochastic seasonal 7\", \"state_transition\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \"process_noise\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \"observation_model\": [[1, 0, 1, 0, 0, 0, 0, 0]], \"observation_noise\": 0.25, \"em_iter\": null}}}} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 413 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 28, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"k\": 10, \"max_windows\": 10000} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 414 with model UnivariateMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"cityblock\", \"k\": 3, \"max_windows\": 10000} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"StandardScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 415 with model MetricMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"mae\", \"k\": 10, \"comparison_transformation\": {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"KalmanSmoothing\"}, \"transformation_params\": {\"0\": {\"model_name\": \"X1\", \"state_transition\": [[1, 1, 0], [0, 1, 0], [0, 0, 1]], \"process_noise\": [[0.1, 0.0, 0.0], [0.0, 0.01, 0.0], [0.0, 0.0, 0.1]], \"observation_model\": [[1, 1, 1]], \"observation_noise\": 1.0, \"em_iter\": null}}}, \"combination_transformation\": {\"fillna\": \"rolling_mean_24\", \"transformations\": {\"0\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"method\": \"butter\", \"method_args\": {\"N\": 7, \"window_size\": 24, \"btype\": \"lowpass\", \"analog\": false, \"output\": \"sos\"}}}}} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"ClipOutliers\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3.5, \"fillna\": null}}}\n",
            "Model Number: 416 with model LastValueNaive in generation 2 of 2 with params {} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 417 with model ARDL in generation 2 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 1, \"causal\": false, \"regression_type\": \"simple_binarized\"} and transformations {\"fillna\": \"fake_date\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 418 with model AverageValueNaive in generation 2 of 2 with params {\"method\": \"Mean\", \"window\": null} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}, \"1\": {\"lag_1\": 12, \"method\": \"Median\"}}}\n",
            "Model Number: 419 with model UnobservedComponents in generation 2 of 2 with params {\"level\": \"random trend\", \"maxiter\": 50, \"cov_type\": \"opg\", \"method\": \"lbfgs\", \"autoregressive\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 420 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 12, \"macd_periods\": 94, \"std_rolling_periods\": null, \"max_rolling_periods\": 12, \"min_rolling_periods\": 28, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 30, \"ewm_alpha\": 0.1, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": null, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"akima\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Tweedie\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 421 with model MultivariateMotif in generation 2 of 2 with params {\"window\": 10, \"point_method\": \"midhinge\", \"distance_metric\": \"yule\", \"k\": 3, \"max_windows\": 10000} and transformations {\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"LocalLinearTrend\", \"1\": \"bkfilter\"}, \"transformation_params\": {\"0\": {\"rolling_window\": 180, \"n_tails\": 30, \"n_future\": 0.2, \"method\": \"median\"}, \"1\": {}}}\n",
            "Model Number: 422 with model WindowRegression in generation 2 of 2 with params {\"window_size\": 28, \"input_dim\": \"univariate\", \"output_dim\": \"1step\", \"normalize_window\": false, \"max_windows\": 5000, \"regression_type\": null, \"regression_model\": {\"model\": \"SVM\", \"model_params\": {}}} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"StandardScaler\", \"1\": \"SeasonalDifference\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"lag_1\": 12, \"method\": \"LastValue\"}}}\n",
            "[LibLinear]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/0kx1qmw6.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 423 with model FBProphet in generation 2 of 2 with params {\"holiday\": false, \"regression_type\": null, \"growth\": \"linear\", \"n_changepoints\": 25, \"changepoint_prior_scale\": 0.05, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.98, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"ScipyFilter\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"method\": \"savgol_filter\", \"method_args\": {\"window_length\": 7, \"polyorder\": 4, \"deriv\": 0, \"mode\": \"mirror\"}}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpav2iq6so/4w4q42l6.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=86717', 'data', 'file=/tmp/tmpav2iq6so/0kx1qmw6.json', 'init=/tmp/tmpav2iq6so/4w4q42l6.json', 'output', 'file=/tmp/tmpav2iq6so/prophet_modelh1tx050r/prophet_model-20230317053259.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "05:32:59 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "05:33:02 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 424 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"RandomForest\", \"model_params\": {\"n_estimators\": 200, \"min_samples_leaf\": 1, \"bootstrap\": true}}, \"mean_rolling_periods\": 12, \"macd_periods\": 94, \"std_rolling_periods\": null, \"max_rolling_periods\": null, \"min_rolling_periods\": 7, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": 30, \"ewm_alpha\": 0.1, \"ewm_var_alpha\": 0.2, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": null, \"holiday\": true, \"probabilistic\": false, \"cointegration\": null, \"cointegration_lag\": 1} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 0.9, \"first_value_only\": false}, \"1\": {}}}\n",
            "building tree 1 of 200\n",
            "building tree 2 of 200\n",
            "building tree 3 of 200\n",
            "building tree 4 of 200\n",
            "building tree 5 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 6 of 200\n",
            "building tree 7 of 200\n",
            "building tree 8 of 200\n",
            "building tree 9 of 200\n",
            "building tree 10 of 200\n",
            "building tree 11 of 200\n",
            "building tree 12 of 200\n",
            "building tree 13 of 200\n",
            "building tree 14 of 200\n",
            "building tree 15 of 200\n",
            "building tree 16 of 200\n",
            "building tree 17 of 200\n",
            "building tree 18 of 200\n",
            "building tree 19 of 200\n",
            "building tree 20 of 200\n",
            "building tree 21 of 200\n",
            "building tree 22 of 200\n",
            "building tree 23 of 200\n",
            "building tree 24 of 200\n",
            "building tree 25 of 200\n",
            "building tree 26 of 200\n",
            "building tree 27 of 200\n",
            "building tree 28 of 200\n",
            "building tree 29 of 200\n",
            "building tree 30 of 200\n",
            "building tree 31 of 200\n",
            "building tree 32 of 200\n",
            "building tree 33 of 200\n",
            "building tree 34 of 200\n",
            "building tree 35 of 200\n",
            "building tree 36 of 200\n",
            "building tree 37 of 200\n",
            "building tree 38 of 200\n",
            "building tree 39 of 200\n",
            "building tree 40 of 200\n",
            "building tree 41 of 200\n",
            "building tree 42 of 200\n",
            "building tree 43 of 200\n",
            "building tree 44 of 200\n",
            "building tree 45 of 200\n",
            "building tree 46 of 200\n",
            "building tree 47 of 200\n",
            "building tree 48 of 200\n",
            "building tree 49 of 200\n",
            "building tree 50 of 200\n",
            "building tree 51 of 200\n",
            "building tree 52 of 200\n",
            "building tree 53 of 200\n",
            "building tree 54 of 200\n",
            "building tree 55 of 200\n",
            "building tree 56 of 200\n",
            "building tree 57 of 200\n",
            "building tree 58 of 200\n",
            "building tree 59 of 200\n",
            "building tree 60 of 200\n",
            "building tree 61 of 200\n",
            "building tree 62 of 200\n",
            "building tree 63 of 200\n",
            "building tree 64 of 200\n",
            "building tree 65 of 200\n",
            "building tree 66 of 200\n",
            "building tree 67 of 200\n",
            "building tree 68 of 200\n",
            "building tree 69 of 200\n",
            "building tree 70 of 200\n",
            "building tree 71 of 200\n",
            "building tree 72 of 200\n",
            "building tree 73 of 200\n",
            "building tree 74 of 200\n",
            "building tree 75 of 200\n",
            "building tree 76 of 200\n",
            "building tree 77 of 200\n",
            "building tree 78 of 200\n",
            "building tree 79 of 200\n",
            "building tree 80 of 200\n",
            "building tree 81 of 200\n",
            "building tree 82 of 200\n",
            "building tree 83 of 200\n",
            "building tree 84 of 200\n",
            "building tree 85 of 200\n",
            "building tree 86 of 200\n",
            "building tree 87 of 200\n",
            "building tree 88 of 200\n",
            "building tree 89 of 200\n",
            "building tree 90 of 200\n",
            "building tree 91 of 200\n",
            "building tree 92 of 200\n",
            "building tree 93 of 200\n",
            "building tree 94 of 200\n",
            "building tree 95 of 200\n",
            "building tree 96 of 200\n",
            "building tree 97 of 200\n",
            "building tree 98 of 200\n",
            "building tree 99 of 200\n",
            "building tree 100 of 200\n",
            "building tree 101 of 200\n",
            "building tree 102 of 200\n",
            "building tree 103 of 200\n",
            "building tree 104 of 200\n",
            "building tree 105 of 200\n",
            "building tree 106 of 200\n",
            "building tree 107 of 200\n",
            "building tree 108 of 200\n",
            "building tree 109 of 200\n",
            "building tree 110 of 200\n",
            "building tree 111 of 200\n",
            "building tree 112 of 200\n",
            "building tree 113 of 200\n",
            "building tree 114 of 200\n",
            "building tree 115 of 200\n",
            "building tree 116 of 200\n",
            "building tree 117 of 200\n",
            "building tree 118 of 200\n",
            "building tree 119 of 200\n",
            "building tree 120 of 200\n",
            "building tree 121 of 200\n",
            "building tree 122 of 200\n",
            "building tree 123 of 200\n",
            "building tree 124 of 200\n",
            "building tree 125 of 200\n",
            "building tree 126 of 200\n",
            "building tree 127 of 200\n",
            "building tree 128 of 200\n",
            "building tree 129 of 200\n",
            "building tree 130 of 200\n",
            "building tree 131 of 200\n",
            "building tree 132 of 200\n",
            "building tree 133 of 200\n",
            "building tree 134 of 200\n",
            "building tree 135 of 200\n",
            "building tree 136 of 200\n",
            "building tree 137 of 200\n",
            "building tree 138 of 200\n",
            "building tree 139 of 200\n",
            "building tree 140 of 200\n",
            "building tree 141 of 200\n",
            "building tree 142 of 200\n",
            "building tree 143 of 200\n",
            "building tree 144 of 200\n",
            "building tree 145 of 200\n",
            "building tree 146 of 200\n",
            "building tree 147 of 200\n",
            "building tree 148 of 200\n",
            "building tree 149 of 200\n",
            "building tree 150 of 200\n",
            "building tree 151 of 200\n",
            "building tree 152 of 200\n",
            "building tree 153 of 200\n",
            "building tree 154 of 200\n",
            "building tree 155 of 200\n",
            "building tree 156 of 200\n",
            "building tree 157 of 200\n",
            "building tree 158 of 200\n",
            "building tree 159 of 200\n",
            "building tree 160 of 200\n",
            "building tree 161 of 200\n",
            "building tree 162 of 200\n",
            "building tree 163 of 200\n",
            "building tree 164 of 200\n",
            "building tree 165 of 200\n",
            "building tree 166 of 200\n",
            "building tree 167 of 200\n",
            "building tree 168 of 200\n",
            "building tree 169 of 200\n",
            "building tree 170 of 200\n",
            "building tree 171 of 200\n",
            "building tree 172 of 200\n",
            "building tree 173 of 200\n",
            "building tree 174 of 200\n",
            "building tree 175 of 200\n",
            "building tree 176 of 200\n",
            "building tree 177 of 200\n",
            "building tree 178 of 200\n",
            "building tree 179 of 200\n",
            "building tree 180 of 200\n",
            "building tree 181 of 200\n",
            "building tree 182 of 200\n",
            "building tree 183 of 200\n",
            "building tree 184 of 200\n",
            "building tree 185 of 200\n",
            "building tree 186 of 200\n",
            "building tree 187 of 200\n",
            "building tree 188 of 200\n",
            "building tree 189 of 200\n",
            "building tree 190 of 200\n",
            "building tree 191 of 200\n",
            "building tree 192 of 200\n",
            "building tree 193 of 200\n",
            "building tree 194 of 200\n",
            "building tree 195 of 200\n",
            "building tree 196 of 200\n",
            "building tree 197 of 200\n",
            "building tree 198 of 200\n",
            "building tree 199 of 200\n",
            "building tree 200 of 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    4.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 425 with model SeasonalNaive in generation 2 of 2 with params {\"method\": \"lastvalue\", \"lag_1\": 24, \"lag_2\": 14} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"rows\": 7, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"EWMAFilter\"}, \"transformation_params\": {\"0\": {\"span\": 2}}}}}}\n",
            "Model Number: 426 with model ETS in generation 2 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": null, \"seasonal_periods\": null} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"ClipOutliers\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"method\": \"clip\", \"std_threshold\": 3, \"fillna\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 427 with model NVAR in generation 2 of 2 with params {\"k\": 1, \"ridge_param\": 0.0002, \"warmup_pts\": 50, \"seed_pts\": 1, \"seed_weighted\": null, \"batch_size\": 5, \"batch_method\": \"input_order\"} and transformations {\"fillna\": \"pad\", \"transformations\": {\"0\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 428 with model ARDL in generation 2 of 2 with params {\"lags\": 1, \"trend\": \"ct\", \"order\": 1, \"causal\": true, \"regression_type\": \"simple_binarized\"} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"DatepartRegression\"}, \"transformation_params\": {\"0\": {\"model\": \"GLS\", \"phi\": 1, \"window\": 10, \"transform_dict\": {\"fillna\": null, \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}}, \"1\": {\"regression_model\": {\"model\": \"ElasticNet\", \"model_params\": {}}, \"datepart_method\": \"recurring\", \"polynomial_degree\": null, \"transform_dict\": null}}}\n",
            "Model Number: 429 with model MultivariateRegression in generation 2 of 2 with params {\"regression_model\": {\"model\": \"RANSAC\", \"model_params\": {}}, \"mean_rolling_periods\": 30, \"macd_periods\": 7, \"std_rolling_periods\": 90, \"max_rolling_periods\": null, \"min_rolling_periods\": 7, \"quantile90_rolling_periods\": 10, \"quantile10_rolling_periods\": null, \"ewm_alpha\": null, \"ewm_var_alpha\": null, \"additional_lag_periods\": null, \"abs_energy\": false, \"rolling_autocorr_periods\": null, \"datepart_method\": null, \"polynomial_degree\": null, \"regression_type\": null, \"window\": 3, \"holiday\": true, \"probabilistic\": false, \"cointegration\": \"Johansen\", \"cointegration_lag\": 2} and transformations {\"fillna\": \"quadratic\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 713, in ModelPrediction\n",
            "    df_forecast = model.predict(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 2783, in predict\n",
            "    rfPred = self.model.predict(x_dat)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ransac.py\", line 585, in predict\n",
            "    return self.estimator_.predict(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_base.py\", line 354, in predict\n",
            "    return self._decision_function(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_base.py\", line 337, in _decision_function\n",
            "    X = self._validate_data(X, accept_sparse=[\"csr\", \"csc\", \"coo\"], reset=False)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 565, in _validate_data\n",
            "    X = check_array(X, input_name=\"X\", **check_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            " in model 429: MultivariateRegression\n",
            "Model Number: 430 with model WindowRegression in generation 2 of 2 with params {\"window_size\": 20, \"input_dim\": \"univariate\", \"output_dim\": \"forecast_length\", \"normalize_window\": true, \"max_windows\": 5000, \"regression_type\": null, \"regression_model\": {\"colsample_bytree\": 0.94716, \"learning_rate\": 0.7024, \"max_bin\": 255, \"min_child_samples\": 15, \"n_estimators\": 5, \"num_leaves\": 35, \"reg_alpha\": 0.00308, \"reg_lambda\": 5.1817}} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"MaxAbsScaler\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Template Eval Error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1375, in TemplateWizard\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 1194, in model_forecast\n",
            "    df_forecast = ModelPrediction(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/evaluator/auto_model.py\", line 712, in ModelPrediction\n",
            "    model = model.fit(df_train_transformed, future_regressor=future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 1464, in fit\n",
            "    self.regr = retrieve_regressor(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/autots/models/sklearn.py\", line 218, in retrieve_regressor\n",
            "    model_class = regression_model['model']\n",
            "KeyError: 'model'\n",
            " in model 430: WindowRegression\n",
            "Model Number: 431 with model ARDL in generation 2 of 2 with params {\"lags\": 3, \"trend\": \"n\", \"order\": 3, \"causal\": false, \"regression_type\": \"holiday\"} and transformations {\"fillna\": \"pchip\", \"transformations\": {\"0\": \"Detrend\", \"1\": \"MinMaxScaler\"}, \"transformation_params\": {\"0\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}, \"1\": {}}}\n",
            "Model Number: 432 with model WindowRegression in generation 2 of 2 with params {\"window_size\": 10, \"input_dim\": \"univariate\", \"output_dim\": \"1step\", \"normalize_window\": false, \"max_windows\": 1000, \"regression_type\": null, \"regression_model\": {\"model\": \"KNN\", \"model_params\": {\"n_neighbors\": 3, \"weights\": \"uniform\", \"p\": 2, \"leaf_size\": 30}}} and transformations {\"fillna\": \"mean\", \"transformations\": {\"0\": \"StandardScaler\", \"1\": \"Discretize\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"discretization\": \"center\", \"n_bins\": 10}}}\n",
            "Model Number: 433 with model GLS in generation 2 of 2 with params {} and transformations {\"fillna\": \"zero\", \"transformations\": {\"0\": \"AlignLastValue\", \"1\": \"Detrend\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"multiplicative\", \"strength\": 1.0, \"first_value_only\": false}, \"1\": {\"model\": \"Linear\", \"phi\": 1, \"window\": null, \"transform_dict\": null}}}\n",
            "Model Number: 434 with model GLS in generation 2 of 2 with params {} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"AlignLastValue\"}, \"transformation_params\": {\"0\": {\"rows\": 1, \"lag\": 1, \"method\": \"additive\", \"strength\": 1.0, \"first_value_only\": false}}}\n",
            "Model Number: 435 with model ETS in generation 2 of 2 with params {\"damped_trend\": false, \"trend\": null, \"seasonal\": \"additive\", \"seasonal_periods\": 60} and transformations {\"fillna\": \"rolling_mean\", \"transformations\": {\"0\": \"QuantileTransformer\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 1000}}}\n",
            "Model Number: 436 with model SectionalMotif in generation 2 of 2 with params {\"window\": 5, \"point_method\": \"midhinge\", \"distance_metric\": \"canberra\", \"include_differenced\": false, \"k\": 10, \"stride_size\": 1, \"regression_type\": null} and transformations {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"DifferencedTransformer\"}, \"transformation_params\": {\"0\": {}}}\n",
            "Model Number: 437 with model Ensemble in generation 3 of Ensembles with params {\"model_name\": \"BestN\", \"model_count\": 3, \"model_metric\": \"best_score\", \"models\": {\"855abb0989ab119fc791a12587f10b90\": {\"Model\": \"ARIMA\", \"ModelParameters\": \"{\\\"p\\\": 12, \\\"d\\\": 2, \\\"q\\\": 1, \\\"regression_type\\\": \\\"Holiday\\\"}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"rolling_mean_24\\\", \\\"transformations\\\": {\\\"0\\\": \\\"MinMaxScaler\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {}}}\"}, \"839273930bb1e85a1dd0336747a8e760\": {\"Model\": \"UnivariateMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"median\\\", \\\"distance_metric\\\": \\\"cityblock\\\", \\\"k\\\": 10, \\\"max_windows\\\": 10000}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"quadratic\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"QuantileTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"output_distribution\\\": \\\"uniform\\\", \\\"n_quantiles\\\": 1000}}}\"}, \"565d61ebbb7671a580e414aa3e22dc95\": {\"Model\": \"MetricMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"weighted_mean\\\", \\\"distance_metric\\\": \\\"mae\\\", \\\"k\\\": 3, \\\"comparison_transformation\\\": {\\\"fillna\\\": \\\"time\\\", \\\"transformations\\\": {\\\"0\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"rows\\\": 2, \\\"lag\\\": 7, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 0.9, \\\"first_value_only\\\": false}}}, \\\"combination_transformation\\\": {\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"KalmanSmoothing\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model_name\\\": \\\"local linear stochastic seasonal 7\\\", \\\"state_transition\\\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \\\"process_noise\\\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \\\"observation_model\\\": [[1, 0, 1, 0, 0, 0, 0, 0]], \\\"observation_noise\\\": 0.25, \\\"em_iter\\\": null}}}}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"rows\\\": 1, \\\"lag\\\": 1, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 1.0, \\\"first_value_only\\\": false}}}\"}}} and transformations {}\n",
            "Ensemble BestN component 2 of 3 ARIMA succeeded\n",
            "Ensemble BestN component 3 of 3 UnivariateMotif succeeded\n",
            "Ensemble BestN component 4 of 3 MetricMotif succeeded\n",
            "Model Number: 438 with model Ensemble in generation 3 of Ensembles with params {\"model_name\": \"BestN\", \"model_count\": 5, \"model_metric\": \"bestn_horizontal\", \"models\": {\"855abb0989ab119fc791a12587f10b90\": {\"Model\": \"ARIMA\", \"ModelParameters\": \"{\\\"p\\\": 12, \\\"d\\\": 2, \\\"q\\\": 1, \\\"regression_type\\\": \\\"Holiday\\\"}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"rolling_mean_24\\\", \\\"transformations\\\": {\\\"0\\\": \\\"MinMaxScaler\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {}}}\"}, \"839273930bb1e85a1dd0336747a8e760\": {\"Model\": \"UnivariateMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"median\\\", \\\"distance_metric\\\": \\\"cityblock\\\", \\\"k\\\": 10, \\\"max_windows\\\": 10000}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"quadratic\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"QuantileTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"output_distribution\\\": \\\"uniform\\\", \\\"n_quantiles\\\": 1000}}}\"}, \"565d61ebbb7671a580e414aa3e22dc95\": {\"Model\": \"MetricMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"weighted_mean\\\", \\\"distance_metric\\\": \\\"mae\\\", \\\"k\\\": 3, \\\"comparison_transformation\\\": {\\\"fillna\\\": \\\"time\\\", \\\"transformations\\\": {\\\"0\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"rows\\\": 2, \\\"lag\\\": 7, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 0.9, \\\"first_value_only\\\": false}}}, \\\"combination_transformation\\\": {\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"KalmanSmoothing\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model_name\\\": \\\"local linear stochastic seasonal 7\\\", \\\"state_transition\\\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \\\"process_noise\\\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \\\"observation_model\\\": [[1, 0, 1, 0, 0, 0, 0, 0]], \\\"observation_noise\\\": 0.25, \\\"em_iter\\\": null}}}}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"rows\\\": 1, \\\"lag\\\": 1, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 1.0, \\\"first_value_only\\\": false}}}\"}, \"77dbf10c955f4f1e5946f4009e339bdb\": {\"Model\": \"UnivariateMotif\", \"ModelParameters\": \"{\\\"window\\\": 28, \\\"point_method\\\": \\\"weighted_mean\\\", \\\"distance_metric\\\": \\\"canberra\\\", \\\"k\\\": 10, \\\"max_windows\\\": 10000}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"quadratic\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"QuantileTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"output_distribution\\\": \\\"uniform\\\", \\\"n_quantiles\\\": 1000}}}\"}, \"2c0c1e2b026356c134e5000c3dd00ecb\": {\"Model\": \"MetricMotif\", \"ModelParameters\": \"{\\\"window\\\": 5, \\\"point_method\\\": \\\"midhinge\\\", \\\"distance_metric\\\": \\\"mae\\\", \\\"k\\\": 3, \\\"comparison_transformation\\\": {\\\"fillna\\\": \\\"quadratic\\\", \\\"transformations\\\": {\\\"0\\\": \\\"KalmanSmoothing\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model_name\\\": \\\"X1\\\", \\\"state_transition\\\": [[1, 1, 0], [0, 1, 0], [0, 0, 1]], \\\"process_noise\\\": [[0.1, 0.0, 0.0], [0.0, 0.01, 0.0], [0.0, 0.0, 0.1]], \\\"observation_model\\\": [[1, 1, 1]], \\\"observation_noise\\\": 1.0, \\\"em_iter\\\": null}}}, \\\"combination_transformation\\\": {\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"KalmanSmoothing\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model_name\\\": \\\"local linear stochastic seasonal 7\\\", \\\"state_transition\\\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \\\"process_noise\\\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \\\"observation_model\\\": [[1, 0, 1, 0, 0, 0, 0, 0]], \\\"observation_noise\\\": 0.25, \\\"em_iter\\\": null}}}}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"QuantileTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"output_distribution\\\": \\\"uniform\\\", \\\"n_quantiles\\\": 1000}}}\"}}, \"point_method\": \"median\"} and transformations {}\n",
            "Ensemble BestN component 2 of 5 ARIMA succeeded\n",
            "Ensemble BestN component 3 of 5 UnivariateMotif succeeded\n",
            "Ensemble BestN component 4 of 5 MetricMotif succeeded\n",
            "Ensemble BestN component 5 of 5 UnivariateMotif succeeded\n",
            "Ensemble BestN component 6 of 5 MetricMotif succeeded\n",
            "Model Number: 439 with model Ensemble in generation 3 of Ensembles with params {\"model_name\": \"BestN\", \"model_count\": 3, \"model_metric\": \"mixed_metric\", \"models\": {\"855abb0989ab119fc791a12587f10b90\": {\"Model\": \"ARIMA\", \"ModelParameters\": \"{\\\"p\\\": 12, \\\"d\\\": 2, \\\"q\\\": 1, \\\"regression_type\\\": \\\"Holiday\\\"}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"rolling_mean_24\\\", \\\"transformations\\\": {\\\"0\\\": \\\"MinMaxScaler\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {}}}\"}, \"d9446c3ca177cc514c8ad60ac2cd95ce\": {\"Model\": \"UnobservedComponents\", \"ModelParameters\": \"{\\\"level\\\": \\\"random trend\\\", \\\"maxiter\\\": 50, \\\"cov_type\\\": \\\"opg\\\", \\\"method\\\": \\\"lbfgs\\\", \\\"autoregressive\\\": 1, \\\"regression_type\\\": null}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"mean\\\", \\\"transformations\\\": {\\\"0\\\": \\\"AlignLastValue\\\", \\\"1\\\": \\\"SeasonalDifference\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"rows\\\": 7, \\\"lag\\\": 1, \\\"method\\\": \\\"additive\\\", \\\"strength\\\": 0.2, \\\"first_value_only\\\": false}, \\\"1\\\": {\\\"lag_1\\\": 12, \\\"method\\\": \\\"Median\\\"}}}\"}, \"7c04efaff0dbb8096c9bfb982a1c0d33\": {\"Model\": \"UnobservedComponents\", \"ModelParameters\": \"{\\\"level\\\": \\\"random trend\\\", \\\"maxiter\\\": 50, \\\"cov_type\\\": \\\"opg\\\", \\\"method\\\": \\\"lbfgs\\\", \\\"autoregressive\\\": 1, \\\"regression_type\\\": null}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"ffill\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}}}\"}}} and transformations {}\n",
            "Ensemble BestN component 2 of 3 ARIMA succeeded\n",
            "Ensemble BestN component 3 of 3 UnobservedComponents succeeded\n",
            "Ensemble BestN component 4 of 3 UnobservedComponents succeeded\n",
            "Model Number: 440 with model Ensemble in generation 3 of Ensembles with params {\"model_name\": \"BestN\", \"model_count\": 5, \"model_metric\": \"mixed_metric\", \"models\": {\"855abb0989ab119fc791a12587f10b90\": {\"Model\": \"ARIMA\", \"ModelParameters\": \"{\\\"p\\\": 12, \\\"d\\\": 2, \\\"q\\\": 1, \\\"regression_type\\\": \\\"Holiday\\\"}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"rolling_mean_24\\\", \\\"transformations\\\": {\\\"0\\\": \\\"MinMaxScaler\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {}}}\"}, \"d9446c3ca177cc514c8ad60ac2cd95ce\": {\"Model\": \"UnobservedComponents\", \"ModelParameters\": \"{\\\"level\\\": \\\"random trend\\\", \\\"maxiter\\\": 50, \\\"cov_type\\\": \\\"opg\\\", \\\"method\\\": \\\"lbfgs\\\", \\\"autoregressive\\\": 1, \\\"regression_type\\\": null}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"mean\\\", \\\"transformations\\\": {\\\"0\\\": \\\"AlignLastValue\\\", \\\"1\\\": \\\"SeasonalDifference\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"rows\\\": 7, \\\"lag\\\": 1, \\\"method\\\": \\\"additive\\\", \\\"strength\\\": 0.2, \\\"first_value_only\\\": false}, \\\"1\\\": {\\\"lag_1\\\": 12, \\\"method\\\": \\\"Median\\\"}}}\"}, \"7c04efaff0dbb8096c9bfb982a1c0d33\": {\"Model\": \"UnobservedComponents\", \"ModelParameters\": \"{\\\"level\\\": \\\"random trend\\\", \\\"maxiter\\\": 50, \\\"cov_type\\\": \\\"opg\\\", \\\"method\\\": \\\"lbfgs\\\", \\\"autoregressive\\\": 1, \\\"regression_type\\\": null}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"ffill\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}}}\"}, \"8bfb824fd39b68a3b105debf8b6ba78d\": {\"Model\": \"SeasonalNaive\", \"ModelParameters\": \"{\\\"method\\\": \\\"lastvalue\\\", \\\"lag_1\\\": 2, \\\"lag_2\\\": 84}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"ffill_mean_biased\\\", \\\"transformations\\\": {\\\"0\\\": \\\"DifferencedTransformer\\\", \\\"1\\\": \\\"QuantileTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {}, \\\"1\\\": {\\\"output_distribution\\\": \\\"uniform\\\", \\\"n_quantiles\\\": 1000}}}\"}, \"1494bb1084f18408cd8c51f1d9810170\": {\"Model\": \"UnivariateMotif\", \"ModelParameters\": \"{\\\"window\\\": 60, \\\"point_method\\\": \\\"median\\\", \\\"distance_metric\\\": \\\"canberra\\\", \\\"k\\\": 10, \\\"max_windows\\\": 10000}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"ffill\\\", \\\"transformations\\\": {\\\"0\\\": \\\"EWMAFilter\\\", \\\"1\\\": \\\"PowerTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"span\\\": 2}, \\\"1\\\": {}}}\"}}, \"point_method\": \"median\"} and transformations {}\n",
            "Ensemble BestN component 2 of 5 ARIMA succeeded\n",
            "Ensemble BestN component 3 of 5 UnobservedComponents succeeded\n",
            "Ensemble BestN component 4 of 5 UnobservedComponents succeeded\n",
            "Ensemble BestN component 5 of 5 SeasonalNaive succeeded\n",
            "Ensemble BestN component 6 of 5 UnivariateMotif succeeded\n",
            "Model Number: 441 with model Ensemble in generation 3 of Ensembles with params {\"model_name\": \"BestN\", \"model_count\": 3, \"model_metric\": \"best_score_unique\", \"models\": {\"855abb0989ab119fc791a12587f10b90\": {\"Model\": \"ARIMA\", \"ModelParameters\": \"{\\\"p\\\": 12, \\\"d\\\": 2, \\\"q\\\": 1, \\\"regression_type\\\": \\\"Holiday\\\"}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"rolling_mean_24\\\", \\\"transformations\\\": {\\\"0\\\": \\\"MinMaxScaler\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {}}}\"}, \"839273930bb1e85a1dd0336747a8e760\": {\"Model\": \"UnivariateMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"median\\\", \\\"distance_metric\\\": \\\"cityblock\\\", \\\"k\\\": 10, \\\"max_windows\\\": 10000}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"quadratic\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"QuantileTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"output_distribution\\\": \\\"uniform\\\", \\\"n_quantiles\\\": 1000}}}\"}, \"565d61ebbb7671a580e414aa3e22dc95\": {\"Model\": \"MetricMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"weighted_mean\\\", \\\"distance_metric\\\": \\\"mae\\\", \\\"k\\\": 3, \\\"comparison_transformation\\\": {\\\"fillna\\\": \\\"time\\\", \\\"transformations\\\": {\\\"0\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"rows\\\": 2, \\\"lag\\\": 7, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 0.9, \\\"first_value_only\\\": false}}}, \\\"combination_transformation\\\": {\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"KalmanSmoothing\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model_name\\\": \\\"local linear stochastic seasonal 7\\\", \\\"state_transition\\\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \\\"process_noise\\\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \\\"observation_model\\\": [[1, 0, 1, 0, 0, 0, 0, 0]], \\\"observation_noise\\\": 0.25, \\\"em_iter\\\": null}}}}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"rows\\\": 1, \\\"lag\\\": 1, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 1.0, \\\"first_value_only\\\": false}}}\"}}} and transformations {}\n",
            "Ensemble BestN component 2 of 3 ARIMA succeeded\n",
            "Ensemble BestN component 3 of 3 UnivariateMotif succeeded\n",
            "Ensemble BestN component 4 of 3 MetricMotif succeeded\n",
            "Model Number: 442 with model Ensemble in generation 3 of Ensembles with params {\"model_name\": \"BestN\", \"model_count\": 5, \"model_metric\": \"best_score_unique\", \"models\": {\"855abb0989ab119fc791a12587f10b90\": {\"Model\": \"ARIMA\", \"ModelParameters\": \"{\\\"p\\\": 12, \\\"d\\\": 2, \\\"q\\\": 1, \\\"regression_type\\\": \\\"Holiday\\\"}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"rolling_mean_24\\\", \\\"transformations\\\": {\\\"0\\\": \\\"MinMaxScaler\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {}}}\"}, \"839273930bb1e85a1dd0336747a8e760\": {\"Model\": \"UnivariateMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"median\\\", \\\"distance_metric\\\": \\\"cityblock\\\", \\\"k\\\": 10, \\\"max_windows\\\": 10000}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"quadratic\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"QuantileTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"output_distribution\\\": \\\"uniform\\\", \\\"n_quantiles\\\": 1000}}}\"}, \"565d61ebbb7671a580e414aa3e22dc95\": {\"Model\": \"MetricMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"weighted_mean\\\", \\\"distance_metric\\\": \\\"mae\\\", \\\"k\\\": 3, \\\"comparison_transformation\\\": {\\\"fillna\\\": \\\"time\\\", \\\"transformations\\\": {\\\"0\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"rows\\\": 2, \\\"lag\\\": 7, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 0.9, \\\"first_value_only\\\": false}}}, \\\"combination_transformation\\\": {\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"KalmanSmoothing\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model_name\\\": \\\"local linear stochastic seasonal 7\\\", \\\"state_transition\\\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \\\"process_noise\\\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \\\"observation_model\\\": [[1, 0, 1, 0, 0, 0, 0, 0]], \\\"observation_noise\\\": 0.25, \\\"em_iter\\\": null}}}}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"rows\\\": 1, \\\"lag\\\": 1, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 1.0, \\\"first_value_only\\\": false}}}\"}, \"77c9c9e7367979fc19766556b503f4d7\": {\"Model\": \"MultivariateRegression\", \"ModelParameters\": \"{\\\"regression_model\\\": {\\\"model\\\": \\\"RANSAC\\\", \\\"model_params\\\": {}}, \\\"mean_rolling_periods\\\": 12, \\\"macd_periods\\\": 94, \\\"std_rolling_periods\\\": null, \\\"max_rolling_periods\\\": 12, \\\"min_rolling_periods\\\": 28, \\\"quantile90_rolling_periods\\\": 10, \\\"quantile10_rolling_periods\\\": 30, \\\"ewm_alpha\\\": 0.1, \\\"ewm_var_alpha\\\": null, \\\"additional_lag_periods\\\": null, \\\"abs_energy\\\": false, \\\"rolling_autocorr_periods\\\": null, \\\"datepart_method\\\": null, \\\"polynomial_degree\\\": null, \\\"regression_type\\\": null, \\\"window\\\": null, \\\"holiday\\\": true, \\\"probabilistic\\\": false, \\\"cointegration\\\": null, \\\"cointegration_lag\\\": 1}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"akima\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Tweedie\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}}}\"}, \"7c04efaff0dbb8096c9bfb982a1c0d33\": {\"Model\": \"UnobservedComponents\", \"ModelParameters\": \"{\\\"level\\\": \\\"random trend\\\", \\\"maxiter\\\": 50, \\\"cov_type\\\": \\\"opg\\\", \\\"method\\\": \\\"lbfgs\\\", \\\"autoregressive\\\": 1, \\\"regression_type\\\": null}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"ffill\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}}}\"}}, \"point_method\": \"midhinge\"} and transformations {}\n",
            "Ensemble BestN component 2 of 5 ARIMA succeeded\n",
            "Ensemble BestN component 3 of 5 UnivariateMotif succeeded\n",
            "Ensemble BestN component 4 of 5 MetricMotif succeeded\n",
            "Ensemble BestN component 5 of 5 MultivariateRegression succeeded\n",
            "Ensemble BestN component 6 of 5 UnobservedComponents succeeded\n",
            "Model Number: 443 with model Ensemble in generation 3 of Ensembles with params {\"model_name\": \"BestN\", \"model_count\": 3, \"model_metric\": \"bestn_horizontal\", \"models\": {\"855abb0989ab119fc791a12587f10b90\": {\"Model\": \"ARIMA\", \"ModelParameters\": \"{\\\"p\\\": 12, \\\"d\\\": 2, \\\"q\\\": 1, \\\"regression_type\\\": \\\"Holiday\\\"}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"rolling_mean_24\\\", \\\"transformations\\\": {\\\"0\\\": \\\"MinMaxScaler\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {}}}\"}, \"839273930bb1e85a1dd0336747a8e760\": {\"Model\": \"UnivariateMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"median\\\", \\\"distance_metric\\\": \\\"cityblock\\\", \\\"k\\\": 10, \\\"max_windows\\\": 10000}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"quadratic\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"QuantileTransformer\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"output_distribution\\\": \\\"uniform\\\", \\\"n_quantiles\\\": 1000}}}\"}, \"565d61ebbb7671a580e414aa3e22dc95\": {\"Model\": \"MetricMotif\", \"ModelParameters\": \"{\\\"window\\\": 10, \\\"point_method\\\": \\\"weighted_mean\\\", \\\"distance_metric\\\": \\\"mae\\\", \\\"k\\\": 3, \\\"comparison_transformation\\\": {\\\"fillna\\\": \\\"time\\\", \\\"transformations\\\": {\\\"0\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"rows\\\": 2, \\\"lag\\\": 7, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 0.9, \\\"first_value_only\\\": false}}}, \\\"combination_transformation\\\": {\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"KalmanSmoothing\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model_name\\\": \\\"local linear stochastic seasonal 7\\\", \\\"state_transition\\\": [[1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], \\\"process_noise\\\": [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], \\\"observation_model\\\": [[1, 0, 1, 0, 0, 0, 0, 0]], \\\"observation_noise\\\": 0.25, \\\"em_iter\\\": null}}}}\", \"TransformationParameters\": \"{\\\"fillna\\\": \\\"fake_date\\\", \\\"transformations\\\": {\\\"0\\\": \\\"Detrend\\\", \\\"1\\\": \\\"AlignLastValue\\\"}, \\\"transformation_params\\\": {\\\"0\\\": {\\\"model\\\": \\\"Linear\\\", \\\"phi\\\": 1, \\\"window\\\": null, \\\"transform_dict\\\": null}, \\\"1\\\": {\\\"rows\\\": 1, \\\"lag\\\": 1, \\\"method\\\": \\\"multiplicative\\\", \\\"strength\\\": 1.0, \\\"first_value_only\\\": false}}}\"}}, \"model_weights\": {\"855abb0989ab119fc791a12587f10b90\": 21.0, \"839273930bb1e85a1dd0336747a8e760\": 20.0, \"565d61ebbb7671a580e414aa3e22dc95\": 19.0}} and transformations {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZiO5GfXt_u7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}